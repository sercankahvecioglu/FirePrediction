{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91a3d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mayer\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mayer\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mayer\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# INSTALL DEPENDENCIES (Colab only)\n",
    "!pip install torch torchvision\n",
    "\n",
    "# ðŸ”§ IMPORTS\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import rasterio \n",
    "# ðŸ“¦ CUSTOM DATASET\n",
    "import rasterio\n",
    "\n",
    "class VegetationDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = []\n",
    "\n",
    "        for label, subfolder in enumerate(['NO_VEGETATION', 'VEGETATION']):\n",
    "            folder = os.path.join(root_dir, subfolder)\n",
    "            for file in os.listdir(folder):\n",
    "                if file.endswith(('.npy', '.tif', '.tiff')):\n",
    "                    self.samples.append((os.path.join(folder, file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "\n",
    "        if path.endswith('.npy'):\n",
    "            array = np.load(path)  # shape: [H, W, 15]\n",
    "            red = array[:, :, 3] / 10000.0\n",
    "            green = array[:, :, 2] / 10000.0\n",
    "            blue = array[:, :, 1] / 10000.0\n",
    "            ndvi = array[:, :, 13]\n",
    "        elif path.endswith(('.tif', '.tiff')):\n",
    "            with rasterio.open(path) as src:\n",
    "                try:\n",
    "                    red = src.read(4).astype(np.float32) / 10000.0\n",
    "                    green = src.read(3).astype(np.float32) / 10000.0\n",
    "                    blue = src.read(2).astype(np.float32) / 10000.0\n",
    "                    nir = src.read(8).astype(np.float32) / 10000.0\n",
    "                except IndexError:\n",
    "                    raise ValueError(f\"{os.path.basename(path)} doesn't contain required bands 2, 3, 4, and 8\")\n",
    "                ndvi = (nir - red) / (nir + red + 1e-5)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {path}\")\n",
    "\n",
    "        # Stack and resize\n",
    "        stacked = np.stack([red, green, blue, ndvi], axis=0)  # [4, H, W]\n",
    "        tensor = torch.tensor(stacked, dtype=torch.float32)\n",
    "        tensor = F.interpolate(tensor.unsqueeze(0), size=(64, 64), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        return tensor, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "#  MODEL\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # assuming 64x64 patches\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [B, 32, 32, 32]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [B, 64, 16, 16]\n",
    "        x = x.view(x.size(0), -1)             # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))\n",
    "\n",
    "#  TRAINING SETUP\n",
    "def train_model(dataset_path, num_epochs=10, batch_size=32):\n",
    "    dataset = VegetationDataset(dataset_path)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "    model = SimpleCNN(in_channels=4)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "#  EVALUATION FUNCTION\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images).squeeze() > 0.5\n",
    "            correct += (outputs == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    print(f\"Validation Accuracy: {correct / total:.2%}\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def predict(model, image_path):\n",
    "    # Detect file type\n",
    "    if image_path.endswith('.npy'):\n",
    "        array = np.load(image_path)  # shape: [H, W, 15]\n",
    "        red = array[:, :, 3] / 10000.0\n",
    "        green = array[:, :, 2] / 10000.0\n",
    "        blue = array[:, :, 1] / 10000.0\n",
    "        ndvi = array[:, :, 13]\n",
    "\n",
    "        # Stack to [4, H, W]\n",
    "        stacked = np.stack([red, green, blue, ndvi], axis=0)\n",
    "    elif image_path.endswith('.png') or image_path.endswith('.jpg'):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = img.resize((64, 64))  # Resize for consistency\n",
    "        img = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "        red = img[:, :, 0]\n",
    "        green = img[:, :, 1]\n",
    "        blue = img[:, :, 2]\n",
    "        ndvi = np.zeros_like(red)\n",
    "\n",
    "        # Stack to [4, 64, 64]\n",
    "        stacked = np.stack([red, green, blue, ndvi], axis=0)\n",
    "\n",
    "    elif image_path.endswith('.tif') or image_path.endswith('.tiff'):\n",
    "        import rasterio\n",
    "        with rasterio.open(image_path) as src:\n",
    "        # Read bands using Sentinel-2 standard band numbers:\n",
    "        # Band 4 = red (index 4)\n",
    "        # Band 3 = green (index 3)\n",
    "        # Band 2 = blue (index 2)\n",
    "        # Band 8 = NIR (index 8)\n",
    "         red = src.read(4).astype(np.float32) / 10000.0\n",
    "         green = src.read(3).astype(np.float32) / 10000.0\n",
    "         blue = src.read(2).astype(np.float32) / 10000.0\n",
    "         nir = src.read(8).astype(np.float32) / 10000.0\n",
    "\n",
    "        # Compute NDVI\n",
    "         ndvi = (nir - red) / (nir + red + 1e-5)\n",
    "\n",
    "        # Stack to [4, H, W]\n",
    "         stacked = np.stack([red, green, blue, ndvi], axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use .npy or .png/.jpg\")\n",
    "\n",
    "    # Resize if needed (for .npy)\n",
    "    if stacked.shape[1:] != (64, 64):\n",
    "        tensor = torch.tensor(stacked, dtype=torch.float32).unsqueeze(0)  # [1, 4, H, W]\n",
    "        tensor = F.interpolate(tensor, size=(64, 64), mode='bilinear', align_corners=False)\n",
    "    else:\n",
    "        tensor = torch.tensor(stacked, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    # Predict\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        prob = model(tensor.to(device)).item()\n",
    "        label = \"VEGETATION\" if prob > 0.5 else \"NO_VEGETATION\"\n",
    "   \n",
    "   # visualize = true \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    rgb_vis = np.stack([red, green, blue], axis=-1)\n",
    "    rgb_vis = np.clip(rgb_vis, 0, 1)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(rgb_vis)\n",
    "    plt.title(f\"Prediction: {label}\", fontsize=14, color='green' if label == \"VEGETATION\" else 'red')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6377b500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.5194\n",
      "Epoch 2/25, Loss: 0.2311\n",
      "Epoch 3/25, Loss: 0.2777\n",
      "Epoch 4/25, Loss: 0.2203\n",
      "Epoch 5/25, Loss: 0.1630\n",
      "Epoch 6/25, Loss: 0.1556\n",
      "Epoch 7/25, Loss: 0.1484\n",
      "Epoch 8/25, Loss: 0.1369\n",
      "Epoch 9/25, Loss: 0.1001\n",
      "Epoch 10/25, Loss: 0.0890\n",
      "Epoch 11/25, Loss: 0.0652\n",
      "Epoch 12/25, Loss: 0.0542\n",
      "Epoch 13/25, Loss: 0.0439\n",
      "Epoch 14/25, Loss: 0.0381\n",
      "Epoch 15/25, Loss: 0.0305\n",
      "Epoch 16/25, Loss: 0.0185\n",
      "Epoch 17/25, Loss: 0.0166\n",
      "Epoch 18/25, Loss: 0.0300\n",
      "Epoch 19/25, Loss: 0.0488\n",
      "Epoch 20/25, Loss: 0.0287\n",
      "Epoch 21/25, Loss: 0.0156\n",
      "Epoch 22/25, Loss: 0.0094\n",
      "Epoch 23/25, Loss: 0.0100\n",
      "Epoch 24/25, Loss: 0.0045\n",
      "Epoch 25/25, Loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Local path to the ZIP file\n",
    "zip_path = r\"C:\\Users\\mayer\\Ð Ð°Ð±Ð¾Ñ‚ÐµÐ½ Ð¿Ð»Ð¾Ñ‚\\final forest detector\\sample_veg_detection_data\"\n",
    "\n",
    "# Folder where the data will be extracted\n",
    "extracted_path = r\"C:\\Users\\mayer\\Ð Ð°Ð±Ð¾Ñ‚ÐµÐ½ Ð¿Ð»Ð¾Ñ‚\\final forest detector\\sample_veg_detection_data\"\n",
    "\n",
    "# Only extract if not already extracted\n",
    "if not os.path.exists(extracted_path):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "# Train the model using the extracted folder\n",
    "model = train_model(extracted_path, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1384a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VEGETATION\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "testFile_path = r\"photos from DIego previous project/Highway_9.tif\" # Get the uploaded filename\n",
    "result = predict(model, testFile_path)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d526c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "class BigEarthNetVegetationDataset(Dataset):\n",
    "    def __init__(self, root_dir, metadata_parquet_path, required_bands=None,\n",
    "                 max_samples_per_class=None, filter_cloud=True):\n",
    "        \"\"\"\n",
    "        root_dir: BigEarthNet-S2 root (contains many tile folders)\n",
    "        metadata_parquet_path: path to metadata.parquet\n",
    "        required_bands: list of band suffixes, e.g. ['_B04.tif','_B03.tif',...]\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.samples = []\n",
    "\n",
    "        if required_bands is None:\n",
    "            # Default: RGB + red-edge + NIR + SWIR\n",
    "            required_bands = [\n",
    "                '_B04.tif', '_B03.tif', '_B02.tif',  # RGB\n",
    "                '_B05.tif', '_B06.tif', '_B07.tif', '_B8A.tif',  # Red-edge\n",
    "                '_B08.tif',  # NIR\n",
    "                '_B11.tif', '_B12.tif'  # SWIR\n",
    "            ]\n",
    "\n",
    "        # Load metadata parquet\n",
    "        table = pq.read_table(metadata_parquet_path)\n",
    "        df = table.to_pandas()\n",
    "\n",
    "        # Filter cloudy or snowy patches if needed\n",
    "        if filter_cloud:\n",
    "            if 'contains_cloud_or_shadow' in df.columns:\n",
    "                df = df[df['contains_cloud_or_shadow'] == False]\n",
    "            if 'contains_seasonal_snow' in df.columns:\n",
    "                df = df[df['contains_seasonal_snow'] == False]\n",
    "\n",
    "        # Forest label set\n",
    "        forest_labels = set([\n",
    "            \"Forest\", \"Broad-leaved forest\", \"Coniferous forest\",\n",
    "            \"Mixed forest\", \"Transitional woodland, shrub\"\n",
    "        ])\n",
    "\n",
    "        # Binary label column\n",
    "        df['binary_label'] = df['labels'].apply(\n",
    "            lambda labels: 1.0 if set(labels) & forest_labels else 0.0\n",
    "        )\n",
    "\n",
    "        # Optional: limit samples per class\n",
    "        if max_samples_per_class is not None:\n",
    "            pos = df[df['binary_label'] == 1.0].sample(n=max_samples_per_class, random_state=42)\n",
    "            neg = df[df['binary_label'] == 0.0].sample(n=max_samples_per_class, random_state=42)\n",
    "            df = pd.concat([pos, neg]).reset_index(drop=True)\n",
    "\n",
    "        # Iterate rows and load patches\n",
    "        for _, row in df.iterrows():\n",
    "            patch_id = row['patch_id']\n",
    "            binary_label = float(row['binary_label'])\n",
    "\n",
    "            found_patch_path = None\n",
    "            for tile_folder in os.listdir(root_dir):\n",
    "                tile_path = os.path.join(root_dir, tile_folder)\n",
    "                candidate = os.path.join(tile_path, patch_id)\n",
    "                if os.path.isdir(candidate):\n",
    "                    if all(os.path.exists(os.path.join(candidate, patch_id + b)) for b in required_bands):\n",
    "                        found_patch_path = candidate\n",
    "                        break\n",
    "\n",
    "            if not found_patch_path:\n",
    "                continue  # Skip if not found or missing bands\n",
    "\n",
    "            chans = []\n",
    "            target_shape = None  # Will be set from first band\n",
    "            try:\n",
    "                for b in required_bands:\n",
    "                    path = os.path.join(found_patch_path, patch_id + b)\n",
    "                    with rasterio.open(path) as src:\n",
    "                        arr = src.read(1).astype(np.float32)\n",
    "\n",
    "                        # Set target shape from first band\n",
    "                        if target_shape is None:\n",
    "                            target_shape = arr.shape\n",
    "\n",
    "                        # Resize if needed\n",
    "                        if arr.shape != target_shape:\n",
    "                            arr = resize(arr, target_shape, mode='reflect', anti_aliasing=True)\n",
    "\n",
    "                        # Scale and clean\n",
    "                        arr /= 10000.0\n",
    "                        arr = np.nan_to_num(np.clip(arr, 0.0, 1.0))\n",
    "                        chans.append(arr)\n",
    "\n",
    "                # Compute NDVI & NDMI\n",
    "                nir = chans[required_bands.index('_B08.tif')]\n",
    "                red = chans[required_bands.index('_B04.tif')]\n",
    "                swir = chans[required_bands.index('_B11.tif')] if '_B11.tif' in required_bands else None\n",
    "\n",
    "                ndvi = (nir - red) / (nir + red + 1e-6)\n",
    "                ndmi = (nir - swir) / (nir + swir + 1e-6) if swir is not None else np.zeros_like(ndvi)\n",
    "\n",
    "                chans.append(ndvi)\n",
    "                chans.append(ndmi)\n",
    "\n",
    "                stacked = np.stack(chans, axis=0)  # Shape: C x H x W\n",
    "                self.samples.append((stacked, binary_label))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {patch_id} due to {e}\")\n",
    "                continue\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.samples[idx]\n",
    "        tensor = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Resize to fixed size for model\n",
    "        tensor = F.interpolate(tensor.unsqueeze(0), size=(64, 64), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        return tensor, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85253b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        # use adaptive pooling so FC receives fixed-size features regardless of input size\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((4,4))  # outputs [B, 64, 4, 4]\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)  # logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.adapt(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)  # raw logits (no sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1548d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "def train_model(dataset_path, metadata_parquet, required_bands, num_epochs=10, batch_size=32, max_samples_per_class=None):\n",
    "    # create dataset\n",
    "    ds = BigEarthNetVegetationDataset(dataset_path, metadata_parquet_path=metadata_parquet,\n",
    "                                      required_bands=required_bands, max_samples_per_class=max_samples_per_class)\n",
    "    if len(ds) == 0:\n",
    "        raise RuntimeError(\"No samples found in dataset. Check paths and required_bands.\")\n",
    "    # dynamic channels\n",
    "    sample = ds[0][0]  # tensor CxHxW\n",
    "    in_channels = sample.shape[0]\n",
    "\n",
    "    train_size = int(0.8 * len(ds))\n",
    "    val_size = len(ds) - train_size\n",
    "    train_ds, val_ds = random_split(ds, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=min(batch_size, max(1, len(val_ds))), shuffle=False)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = SimpleCNN(in_channels).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    loss_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)  # logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / max(1, len(train_loader))\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}  AvgLoss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model, train_loader, val_loader, loss_history\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            logits = model(images)\n",
    "            probs = torch.sigmoid(logits).squeeze(1)\n",
    "            preds = (probs > 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    if total == 0:\n",
    "        print(\"No validation samples.\")\n",
    "        return None\n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546edd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping S2B_MSIL2A_20180326T112109_N9999_R037_T29SNB_39_10 due to Unable to allocate 675. KiB for an array with shape (12, 120, 120) and data type float32\n"
     ]
    }
   ],
   "source": [
    "required = ['_B04.tif','_B03.tif','_B02.tif','_B05.tif','_B06.tif','_B07.tif','_B8A.tif','_B08.tif','_B11.tif','_B12.tif']\n",
    "model, train_loader, val_loader, loss_history = train_model(\n",
    "    dataset_path=r\"C:\\Users\\mayer\\Работен плот\\final forest detector\\Big Earth Net Dataset\\BigEarthNet-S2\",\n",
    "    metadata_parquet=r\"C:\\Users\\mayer\\Работен плот\\final forest detector\\metadata.parquet\",\n",
    "    required_bands=required,\n",
    "    num_epochs=15,\n",
    "    batch_size=16,\n",
    "    max_samples_per_class=10  # small for quick test, increase later\n",
    ")\n",
    "evaluate_model(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

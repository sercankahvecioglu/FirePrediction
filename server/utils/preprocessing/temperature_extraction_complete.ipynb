{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017cbdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce6f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set:\n",
      "  XML folder: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "  Output folder: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output\n",
      "  Found 24 XML files to process\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Setup\n",
    "XML_FOLDER_PATH = os.path.join('/Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files')\n",
    "OUTPUT_FOLDER = os.path.join(os.getcwd(), 'temperature_extraction_output')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"  XML folder: {XML_FOLDER_PATH}\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# Check XML files available\n",
    "xml_files = [f for f in os.listdir(XML_FOLDER_PATH) if f.endswith('_inspire.xml')]\n",
    "print(f\"  Found {len(xml_files)} XML files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f63b6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Google Earth Engine...\n",
      "✓ Google Earth Engine initialized successfully!\n",
      "Google Earth Engine is ready for use!\n"
     ]
    }
   ],
   "source": [
    "# Google Earth Engine Authentication and Initialization\n",
    "print(\"Initializing Google Earth Engine...\")\n",
    "\n",
    "try:\n",
    "    # Try to initialize first (if already authenticated)\n",
    "    ee.Initialize()\n",
    "    print(\"✓ Google Earth Engine initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Authentication required. Please follow the authentication process...\")\n",
    "    try:\n",
    "        # If initialization fails, authenticate first\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "        print(\"✓ Google Earth Engine authenticated and initialized successfully!\")\n",
    "    except Exception as auth_error:\n",
    "        print(f\"✗ Authentication failed: {auth_error}\")\n",
    "        print(\"Please ensure you have a Google Earth Engine account and proper permissions.\")\n",
    "        raise\n",
    "\n",
    "print(\"Google Earth Engine is ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0e6fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated temperature datasets configuration:\n",
      "  MODIS_TERRA: MODIS Terra Land Surface Temperature (1km, daily)\n",
      "    Resolution: 1000m\n",
      "    Collection: MODIS/061/MOD11A1\n",
      "    Temperature Band: LST_Day_1km\n",
      "\n",
      "  MODIS_AQUA: MODIS Aqua Land Surface Temperature (1km, daily)\n",
      "    Resolution: 1000m\n",
      "    Collection: MODIS/061/MYD11A1\n",
      "    Temperature Band: LST_Day_1km\n",
      "\n",
      "  LANDSAT8: Landsat 8 Surface Temperature (100m)\n",
      "    Resolution: 100m\n",
      "    Collection: LANDSAT/LC08/C02/T1_L2\n",
      "    Temperature Band: ST_B10\n",
      "\n",
      "  LANDSAT9: Landsat 9 Surface Temperature (100m)\n",
      "    Resolution: 100m\n",
      "    Collection: LANDSAT/LC09/C02/T1_L2\n",
      "    Temperature Band: ST_B10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temperature Dataset Configuration\n",
    "TEMPERATURE_DATASETS = {\n",
    "    \"MODIS_TERRA\": {\n",
    "        \"collection_id\": \"MODIS/061/MOD11A1\",\n",
    "        \"temperature_band\": \"LST_Day_1km\",\n",
    "        \"cloud_mask_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"scale_factor\": 0.02,\n",
    "        \"offset\": 0,\n",
    "        \"description\": \"MODIS Terra Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"MODIS_AQUA\": {\n",
    "        \"collection_id\": \"MODIS/061/MYD11A1\",\n",
    "        \"temperature_band\": \"LST_Day_1km\", \n",
    "        \"cloud_mask_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"scale_factor\": 0.02,\n",
    "        \"offset\": 0,\n",
    "        \"description\": \"MODIS Aqua Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"LANDSAT8\": {\n",
    "        \"collection_id\": \"LANDSAT/LC08/C02/T1_L2\",\n",
    "        \"temperature_band\": \"ST_B10\",\n",
    "        \"cloud_mask_band\": \"QA_PIXEL\",\n",
    "        \"scale\": 100,\n",
    "        \"scale_factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"description\": \"Landsat 8 Surface Temperature (100m)\"\n",
    "    },\n",
    "    \"LANDSAT9\": {\n",
    "        \"collection_id\": \"LANDSAT/LC09/C02/T1_L2\",\n",
    "        \"temperature_band\": \"ST_B10\",\n",
    "        \"cloud_mask_band\": \"QA_PIXEL\", \n",
    "        \"scale\": 100,\n",
    "        \"scale_factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"description\": \"Landsat 9 Surface Temperature (100m)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Updated temperature datasets configuration:\")\n",
    "for key, dataset in TEMPERATURE_DATASETS.items():\n",
    "    print(f\"  {key}: {dataset['description']}\")\n",
    "    print(f\"    Resolution: {dataset['scale']}m\")\n",
    "    print(f\"    Collection: {dataset['collection_id']}\")\n",
    "    print(f\"    Temperature Band: {dataset['temperature_band']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a2a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using XML folder path: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "MetadataExtractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Metadata Extractor Class\n",
    "class MetadataExtractor:\n",
    "    \"\"\"\n",
    "    A robust class to extract essential metadata from Sentinel-2 XML files\n",
    "    for extracting coordinates and temporal information\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, xml_folder_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the MetadataExtractor\n",
    "        \n",
    "        Args:\n",
    "            xml_folder_path (str): Path to the folder containing XML files\n",
    "        \"\"\"\n",
    "        self.xml_folder_path = Path(xml_folder_path)\n",
    "        self.metadata_cache = {}\n",
    "    \n",
    "    def extract_geospatial_metadata(self, country_id, when='pre', resolution=10):\n",
    "        \"\"\"\n",
    "        Extract geospatial metadata from XML files.\n",
    "        \n",
    "        Args:\n",
    "            country_id (str): Country identifier\n",
    "            when (str): Time period identifier ('pre', 'post')\n",
    "            resolution (int): Spatial resolution in meters\n",
    "        \n",
    "        Returns:\n",
    "            dict: Extracted metadata dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        xml_file = self.xml_folder_path / f\"{country_id}_{when}_inspire.xml\"\n",
    "        \n",
    "        # Check if the XML file exists\n",
    "        if not xml_file.exists():\n",
    "            raise FileNotFoundError(f\"XML file not found: {xml_file}\")\n",
    "        \n",
    "        print(f\"Extracting metadata from: {xml_file}\")\n",
    "        \n",
    "        # Parse XML\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Namespaces\n",
    "        ns = {\n",
    "            'gmd': 'http://www.isotc211.org/2005/gmd',\n",
    "            'gco': 'http://www.isotc211.org/2005/gco',\n",
    "            'gml': 'http://www.opengis.net/gml'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Extract product identification\n",
    "            title_elem = root.find('.//gmd:title/gco:CharacterString', ns)\n",
    "            title = title_elem.text if title_elem is not None else \"Unknown\"\n",
    "            \n",
    "            # Extract geographic coordinates\n",
    "            west_elem = root.find('.//gmd:westBoundLongitude/gco:Decimal', ns)\n",
    "            east_elem = root.find('.//gmd:eastBoundLongitude/gco:Decimal', ns)\n",
    "            south_elem = root.find('.//gmd:southBoundLatitude/gco:Decimal', ns)\n",
    "            north_elem = root.find('.//gmd:northBoundLatitude/gco:Decimal', ns)\n",
    "            \n",
    "            west = float(west_elem.text) if west_elem is not None else None\n",
    "            east = float(east_elem.text) if east_elem is not None else None\n",
    "            south = float(south_elem.text) if south_elem is not None else None\n",
    "            north = float(north_elem.text) if north_elem is not None else None\n",
    "            \n",
    "            # Extract temporal information\n",
    "            begin_elem = root.find('.//gml:beginPosition', ns)\n",
    "            end_elem = root.find('.//gml:endPosition', ns)\n",
    "            \n",
    "            begin_time = begin_elem.text if begin_elem is not None else None\n",
    "            end_time = end_elem.text if end_elem is not None else None\n",
    "            \n",
    "            # Extract spatial resolution\n",
    "            resolution_elem = root.find('.//gmd:denominator/gco:Integer', ns)\n",
    "            spatial_resolution = int(resolution_elem.text) if resolution_elem is not None else resolution\n",
    "            \n",
    "            # Extract coordinate reference system\n",
    "            crs_elem = root.find('.//gmd:code/gco:CharacterString', ns)\n",
    "            crs_code = crs_elem.text if crs_elem is not None else \"Unknown\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error extracting some metadata: {e}\")\n",
    "            # Provide default values if extraction fails\n",
    "            title = \"Unknown\"\n",
    "            west = east = south = north = None\n",
    "            begin_time = end_time = None\n",
    "            spatial_resolution = resolution\n",
    "            crs_code = \"Unknown\"\n",
    "        \n",
    "        # Build metadata dictionary\n",
    "        metadata = {\n",
    "            'country_id': country_id,\n",
    "            'time_period': when,\n",
    "            'product_info': {\n",
    "                'title': title,\n",
    "                'file_path': xml_file\n",
    "            },\n",
    "            'spatial_extent': {\n",
    "                'west_bound': west,\n",
    "                'east_bound': east,\n",
    "                'south_bound': south,\n",
    "                'north_bound': north,\n",
    "                'center_lat': (north + south) / 2 if north and south else None,\n",
    "                'center_lon': (east + west) / 2 if east and west else None\n",
    "            },\n",
    "            'temporal_extent': {\n",
    "                'start_time': begin_time,\n",
    "                'end_time': end_time\n",
    "            },\n",
    "            'technical_specs': {\n",
    "                'spatial_resolution': spatial_resolution,\n",
    "                'crs_code': crs_code\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "# Initialize MetadataExtractor\n",
    "print(f\"Using XML folder path: {XML_FOLDER_PATH}\")\n",
    "extractor = MetadataExtractor(XML_FOLDER_PATH)\n",
    "print(\"MetadataExtractor initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae0b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature utility functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Temperature Processing Utility Functions\n",
    "\n",
    "def apply_landsat_temperature_calibration(thermal_band, dataset_config):\n",
    "    \"\"\"\n",
    "    Apply temperature calibration for Landsat thermal bands.\n",
    "    \n",
    "    Args:\n",
    "        thermal_band (ee.Image): Thermal infrared band\n",
    "        dataset_config (dict): Dataset configuration with calibration parameters\n",
    "        \n",
    "    Returns:\n",
    "        ee.Image: Temperature in Celsius\n",
    "    \"\"\"\n",
    "    # Apply scale factor and offset, then convert from Kelvin to Celsius\n",
    "    return thermal_band.multiply(dataset_config[\"scale_factor\"]).add(dataset_config[\"offset\"]).subtract(273.15)\n",
    "\n",
    "def classify_temperature_conditions(temp_celsius):\n",
    "    \"\"\"\n",
    "    Classify temperature conditions for fire risk assessment.\n",
    "    \n",
    "    Args:\n",
    "        temp_celsius (float): Temperature in Celsius\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (risk_level, description)\n",
    "    \"\"\"\n",
    "    if temp_celsius < 15:\n",
    "        return (\"COOL\", \"Cool conditions\")\n",
    "    elif temp_celsius < 25:\n",
    "        return (\"MODERATE\", \"Moderate temperature\")\n",
    "    elif temp_celsius < 35:\n",
    "        return (\"WARM\", \"Warm conditions\")\n",
    "    elif temp_celsius < 45:\n",
    "        return (\"HOT\", \"Hot conditions - Elevated fire risk\")\n",
    "    else:\n",
    "        return (\"EXTREME_HOT\", \"Extreme heat - High fire risk\")\n",
    "\n",
    "def calculate_fire_weather_index(temp_celsius):\n",
    "    \"\"\"\n",
    "    Calculate a simple fire weather index based on temperature.\n",
    "    \n",
    "    Args:\n",
    "        temp_celsius (float): Temperature in Celsius\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (index_value, risk_category)\n",
    "    \"\"\"\n",
    "    # Simplified fire weather index based on temperature\n",
    "    if temp_celsius < 20:\n",
    "        return (1, \"LOW\")\n",
    "    elif temp_celsius < 30:\n",
    "        return (2, \"MODERATE\") \n",
    "    elif temp_celsius < 40:\n",
    "        return (3, \"HIGH\")\n",
    "    else:\n",
    "        return (4, \"EXTREME\")\n",
    "\n",
    "def extract_temperature_statistics(image, geometry, scale):\n",
    "    \"\"\"\n",
    "    Extract temperature statistics from an image over a given geometry.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): Temperature image in Celsius\n",
    "        geometry (ee.Geometry): Area of interest\n",
    "        scale (int): Scale for reduction in meters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Temperature statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract comprehensive statistics\n",
    "        stats = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(\n",
    "                ee.Reducer.minMax(), outputPrefix='', sharedInputs=True\n",
    "            ).combine(\n",
    "                ee.Reducer.stdDev(), outputPrefix='', sharedInputs=True\n",
    "            ).combine(\n",
    "                ee.Reducer.count(), outputPrefix='', sharedInputs=True\n",
    "            ),\n",
    "            geometry=geometry,\n",
    "            scale=scale,\n",
    "            maxPixels=1e9,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        \n",
    "        return stats.getInfo()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting temperature statistics: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Temperature utility functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2afa07ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature extraction function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Main Temperature Data Extraction Function\n",
    "\n",
    "def extract_temperature_for_metadata(metadata, datasets=None, day_tolerance=1):\n",
    "    \"\"\"\n",
    "    Extract temperature data for given metadata from multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "        metadata (dict): Metadata containing spatial and temporal extents\n",
    "        datasets (list): List of dataset names to use (None = all available)\n",
    "        day_tolerance (int): Number of days tolerance around target date\n",
    "        \n",
    "    Returns:\n",
    "        dict: Temperature data results for all datasets\n",
    "    \"\"\"\n",
    "    if datasets is None:\n",
    "        datasets = list(TEMPERATURE_DATASETS.keys())\n",
    "    \n",
    "    # Extract spatial extent\n",
    "    west = metadata['spatial_extent']['west_bound']\n",
    "    east = metadata['spatial_extent']['east_bound'] \n",
    "    south = metadata['spatial_extent']['south_bound']\n",
    "    north = metadata['spatial_extent']['north_bound']\n",
    "    \n",
    "    # Create geometry\n",
    "    geometry = ee.Geometry.Rectangle([west, south, east, north])\n",
    "    \n",
    "    # Extract target date\n",
    "    start_time = metadata['temporal_extent']['start_time']\n",
    "    if start_time:\n",
    "        target_date = dt.datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n",
    "    else:\n",
    "        print(\"Warning: No start time found in metadata, using default date\")\n",
    "        target_date = dt.datetime(2022, 7, 17)  # Default date\n",
    "    \n",
    "    # Define date range with tolerance\n",
    "    start_date = target_date - dt.timedelta(days=day_tolerance)\n",
    "    end_date = target_date + dt.timedelta(days=day_tolerance + 1)\n",
    "    \n",
    "    print(f\"Extracting temperature data for {metadata['country_id']} {metadata['time_period']}:\")\n",
    "    print(f\"  Area: {west:.3f}, {south:.3f} to {east:.3f}, {north:.3f}\")\n",
    "    print(f\"  Target date: {target_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    results = {\n",
    "        \"metadata\": metadata,\n",
    "        \"date\": target_date.strftime('%Y-%m-%d'),\n",
    "        \"satellite_acquisition_date\": target_date.strftime('%Y-%m-%d'),\n",
    "        \"coordinates\": {\n",
    "            \"west\": west, \"east\": east,\n",
    "            \"south\": south, \"north\": north\n",
    "        },\n",
    "        \"temperature_data\": {}\n",
    "    }\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        try:\n",
    "            ds = TEMPERATURE_DATASETS[dataset_name]\n",
    "            \n",
    "            # Load collection\n",
    "            collection = ee.ImageCollection(ds[\"id\"])\n",
    "            \n",
    "            # Filter by date and location\n",
    "            filtered = collection.filterDate(\n",
    "                start_date.strftime('%Y-%m-%d'),\n",
    "                end_date.strftime('%Y-%m-%d')\n",
    "            ).filterBounds(geometry)\n",
    "            \n",
    "            # Check if any images are available\n",
    "            count = filtered.size().getInfo()\n",
    "            if count == 0:\n",
    "                results[\"temperature_data\"][dataset_name] = {\n",
    "                    \"error\": f\"No images available for the specified date range\"\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            # Get mean image over the time period\n",
    "            mean_image = filtered.mean()\n",
    "            \n",
    "            # Apply cloud masking\n",
    "            masked_image = apply_cloud_mask(mean_image, dataset_name)\n",
    "            \n",
    "            # Convert to Celsius\n",
    "            temperature_celsius = convert_to_celsius(masked_image, dataset_name)\n",
    "            \n",
    "            # Extract temperature statistics\n",
    "            stats = extract_temperature_statistics(temperature_celsius, geometry, ds[\"scale\"])\n",
    "            \n",
    "            if stats:\n",
    "                band_name = ds[\"band\"]\n",
    "                temp_mean = stats.get(f'{band_name}_mean')\n",
    "                temp_min = stats.get(f'{band_name}_min')\n",
    "                temp_max = stats.get(f'{band_name}_max')\n",
    "                temp_std = stats.get(f'{band_name}_stdDev')\n",
    "                pixel_count = stats.get(f'{band_name}_count')\n",
    "                \n",
    "                if temp_mean is not None:\n",
    "                    # Classify temperature conditions\n",
    "                    risk_level, risk_desc = classify_temperature_conditions(temp_mean)\n",
    "                    fire_index, fire_risk = calculate_fire_weather_index(temp_mean)\n",
    "                    \n",
    "                    results[\"temperature_data\"][dataset_name] = {\n",
    "                        \"temperature_mean_C\": temp_mean,\n",
    "                        \"temperature_min_C\": temp_min,\n",
    "                        \"temperature_max_C\": temp_max,\n",
    "                        \"temperature_stdDev_C\": temp_std,\n",
    "                        \"temperature_range_C\": temp_max - temp_min if temp_max and temp_min else None,\n",
    "                        \"pixel_count\": pixel_count,\n",
    "                        \"scale_m\": ds[\"scale\"],\n",
    "                        \"temperature_classification\": risk_level,\n",
    "                        \"temperature_description\": risk_desc,\n",
    "                        \"fire_weather_index\": fire_index,\n",
    "                        \"fire_risk_level\": fire_risk,\n",
    "                        \"image_count\": count\n",
    "                    }\n",
    "                else:\n",
    "                    results[\"temperature_data\"][dataset_name] = {\n",
    "                        \"error\": \"Failed to extract valid temperature statistics\"\n",
    "                    }\n",
    "            else:\n",
    "                results[\"temperature_data\"][dataset_name] = {\n",
    "                    \"error\": \"Failed to extract temperature statistics\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"temperature_data\"][dataset_name] = {\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Temperature extraction function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af403134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XML file discovery function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# XML File Discovery Function\n",
    "\n",
    "def find_xml_files(xml_folder):\n",
    "    \"\"\"\n",
    "    Find all XML files in the specified folder and subfolders.\n",
    "    \n",
    "    Args:\n",
    "        xml_folder (str): Path to the folder containing XML files\n",
    "        \n",
    "    Returns:\n",
    "        list: List of absolute paths to XML files\n",
    "    \"\"\"\n",
    "    xml_files = []\n",
    "    xml_folder_path = Path(xml_folder)\n",
    "    \n",
    "    if not xml_folder_path.exists():\n",
    "        print(f\"❌ XML folder does not exist: {xml_folder}\")\n",
    "        return xml_files\n",
    "    \n",
    "    # Search for XML files recursively\n",
    "    for xml_file in xml_folder_path.rglob(\"*.xml\"):\n",
    "        xml_files.append(str(xml_file.absolute()))\n",
    "    \n",
    "    # Sort files for consistent processing order\n",
    "    xml_files.sort()\n",
    "    \n",
    "    print(f\"🔍 Found {len(xml_files)} XML files:\")\n",
    "    for i, xml_file in enumerate(xml_files[:5], 1):  # Show first 5\n",
    "        print(f\"   {i}. {os.path.basename(xml_file)}\")\n",
    "    if len(xml_files) > 5:\n",
    "        print(f\"   ... and {len(xml_files) - 5} more files\")\n",
    "    \n",
    "    return xml_files\n",
    "\n",
    "print(\"XML file discovery function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee7cde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main temperature extraction function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Main Temperature Data Extraction Function\n",
    "\n",
    "def extract_temperature_data(xml_file_path):\n",
    "    \"\"\"\n",
    "    Extract temperature data from satellite datasets for a given XML metadata file.\n",
    "    \n",
    "    Args:\n",
    "        xml_file_path (str): Path to the XML metadata file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Complete extraction results including metadata and temperature data\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    result = {\n",
    "        'processing_info': {\n",
    "            'xml_file': os.path.basename(xml_file_path),\n",
    "            'country': 'Unknown',\n",
    "            'time_period': 'Unknown',\n",
    "            'processing_start_time': datetime.datetime.now().isoformat()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract metadata from XML\n",
    "        metadata = parse_xml_filename_and_extract_metadata(xml_file_path)\n",
    "        if not metadata:\n",
    "            raise Exception(\"Failed to extract metadata from XML file\")\n",
    "        \n",
    "        result['metadata'] = metadata\n",
    "        \n",
    "        # Extract location info from filename\n",
    "        filename = os.path.basename(xml_file_path)\n",
    "        if 'chile' in filename.lower():\n",
    "            result['processing_info']['country'] = 'Chile'\n",
    "        elif 'france' in filename.lower():\n",
    "            result['processing_info']['country'] = 'France'\n",
    "        \n",
    "        if 'pre' in filename.lower():\n",
    "            result['processing_info']['time_period'] = 'Pre-Fire'\n",
    "        elif 'post' in filename.lower():\n",
    "            result['processing_info']['time_period'] = 'Post-Fire'\n",
    "        \n",
    "        # Step 2: Extract satellite acquisition date\n",
    "        if 'temporal_extent' in metadata:\n",
    "            start_time_str = metadata['temporal_extent'].get('start_time', '')\n",
    "            if start_time_str:\n",
    "                # Parse date from start time\n",
    "                try:\n",
    "                    start_date = datetime.datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))\n",
    "                    result['satellite_acquisition_date'] = start_date.strftime('%Y-%m-%d')\n",
    "                except:\n",
    "                    result['satellite_acquisition_date'] = start_time_str\n",
    "        \n",
    "        # Step 3: Extract temperature data from all datasets\n",
    "        result['temperature_data'] = {}\n",
    "        \n",
    "        for dataset_name, dataset_config in TEMPERATURE_DATASETS.items():\n",
    "            print(f\"  📡 Processing {dataset_name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Extract spatial extent\n",
    "                spatial = metadata['spatial_extent']\n",
    "                west = spatial['west_bound']\n",
    "                east = spatial['east_bound']\n",
    "                south = spatial['south_bound'] \n",
    "                north = spatial['north_bound']\n",
    "                \n",
    "                # Create geometry\n",
    "                geometry = ee.Geometry.Rectangle([west, south, east, north])\n",
    "                \n",
    "                # Get temporal extent\n",
    "                temporal = metadata['temporal_extent']\n",
    "                start_date = temporal['start_time']\n",
    "                end_date = temporal['end_time']\n",
    "                \n",
    "                # Parse dates for GEE\n",
    "                try:\n",
    "                    if 'T' in start_date:\n",
    "                        start_date = start_date.split('T')[0]\n",
    "                    if 'T' in end_date:\n",
    "                        end_date = end_date.split('T')[0]\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                # Get image collection with date filter\n",
    "                collection = ee.ImageCollection(dataset_config['collection_id'])\n",
    "                \n",
    "                # Apply date filter with some tolerance\n",
    "                date_filtered = collection.filterDate(\n",
    "                    ee.Date(start_date).advance(-7, 'day'),\n",
    "                    ee.Date(end_date).advance(7, 'day')\n",
    "                )\n",
    "                \n",
    "                # Filter by geometry\n",
    "                geo_filtered = date_filtered.filterBounds(geometry)\n",
    "                \n",
    "                # Get the closest image to start date\n",
    "                target_date = ee.Date(start_date)\n",
    "                def add_time_difference(image):\n",
    "                    return image.set('time_diff', \n",
    "                        ee.Number(image.get('system:time_start')).subtract(target_date.millis()).abs())\n",
    "                \n",
    "                with_time_diff = geo_filtered.map(add_time_difference)\n",
    "                closest_image = with_time_diff.sort('time_diff').first()\n",
    "                \n",
    "                # Get temperature band\n",
    "                temp_band = closest_image.select(dataset_config['temperature_band'])\n",
    "                \n",
    "                # Apply temperature conversion\n",
    "                if dataset_name.startswith('MODIS'):\n",
    "                    # MODIS: Kelvin to Celsius\n",
    "                    temp_celsius = temp_band.multiply(dataset_config['scale_factor']).subtract(273.15)\n",
    "                else:\n",
    "                    # Landsat: Apply calibration\n",
    "                    temp_celsius = apply_landsat_temperature_calibration(temp_band, dataset_config)\n",
    "                \n",
    "                # Apply cloud masking if available\n",
    "                if 'cloud_mask_band' in dataset_config:\n",
    "                    try:\n",
    "                        cloud_mask = closest_image.select(dataset_config['cloud_mask_band'])\n",
    "                        # Simple cloud mask - remove pixels with high cloud probability\n",
    "                        clean_mask = cloud_mask.lt(50)  # Less than 50% cloud probability\n",
    "                        temp_celsius = temp_celsius.updateMask(clean_mask)\n",
    "                    except:\n",
    "                        pass  # Continue without cloud masking if it fails\n",
    "                \n",
    "                # Extract temperature statistics\n",
    "                stats = temp_celsius.reduceRegion(\n",
    "                    reducer=ee.Reducer.mean().combine(\n",
    "                        ee.Reducer.minMax(), outputPrefix='', sharedInputs=True\n",
    "                    ).combine(\n",
    "                        ee.Reducer.stdDev(), outputPrefix='', sharedInputs=True\n",
    "                    ).combine(\n",
    "                        ee.Reducer.count(), outputPrefix='', sharedInputs=True\n",
    "                    ),\n",
    "                    geometry=geometry,\n",
    "                    scale=dataset_config['scale'],\n",
    "                    maxPixels=1e9,\n",
    "                    bestEffort=True\n",
    "                ).getInfo()\n",
    "                \n",
    "                # Process statistics\n",
    "                temp_mean = stats.get(f'{dataset_config[\"temperature_band\"]}_mean')\n",
    "                temp_min = stats.get(f'{dataset_config[\"temperature_band\"]}_min')\n",
    "                temp_max = stats.get(f'{dataset_config[\"temperature_band\"]}_max')\n",
    "                temp_stddev = stats.get(f'{dataset_config[\"temperature_band\"]}_stdDev')\n",
    "                pixel_count = stats.get(f'{dataset_config[\"temperature_band\"]}_count')\n",
    "                \n",
    "                if temp_mean is not None and temp_mean > -50:  # Reasonable temperature check\n",
    "                    # Calculate additional metrics\n",
    "                    temp_range = temp_max - temp_min if temp_max and temp_min else None\n",
    "                    \n",
    "                    # Classify temperature\n",
    "                    temp_class, temp_desc = classify_temperature_conditions(temp_mean)\n",
    "                    fire_index, fire_risk = calculate_fire_weather_index(temp_mean)\n",
    "                    \n",
    "                    # Count images in collection\n",
    "                    image_count = geo_filtered.size().getInfo()\n",
    "                    \n",
    "                    result['temperature_data'][dataset_name] = {\n",
    "                        'temperature_mean_C': round(temp_mean, 2),\n",
    "                        'temperature_min_C': round(temp_min, 2) if temp_min is not None else None,\n",
    "                        'temperature_max_C': round(temp_max, 2) if temp_max is not None else None,\n",
    "                        'temperature_stdDev_C': round(temp_stddev, 2) if temp_stddev is not None else None,\n",
    "                        'temperature_range_C': round(temp_range, 2) if temp_range is not None else None,\n",
    "                        'temperature_classification': temp_class,\n",
    "                        'temperature_description': temp_desc,\n",
    "                        'fire_weather_index': fire_index,\n",
    "                        'fire_risk_level': fire_risk,\n",
    "                        'pixel_count': pixel_count,\n",
    "                        'image_count': image_count,\n",
    "                        'scale_m': dataset_config['scale']\n",
    "                    }\n",
    "                    print(f\"    ✅ Success: {temp_mean:.1f}°C ({temp_class})\")\n",
    "                    \n",
    "                else:\n",
    "                    result['temperature_data'][dataset_name] = {\n",
    "                        'error': 'No valid temperature data extracted'\n",
    "                    }\n",
    "                    print(f\"    ❌ No valid data\")\n",
    "                    \n",
    "            except Exception as dataset_error:\n",
    "                result['temperature_data'][dataset_name] = {\n",
    "                    'error': str(dataset_error)\n",
    "                }\n",
    "                print(f\"    ❌ Error: {dataset_error}\")\n",
    "        \n",
    "        # Calculate processing time\n",
    "        processing_time = time.time() - start_time\n",
    "        result['processing_info']['processing_time_seconds'] = round(processing_time, 2)\n",
    "        result['processing_info']['processing_end_time'] = datetime.datetime.now().isoformat()\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Failed to process {os.path.basename(xml_file_path)}: {str(e)}\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        result['error'] = error_msg\n",
    "        result['processing_info']['processing_time_seconds'] = time.time() - start_time\n",
    "        result['processing_info']['processing_end_time'] = datetime.datetime.now().isoformat()\n",
    "        return result\n",
    "\n",
    "print(\"Main temperature extraction function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98a8afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Batch Processing Function for All XML Files\n",
    "\n",
    "def process_all_xml_files(xml_files):\n",
    "    \"\"\"\n",
    "    Process all XML files for temperature extraction.\n",
    "    \n",
    "    Args:\n",
    "        xml_files (list): List of XML file paths to process\n",
    "        \n",
    "    Returns:\n",
    "        list: List of extraction results for all files\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    total_files = len(xml_files)\n",
    "    \n",
    "    print(f\"🔄 Processing {total_files} XML files...\")\n",
    "    \n",
    "    for i, xml_file in enumerate(xml_files, 1):\n",
    "        print(f\"\\n--- Processing {i}/{total_files}: {os.path.basename(xml_file)} ---\")\n",
    "        \n",
    "        try:\n",
    "            result = extract_temperature_data(xml_file)\n",
    "            all_results.append(result)\n",
    "            \n",
    "            # Quick status report\n",
    "            if 'error' in result:\n",
    "                print(f\"   ❌ Failed: {result['error']}\")\n",
    "            else:\n",
    "                successful_datasets = sum(1 for data in result['temperature_data'].values() if 'error' not in data)\n",
    "                total_datasets = len(result['temperature_data'])\n",
    "                print(f\"   ✅ Success: {successful_datasets}/{total_datasets} datasets extracted\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_result = {\n",
    "                'processing_info': {\n",
    "                    'xml_file': os.path.basename(xml_file),\n",
    "                    'country': 'Unknown',\n",
    "                    'time_period': 'Unknown',\n",
    "                    'processing_start_time': datetime.datetime.now().isoformat()\n",
    "                },\n",
    "                'error': f\"Unexpected error: {str(e)}\"\n",
    "            }\n",
    "            all_results.append(error_result)\n",
    "            print(f\"   ❌ Unexpected error: {e}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"Batch processing function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2249e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel export function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Excel Export Functionality\n",
    "\n",
    "def create_excel_export(all_results, output_filename=\"temperature_data_extraction_complete.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create a comprehensive Excel export of all temperature data extractions.\n",
    "    \n",
    "    Args:\n",
    "        all_results (list): List of all temperature extraction results\n",
    "        output_filename (str): Name of the output Excel file\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, output_filename)\n",
    "    \n",
    "    # Create Excel writer object\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        \n",
    "        # ========== SUMMARY SHEET ==========\n",
    "        summary_data = []\n",
    "        for result in all_results:\n",
    "            if 'error' in result:\n",
    "                summary_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                    'Processing_Status': 'FAILED',\n",
    "                    'Error_Message': result.get('error', 'Unknown error'),\n",
    "                    'MODIS_Terra_Temp_C': 'N/A',\n",
    "                    'MODIS_Aqua_Temp_C': 'N/A',\n",
    "                    'Landsat8_Temp_C': 'N/A',\n",
    "                    'Landsat9_Temp_C': 'N/A',\n",
    "                    'Average_Temperature_C': 'N/A',\n",
    "                    'Max_Temperature_C': 'N/A',\n",
    "                    'Temperature_Classification': 'N/A',\n",
    "                    'Fire_Risk_Level': 'N/A'\n",
    "                })\n",
    "            else:\n",
    "                temp_data = result['temperature_data']\n",
    "                \n",
    "                # Extract temperatures for each dataset\n",
    "                modis_terra_temp = temp_data.get('MODIS_TERRA', {}).get('temperature_mean_C', 'N/A')\n",
    "                modis_aqua_temp = temp_data.get('MODIS_AQUA', {}).get('temperature_mean_C', 'N/A')\n",
    "                landsat8_temp = temp_data.get('LANDSAT8', {}).get('temperature_mean_C', 'N/A')\n",
    "                landsat9_temp = temp_data.get('LANDSAT9', {}).get('temperature_mean_C', 'N/A')\n",
    "                \n",
    "                # Calculate average temperature from successful extractions\n",
    "                temps = []\n",
    "                max_temps = []\n",
    "                for dataset in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "                    if dataset in temp_data and 'error' not in temp_data[dataset]:\n",
    "                        temp = temp_data[dataset].get('temperature_mean_C')\n",
    "                        max_temp = temp_data[dataset].get('temperature_max_C')\n",
    "                        if temp is not None and temp > -50:  # Reasonable temperature check\n",
    "                            temps.append(temp)\n",
    "                        if max_temp is not None and max_temp > -50:\n",
    "                            max_temps.append(max_temp)\n",
    "                \n",
    "                avg_temp = sum(temps) / len(temps) if temps else 0\n",
    "                max_temp = max(max_temps) if max_temps else 0\n",
    "                \n",
    "                # Get temperature classification (prioritize MODIS data)\n",
    "                temp_classification = 'N/A'\n",
    "                fire_risk = 'N/A'\n",
    "                for dataset in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "                    if dataset in temp_data and 'error' not in temp_data[dataset]:\n",
    "                        temp_classification = temp_data[dataset].get('temperature_classification', 'N/A')\n",
    "                        fire_risk = temp_data[dataset].get('fire_risk_level', 'N/A')\n",
    "                        if temp_classification != 'N/A':\n",
    "                            break\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                    'Processing_Status': 'SUCCESS',\n",
    "                    'Error_Message': '',\n",
    "                    'MODIS_Terra_Temp_C': modis_terra_temp if modis_terra_temp != 'N/A' else '',\n",
    "                    'MODIS_Aqua_Temp_C': modis_aqua_temp if modis_aqua_temp != 'N/A' else '',\n",
    "                    'Landsat8_Temp_C': landsat8_temp if landsat8_temp != 'N/A' else '',\n",
    "                    'Landsat9_Temp_C': landsat9_temp if landsat9_temp != 'N/A' else '',\n",
    "                    'Average_Temperature_C': round(avg_temp, 2) if avg_temp > 0 else '',\n",
    "                    'Max_Temperature_C': round(max_temp, 2) if max_temp > 0 else '',\n",
    "                    'Temperature_Classification': temp_classification,\n",
    "                    'Fire_Risk_Level': fire_risk\n",
    "                })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        \n",
    "        # ========== DETAILED SHEETS ==========\n",
    "        \n",
    "        # Create detailed sheets for each dataset\n",
    "        for dataset_key in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "            dataset_data = []\n",
    "            for result in all_results:\n",
    "                if 'temperature_data' in result and dataset_key in result['temperature_data']:\n",
    "                    data = result['temperature_data'][dataset_key]\n",
    "                    if 'error' not in data:\n",
    "                        dataset_data.append({\n",
    "                            'Country': result['processing_info']['country'],\n",
    "                            'Time_Period': result['processing_info']['time_period'],\n",
    "                            'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                            'Temperature_Mean_C': data.get('temperature_mean_C', ''),\n",
    "                            'Temperature_Min_C': data.get('temperature_min_C', ''),\n",
    "                            'Temperature_Max_C': data.get('temperature_max_C', ''),\n",
    "                            'Temperature_StdDev_C': data.get('temperature_stdDev_C', ''),\n",
    "                            'Temperature_Range_C': data.get('temperature_range_C', ''),\n",
    "                            'Temperature_Classification': data.get('temperature_classification', ''),\n",
    "                            'Fire_Weather_Index': data.get('fire_weather_index', ''),\n",
    "                            'Fire_Risk_Level': data.get('fire_risk_level', ''),\n",
    "                            'Pixel_Count': data.get('pixel_count', ''),\n",
    "                            'Image_Count': data.get('image_count', ''),\n",
    "                            'Resolution_m': data.get('scale_m', '')\n",
    "                        })\n",
    "            \n",
    "            if dataset_data:\n",
    "                dataset_df = pd.DataFrame(dataset_data)\n",
    "                sheet_name = f'{dataset_key}_Details'\n",
    "                dataset_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        \n",
    "        # ========== ERROR LOG SHEET ==========\n",
    "        error_data = []\n",
    "        for result in all_results:\n",
    "            if 'error' in result:\n",
    "                error_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'XML_File': result['processing_info']['xml_file'],\n",
    "                    'Error_Type': 'Complete Failure',\n",
    "                    'Error_Message': result.get('error', 'Unknown error')\n",
    "                })\n",
    "            elif 'temperature_data' in result:\n",
    "                # Check for dataset-specific errors\n",
    "                for dataset, data in result['temperature_data'].items():\n",
    "                    if 'error' in data:\n",
    "                        error_data.append({\n",
    "                            'Country': result['processing_info']['country'],\n",
    "                            'Time_Period': result['processing_info']['time_period'],\n",
    "                            'XML_File': result['processing_info']['xml_file'],\n",
    "                            'Error_Type': f'{dataset} Dataset Error',\n",
    "                            'Error_Message': data['error']\n",
    "                        })\n",
    "        \n",
    "        if error_data:\n",
    "            error_df = pd.DataFrame(error_data)\n",
    "            error_df.to_excel(writer, sheet_name='Error_Log', index=False)\n",
    "        \n",
    "        # ========== METADATA SHEET ==========\n",
    "        metadata_data = []\n",
    "        for result in all_results:\n",
    "            if 'metadata' in result:\n",
    "                metadata = result['metadata']\n",
    "                spatial = metadata.get('spatial_extent', {})\n",
    "                temporal = metadata.get('temporal_extent', {})\n",
    "                technical = metadata.get('technical_specs', {})\n",
    "                \n",
    "                metadata_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Product_Title': metadata.get('product_info', {}).get('title', ''),\n",
    "                    'West_Bound_Longitude': spatial.get('west_bound', ''),\n",
    "                    'East_Bound_Longitude': spatial.get('east_bound', ''),\n",
    "                    'South_Bound_Latitude': spatial.get('south_bound', ''),\n",
    "                    'North_Bound_Latitude': spatial.get('north_bound', ''),\n",
    "                    'Center_Latitude': spatial.get('center_lat', ''),\n",
    "                    'Center_Longitude': spatial.get('center_lon', ''),\n",
    "                    'Start_Time': temporal.get('start_time', ''),\n",
    "                    'End_Time': temporal.get('end_time', ''),\n",
    "                    'Spatial_Resolution_m': technical.get('spatial_resolution', ''),\n",
    "                    'CRS_Code': technical.get('crs_code', '')\n",
    "                })\n",
    "        \n",
    "        if metadata_data:\n",
    "            metadata_df = pd.DataFrame(metadata_data)\n",
    "            metadata_df.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "    \n",
    "    print(f\"\\n📊 Excel file created: {output_path}\")\n",
    "    print(f\"📋 Sheets included:\")\n",
    "    print(f\"   - Summary: Overview of all extractions\")\n",
    "    print(f\"   - MODIS_TERRA_Details: Detailed MODIS Terra temperature data\")\n",
    "    print(f\"   - MODIS_AQUA_Details: Detailed MODIS Aqua temperature data\")\n",
    "    print(f\"   - LANDSAT8_Details: Detailed Landsat 8 temperature data\")\n",
    "    print(f\"   - LANDSAT9_Details: Detailed Landsat 9 temperature data\")\n",
    "    print(f\"   - Error_Log: Failed extractions and errors\")\n",
    "    print(f\"   - Metadata: Spatial and temporal metadata\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"Excel export function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de99e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main execution pipeline defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Main Execution Pipeline - Complete Temperature Extraction\n",
    "\n",
    "def main_temperature_extraction():\n",
    "    \"\"\"\n",
    "    Execute the complete temperature extraction pipeline for all XML files.\n",
    "    This is the main function that orchestrates the entire process.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"🚀 Starting Complete Temperature Extraction Pipeline\")\n",
    "    print(f\"⏰ Start Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📁 Looking for XML files in: {XML_FOLDER_PATH}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Step 1: Find all XML files\n",
    "    xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "    if not xml_files:\n",
    "        print(\"❌ No XML files found! Please check the XML folder path.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"📄 Found {len(xml_files)} XML files to process\")\n",
    "    \n",
    "    # Step 2: Process all XML files in batch\n",
    "    print(f\"\\n🔄 Starting batch temperature extraction...\")\n",
    "    all_results = process_all_xml_files(xml_files)\n",
    "    \n",
    "    # Step 3: Create Excel export\n",
    "    print(f\"\\n📊 Creating Excel export...\")\n",
    "    excel_path = create_excel_export(all_results)\n",
    "    \n",
    "    # Step 4: Summary statistics\n",
    "    successful_extractions = [r for r in all_results if 'error' not in r]\n",
    "    failed_extractions = [r for r in all_results if 'error' in r]\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"📋 EXTRACTION COMPLETE - SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"📄 Total XML files processed: {len(xml_files)}\")\n",
    "    print(f\"✅ Successful extractions: {len(successful_extractions)}\")\n",
    "    print(f\"❌ Failed extractions: {len(failed_extractions)}\")\n",
    "    print(f\"📊 Excel file created: {excel_path}\")\n",
    "    print(f\"⏱️  Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"⏰ End Time: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Dataset-specific success rates\n",
    "    if successful_extractions:\n",
    "        print(f\"\\n📊 Dataset Success Rates:\")\n",
    "        datasets = ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']\n",
    "        for dataset in datasets:\n",
    "            successful_dataset = 0\n",
    "            for result in successful_extractions:\n",
    "                if dataset in result.get('temperature_data', {}) and 'error' not in result['temperature_data'][dataset]:\n",
    "                    successful_dataset += 1\n",
    "            success_rate = (successful_dataset / len(successful_extractions)) * 100\n",
    "            print(f\"   - {dataset}: {successful_dataset}/{len(successful_extractions)} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    if failed_extractions:\n",
    "        print(f\"\\n❌ Failed Extractions Details:\")\n",
    "        for result in failed_extractions:\n",
    "            country = result['processing_info']['country']\n",
    "            period = result['processing_info']['time_period']\n",
    "            error = result.get('error', 'Unknown error')\n",
    "            print(f\"   - {country} {period}: {error}\")\n",
    "    \n",
    "    print(\"\\n🎉 Temperature extraction pipeline completed successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return {\n",
    "        'total_files': len(xml_files),\n",
    "        'successful_extractions': len(successful_extractions),\n",
    "        'failed_extractions': len(failed_extractions),\n",
    "        'excel_path': excel_path,\n",
    "        'processing_time_seconds': total_time,\n",
    "        'results': all_results\n",
    "    }\n",
    "\n",
    "print(\"Main execution pipeline defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edc687ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Running test extraction with first 3 XML files...\n",
      "🧪 TESTING: Processing first 3 XML files\n",
      "============================================================\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "📄 Testing with files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "\n",
      "🔄 Processing test files...\n",
      "\n",
      "--- Processing 1/3: chile_post_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_post_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: Extracted temperature data for 4 datasets\n",
      "\n",
      "--- Processing 2/3: chile_post_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_post_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: Extracted temperature data for 4 datasets\n",
      "\n",
      "--- Processing 3/3: chile_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_pre_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 34.9°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: Extracted temperature data for 4 datasets\n",
      "\n",
      "📊 Excel file created: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_test_extraction_20250811_081612.xlsx\n",
      "📋 Sheets included:\n",
      "   - Summary: Overview of all extractions\n",
      "   - MODIS_TERRA_Details: Detailed MODIS Terra temperature data\n",
      "   - MODIS_AQUA_Details: Detailed MODIS Aqua temperature data\n",
      "   - LANDSAT8_Details: Detailed Landsat 8 temperature data\n",
      "   - LANDSAT9_Details: Detailed Landsat 9 temperature data\n",
      "   - Error_Log: Failed extractions and errors\n",
      "   - Metadata: Spatial and temporal metadata\n",
      "\n",
      "📊 TEST SUMMARY:\n",
      "   ✅ Successful: 3/3\n",
      "   ❌ Failed: 0/3\n",
      "   📄 Test Excel: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_test_extraction_20250811_081612.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Test Run - Process First 3 XML Files for Validation\n",
    "\n",
    "def test_temperature_extraction(num_files=3):\n",
    "    \"\"\"\n",
    "    Test the temperature extraction pipeline with a limited number of files.\n",
    "    \n",
    "    Args:\n",
    "        num_files (int): Number of XML files to process for testing\n",
    "    \"\"\"\n",
    "    print(f\"🧪 TESTING: Processing first {num_files} XML files\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Find XML files\n",
    "    xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "    if not xml_files:\n",
    "        print(\"❌ No XML files found!\")\n",
    "        return None\n",
    "    \n",
    "    # Limit to test files\n",
    "    test_files = xml_files[:num_files]\n",
    "    print(f\"📄 Testing with files:\")\n",
    "    for i, file_path in enumerate(test_files, 1):\n",
    "        print(f\"   {i}. {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Process test files\n",
    "    print(f\"\\n🔄 Processing test files...\")\n",
    "    test_results = []\n",
    "    \n",
    "    for i, xml_file in enumerate(test_files, 1):\n",
    "        print(f\"\\n--- Processing {i}/{len(test_files)}: {os.path.basename(xml_file)} ---\")\n",
    "        result = extract_temperature_data(xml_file)\n",
    "        test_results.append(result)\n",
    "        \n",
    "        # Quick status check\n",
    "        if 'error' in result:\n",
    "            print(f\"   ❌ Failed: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"   ✅ Success: Extracted temperature data for {len(result['temperature_data'])} datasets\")\n",
    "    \n",
    "    # Create test Excel export\n",
    "    test_excel_name = f\"temperature_test_extraction_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "    excel_path = create_excel_export(test_results, test_excel_name)\n",
    "    \n",
    "    # Test summary\n",
    "    successful = [r for r in test_results if 'error' not in r]\n",
    "    failed = [r for r in test_results if 'error' in r]\n",
    "    \n",
    "    print(f\"\\n📊 TEST SUMMARY:\")\n",
    "    print(f\"   ✅ Successful: {len(successful)}/{len(test_results)}\")\n",
    "    print(f\"   ❌ Failed: {len(failed)}/{len(test_results)}\")\n",
    "    print(f\"   📄 Test Excel: {excel_path}\")\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# Run the test\n",
    "print(\"🧪 Running test extraction with first 3 XML files...\")\n",
    "test_results = test_temperature_extraction(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "202693c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available methods on extractor:\n",
      "['extract_geospatial_metadata', 'metadata_cache', 'xml_folder_path']\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "\n",
      "Testing with: chile_post_inspire.xml\n",
      "❌ Method not found: extract_metadata\n",
      "❌ Method not found: parse_metadata\n",
      "❌ Method not found: get_metadata\n",
      "❌ Method not found: extract\n",
      "❌ Method not found: parse\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check MetadataExtractor methods\n",
    "\n",
    "print(\"Available methods on extractor:\")\n",
    "print([method for method in dir(extractor) if not method.startswith('_')])\n",
    "\n",
    "# Test a single XML file to see what methods work\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "if xml_files:\n",
    "    test_xml = xml_files[0]\n",
    "    print(f\"\\nTesting with: {os.path.basename(test_xml)}\")\n",
    "    \n",
    "    # Try different method names\n",
    "    methods_to_try = ['extract_metadata', 'parse_metadata', 'get_metadata', 'extract', 'parse']\n",
    "    for method_name in methods_to_try:\n",
    "        if hasattr(extractor, method_name):\n",
    "            print(f\"✅ Found method: {method_name}\")\n",
    "            try:\n",
    "                result = getattr(extractor, method_name)(test_xml)\n",
    "                print(f\"   Method works, returned: {type(result)}\")\n",
    "                if isinstance(result, dict):\n",
    "                    print(f\"   Keys: {list(result.keys())}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"   Method failed: {e}\")\n",
    "        else:\n",
    "            print(f\"❌ Method not found: {method_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bee5c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing single file extraction...\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "Testing: chile_post_inspire.xml\n",
      "❌ Test failed: XML file not found: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml_pre_inspire.xml\n"
     ]
    }
   ],
   "source": [
    "# Test Single File Extraction\n",
    "\n",
    "print(\"🧪 Testing single file extraction...\")\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "if xml_files:\n",
    "    test_file = xml_files[0]\n",
    "    print(f\"Testing: {os.path.basename(test_file)}\")\n",
    "    \n",
    "    try:\n",
    "        # Test metadata extraction\n",
    "        metadata = extractor.extract_geospatial_metadata(test_file)\n",
    "        if metadata:\n",
    "            print(\"✅ Metadata extraction successful!\")\n",
    "            print(f\"   Spatial extent keys: {list(metadata.get('spatial_extent', {}).keys())}\")\n",
    "            print(f\"   Temporal extent keys: {list(metadata.get('temporal_extent', {}).keys())}\")\n",
    "            \n",
    "            # Now test full extraction\n",
    "            result = extract_temperature_data(test_file)\n",
    "            if 'error' in result:\n",
    "                print(f\"❌ Full extraction failed: {result['error']}\")\n",
    "            else:\n",
    "                print(f\"✅ Full extraction successful!\")\n",
    "                print(f\"   Datasets processed: {list(result['temperature_data'].keys())}\")\n",
    "                for dataset, data in result['temperature_data'].items():\n",
    "                    if 'error' in data:\n",
    "                        print(f\"   {dataset}: ❌ {data['error']}\")\n",
    "                    else:\n",
    "                        temp = data.get('temperature_mean_C', 'N/A')\n",
    "                        print(f\"   {dataset}: ✅ {temp}°C\")\n",
    "        else:\n",
    "            print(\"❌ Metadata extraction returned None\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Test failed: {e}\")\n",
    "else:\n",
    "    print(\"❌ No XML files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53e98b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Debugging XML file paths...\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "\n",
      "XML_FOLDER_PATH: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "Number of files found: 48\n",
      "\n",
      "First 5 full paths:\n",
      "   1. /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "      Exists: True\n",
      "   2. /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_metadata.xml\n",
      "      Exists: True\n",
      "   3. /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "      Exists: True\n",
      "   4. /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_metadata.xml\n",
      "      Exists: True\n",
      "   5. /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_post_inspire.xml\n",
      "      Exists: True\n",
      "\n",
      "Testing extractor directly with: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "❌ Extractor failed: XML file not found: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml_pre_inspire.xml\n"
     ]
    }
   ],
   "source": [
    "# Debug XML File Paths\n",
    "\n",
    "print(\"🔍 Debugging XML file paths...\")\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "\n",
    "print(f\"\\nXML_FOLDER_PATH: {XML_FOLDER_PATH}\")\n",
    "print(f\"Number of files found: {len(xml_files)}\")\n",
    "\n",
    "if xml_files:\n",
    "    print(f\"\\nFirst 5 full paths:\")\n",
    "    for i, xml_file in enumerate(xml_files[:5], 1):\n",
    "        print(f\"   {i}. {xml_file}\")\n",
    "        print(f\"      Exists: {os.path.exists(xml_file)}\")\n",
    "        \n",
    "    # Test the extractor directly\n",
    "    test_file = xml_files[0]\n",
    "    print(f\"\\nTesting extractor directly with: {test_file}\")\n",
    "    \n",
    "    if os.path.exists(test_file):\n",
    "        try:\n",
    "            metadata = extractor.extract_geospatial_metadata(test_file)\n",
    "            print(f\"✅ Extractor worked! Metadata type: {type(metadata)}\")\n",
    "            if metadata:\n",
    "                print(f\"   Keys: {list(metadata.keys())}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Extractor failed: {e}\")\n",
    "    else:\n",
    "        print(f\"❌ File does not exist: {test_file}\")\n",
    "else:\n",
    "    print(\"❌ No XML files found\")\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(XML_FOLDER_PATH):\n",
    "        print(f\"✅ Folder exists: {XML_FOLDER_PATH}\")\n",
    "        contents = os.listdir(XML_FOLDER_PATH)\n",
    "        print(f\"   Contents: {contents[:10]}\")\n",
    "    else:\n",
    "        print(f\"❌ Folder does not exist: {XML_FOLDER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b51861a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "Testing different approaches with: chile_post_inspire.xml\n",
      "Full path: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "\n",
      "🧪 Test 1: Using filename only: chile_post_inspire.xml\n",
      "❌ Failed with filename only: XML file not found: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml_pre_inspire.xml\n",
      "\n",
      "🧪 Test 2: Check extractor's xml_folder_path\n",
      "   extractor.xml_folder_path: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "\n",
      "🧪 Test 3: Using second file: chile_post_metadata.xml\n",
      "❌ Failed with second file: XML file not found: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_metadata.xml_pre_inspire.xml\n",
      "\n",
      "🧪 Test 4: Check extractor type and methods\n",
      "   Type: <class '__main__.MetadataExtractor'>\n",
      "   Available attributes: ['extract_geospatial_metadata', 'metadata_cache', 'xml_folder_path']\n",
      "   Metadata cache keys: Empty\n"
     ]
    }
   ],
   "source": [
    "# Test Different Approaches with MetadataExtractor\n",
    "\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "test_file = xml_files[0]\n",
    "\n",
    "print(f\"Testing different approaches with: {os.path.basename(test_file)}\")\n",
    "print(f\"Full path: {test_file}\")\n",
    "\n",
    "# Try 1: Just filename\n",
    "try:\n",
    "    filename_only = os.path.basename(test_file)\n",
    "    print(f\"\\n🧪 Test 1: Using filename only: {filename_only}\")\n",
    "    metadata = extractor.extract_geospatial_metadata(filename_only)\n",
    "    print(f\"✅ Success with filename only!\")\n",
    "    if metadata:\n",
    "        print(f\"   Keys: {list(metadata.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed with filename only: {e}\")\n",
    "\n",
    "# Try 2: Check if extractor has internal path handling\n",
    "print(f\"\\n🧪 Test 2: Check extractor's xml_folder_path\")\n",
    "print(f\"   extractor.xml_folder_path: {extractor.xml_folder_path}\")\n",
    "\n",
    "# Try 3: Test with a different XML file\n",
    "if len(xml_files) > 1:\n",
    "    test_file2 = xml_files[1]\n",
    "    try:\n",
    "        filename_only2 = os.path.basename(test_file2)\n",
    "        print(f\"\\n🧪 Test 3: Using second file: {filename_only2}\")\n",
    "        metadata2 = extractor.extract_geospatial_metadata(filename_only2)\n",
    "        print(f\"✅ Success with second file!\")\n",
    "        if metadata2:\n",
    "            print(f\"   Keys: {list(metadata2.keys())}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed with second file: {e}\")\n",
    "\n",
    "# Try 4: Check the MetadataExtractor source\n",
    "print(f\"\\n🧪 Test 4: Check extractor type and methods\")\n",
    "print(f\"   Type: {type(extractor)}\")\n",
    "print(f\"   Available attributes: {[attr for attr in dir(extractor) if not attr.startswith('_')]}\")\n",
    "\n",
    "# Let's see if there's cached metadata we can use\n",
    "if hasattr(extractor, 'metadata_cache'):\n",
    "    print(f\"   Metadata cache keys: {list(extractor.metadata_cache.keys()) if extractor.metadata_cache else 'Empty'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f57ff506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing corrected metadata extraction...\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "\n",
      "--- Test 1: chile_post_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_post_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "    Keys: ['country_id', 'time_period', 'product_info', 'spatial_extent', 'temporal_extent', 'technical_specs']\n",
      "    Spatial: W=-72.23, E=-71.03\n",
      "            S=-33.51, N=-32.50\n",
      "\n",
      "--- Test 2: chile_post_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_post_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "    Keys: ['country_id', 'time_period', 'product_info', 'spatial_extent', 'temporal_extent', 'technical_specs']\n",
      "    Spatial: W=-72.23, E=-71.03\n",
      "            S=-33.51, N=-32.50\n",
      "\n",
      "--- Test 3: chile_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_pre_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "    Keys: ['country_id', 'time_period', 'product_info', 'spatial_extent', 'temporal_extent', 'technical_specs']\n",
      "    Spatial: W=-72.23, E=-71.03\n",
      "            S=-33.51, N=-32.50\n"
     ]
    }
   ],
   "source": [
    "# Helper Function to Parse XML Filenames and Call Extractor Correctly\n",
    "\n",
    "def parse_xml_filename_and_extract_metadata(xml_file_path):\n",
    "    \"\"\"\n",
    "    Parse XML filename to extract country_id and time period, then call extractor.\n",
    "    \n",
    "    Args:\n",
    "        xml_file_path (str): Path to XML file\n",
    "        \n",
    "    Returns:\n",
    "        dict: Extracted metadata or None if failed\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(xml_file_path)\n",
    "    print(f\"  🔍 Parsing filename: {filename}\")\n",
    "    \n",
    "    # Parse country_id and time period from filename\n",
    "    # Examples: chile_post_inspire.xml, france_pre_metadata.xml\n",
    "    \n",
    "    country_id = None\n",
    "    when = None\n",
    "    \n",
    "    # Extract country\n",
    "    if 'chile' in filename.lower():\n",
    "        country_id = 'chile'\n",
    "    elif 'france' in filename.lower():\n",
    "        country_id = 'france'\n",
    "    \n",
    "    # Extract time period\n",
    "    if 'pre' in filename.lower():\n",
    "        when = 'pre'\n",
    "    elif 'post' in filename.lower():\n",
    "        when = 'post'\n",
    "    \n",
    "    if country_id and when:\n",
    "        print(f\"    📋 Extracted: country_id='{country_id}', when='{when}'\")\n",
    "        try:\n",
    "            metadata = extractor.extract_geospatial_metadata(country_id, when)\n",
    "            if metadata:\n",
    "                print(f\"    ✅ Metadata extraction successful!\")\n",
    "                return metadata\n",
    "            else:\n",
    "                print(f\"    ❌ Metadata extraction returned None\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"    ❌ Metadata extraction failed: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"    ❌ Could not parse country_id or when from filename\")\n",
    "        return None\n",
    "\n",
    "# Test the corrected approach\n",
    "print(\"🧪 Testing corrected metadata extraction...\")\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "\n",
    "if xml_files:\n",
    "    # Test with first few files\n",
    "    for i, test_file in enumerate(xml_files[:3], 1):\n",
    "        print(f\"\\n--- Test {i}: {os.path.basename(test_file)} ---\")\n",
    "        metadata = parse_xml_filename_and_extract_metadata(test_file)\n",
    "        if metadata:\n",
    "            print(f\"    Keys: {list(metadata.keys())}\")\n",
    "            spatial = metadata.get('spatial_extent', {})\n",
    "            if spatial.get('west_bound') is not None:\n",
    "                print(f\"    Spatial: W={spatial.get('west_bound'):.2f}, E={spatial.get('east_bound'):.2f}\")\n",
    "                print(f\"            S={spatial.get('south_bound'):.2f}, N={spatial.get('north_bound'):.2f}\")\n",
    "else:\n",
    "    print(\"❌ No XML files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bad403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Testing complete temperature extraction with one file...\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "Testing with: chile_post_inspire.xml\n",
      "  🔍 Parsing filename: chile_post_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "\n",
      "📊 RESULTS:\n",
      "Processing info: {'xml_file': 'chile_post_inspire.xml', 'country': 'Chile', 'time_period': 'Post-Fire', 'processing_start_time': '2025-08-11T08:15:47.371619', 'processing_time_seconds': 6.0, 'processing_end_time': '2025-08-11T08:15:53.376163'}\n",
      "✅ Extraction successful!\n",
      "Metadata keys: ['country_id', 'time_period', 'product_info', 'spatial_extent', 'temporal_extent', 'technical_specs']\n",
      "Temperature data keys: ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']\n",
      "   MODIS_TERRA: ✅ 32.48°C (WARM)\n",
      "   MODIS_AQUA: ✅ 41.38°C (HOT)\n",
      "   LANDSAT8: ❌ No valid temperature data extracted\n",
      "   LANDSAT9: ❌ No valid temperature data extracted\n"
     ]
    }
   ],
   "source": [
    "# Test Complete Temperature Extraction with One File\n",
    "\n",
    "print(\"🔥 Testing complete temperature extraction with one file...\")\n",
    "\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "if xml_files:\n",
    "    test_file = xml_files[0]  # chile_post_inspire.xml\n",
    "    print(f\"Testing with: {os.path.basename(test_file)}\")\n",
    "    \n",
    "    # Run complete extraction\n",
    "    result = extract_temperature_data(test_file)\n",
    "    \n",
    "    print(f\"\\n📊 RESULTS:\")\n",
    "    print(f\"Processing info: {result['processing_info']}\")\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"❌ Extraction failed: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"✅ Extraction successful!\")\n",
    "        print(f\"Metadata keys: {list(result['metadata'].keys())}\")\n",
    "        print(f\"Temperature data keys: {list(result['temperature_data'].keys())}\")\n",
    "        \n",
    "        # Show temperature results for each dataset\n",
    "        for dataset, data in result['temperature_data'].items():\n",
    "            if 'error' in data:\n",
    "                print(f\"   {dataset}: ❌ {data['error']}\")\n",
    "            else:\n",
    "                temp = data.get('temperature_mean_C', 'N/A')\n",
    "                classification = data.get('temperature_classification', 'N/A')\n",
    "                print(f\"   {dataset}: ✅ {temp}°C ({classification})\")\n",
    "else:\n",
    "    print(\"❌ No XML files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a54bfe0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 LAUNCHING COMPLETE TEMPERATURE EXTRACTION FOR ALL XML FILES!\n",
      "================================================================================\n",
      "🚀 Starting Complete Temperature Extraction Pipeline\n",
      "⏰ Start Time: 2025-08-11 08:17:48\n",
      "📁 Looking for XML files in: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "================================================================================\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "📄 Found 48 XML files to process\n",
      "\n",
      "🔄 Starting batch temperature extraction...\n",
      "🔄 Processing 48 XML files...\n",
      "\n",
      "--- Processing 1/48: chile_post_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_post_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 2/48: chile_post_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_post_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 3/48: chile_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_pre_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 34.9°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 1/4 datasets extracted\n",
      "\n",
      "--- Processing 4/48: chile_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_pre_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 34.9°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 1/4 datasets extracted\n",
      "\n",
      "--- Processing 5/48: france_post_inspire.xml ---\n",
      "  🔍 Parsing filename: france_post_inspire.xml\n",
      "    📋 Extracted: country_id='france', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 36.2°C (HOT)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 38.7°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 6/48: france_post_metadata.xml ---\n",
      "  🔍 Parsing filename: france_post_metadata.xml\n",
      "    📋 Extracted: country_id='france', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 36.2°C (HOT)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 38.7°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 7/48: france_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: france_pre_inspire.xml\n",
      "    📋 Extracted: country_id='france', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 33.2°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 30.5°C (WARM)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 8/48: france_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: france_pre_metadata.xml\n",
      "    📋 Extracted: country_id='france', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 33.2°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 30.5°C (WARM)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 9/48: greece2_post_inspire.xml ---\n",
      "  🔍 Parsing filename: greece2_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 10/48: greece2_post_metadata.xml ---\n",
      "  🔍 Parsing filename: greece2_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 11/48: greece2_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: greece2_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 12/48: greece2_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: greece2_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 13/48: greece_post_inspire.xml ---\n",
      "  🔍 Parsing filename: greece_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 14/48: greece_post_metadata.xml ---\n",
      "  🔍 Parsing filename: greece_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 15/48: greece_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: greece_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 16/48: greece_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: greece_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 17/48: paraguay_post_inspire.xml ---\n",
      "  🔍 Parsing filename: paraguay_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process paraguay_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process paraguay_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 18/48: paraguay_post_metadata.xml ---\n",
      "  🔍 Parsing filename: paraguay_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process paraguay_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process paraguay_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 19/48: paraguay_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: paraguay_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process paraguay_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process paraguay_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 20/48: paraguay_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: paraguay_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process paraguay_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process paraguay_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 21/48: sardinia_post_inspire.xml ---\n",
      "  🔍 Parsing filename: sardinia_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process sardinia_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process sardinia_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 22/48: sardinia_post_metadata.xml ---\n",
      "  🔍 Parsing filename: sardinia_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process sardinia_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process sardinia_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 23/48: sardinia_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: sardinia_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process sardinia_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process sardinia_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 24/48: sardinia_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: sardinia_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process sardinia_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process sardinia_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 25/48: spain2_post_inspire.xml ---\n",
      "  🔍 Parsing filename: spain2_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 26/48: spain2_post_metadata.xml ---\n",
      "  🔍 Parsing filename: spain2_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 27/48: spain2_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: spain2_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 28/48: spain2_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: spain2_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 29/48: spain3_post_inspire.xml ---\n",
      "  🔍 Parsing filename: spain3_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain3_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain3_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 30/48: spain3_post_metadata.xml ---\n",
      "  🔍 Parsing filename: spain3_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain3_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain3_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 31/48: spain3_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: spain3_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain3_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain3_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 32/48: spain3_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: spain3_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain3_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain3_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 33/48: spain_post_inspire.xml ---\n",
      "  🔍 Parsing filename: spain_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 34/48: spain_post_metadata.xml ---\n",
      "  🔍 Parsing filename: spain_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 35/48: spain_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: spain_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 36/48: spain_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: spain_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process spain_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process spain_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 37/48: turkey_post_inspire.xml ---\n",
      "  🔍 Parsing filename: turkey_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process turkey_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process turkey_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 38/48: turkey_post_metadata.xml ---\n",
      "  🔍 Parsing filename: turkey_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process turkey_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process turkey_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 39/48: turkey_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: turkey_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process turkey_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process turkey_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 40/48: turkey_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: turkey_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process turkey_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process turkey_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 41/48: usa2_post_inspire.xml ---\n",
      "  🔍 Parsing filename: usa2_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 42/48: usa2_post_metadata.xml ---\n",
      "  🔍 Parsing filename: usa2_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 43/48: usa2_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: usa2_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 44/48: usa2_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: usa2_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 45/48: usa_post_inspire.xml ---\n",
      "  🔍 Parsing filename: usa_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 46/48: usa_post_metadata.xml ---\n",
      "  🔍 Parsing filename: usa_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 47/48: usa_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: usa_pre_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 48/48: usa_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: usa_pre_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process usa_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process usa_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "📊 Creating Excel export...\n",
      "\n",
      "📊 Excel file created: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_data_extraction_complete.xlsx\n",
      "📋 Sheets included:\n",
      "   - Summary: Overview of all extractions\n",
      "   - MODIS_TERRA_Details: Detailed MODIS Terra temperature data\n",
      "   - MODIS_AQUA_Details: Detailed MODIS Aqua temperature data\n",
      "   - LANDSAT8_Details: Detailed Landsat 8 temperature data\n",
      "   - LANDSAT9_Details: Detailed Landsat 9 temperature data\n",
      "   - Error_Log: Failed extractions and errors\n",
      "   - Metadata: Spatial and temporal metadata\n",
      "\n",
      "================================================================================\n",
      "📋 EXTRACTION COMPLETE - SUMMARY STATISTICS\n",
      "================================================================================\n",
      "📄 Total XML files processed: 48\n",
      "✅ Successful extractions: 8\n",
      "❌ Failed extractions: 40\n",
      "📊 Excel file created: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_data_extraction_complete.xlsx\n",
      "⏱️  Total processing time: 23.46 seconds\n",
      "⏰ End Time: 2025-08-11 08:18:11\n",
      "\n",
      "📊 Dataset Success Rates:\n",
      "   - MODIS_TERRA: 8/8 (100.0%)\n",
      "   - MODIS_AQUA: 6/8 (75.0%)\n",
      "   - LANDSAT8: 0/8 (0.0%)\n",
      "   - LANDSAT9: 0/8 (0.0%)\n",
      "\n",
      "❌ Failed Extractions Details:\n",
      "   - Unknown Unknown: Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process greece_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process paraguay_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process paraguay_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process paraguay_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process paraguay_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process sardinia_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process sardinia_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process sardinia_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process sardinia_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain3_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain3_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain3_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain3_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process spain_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process turkey_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process turkey_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process turkey_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process turkey_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa2_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa2_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa_pre_inspire.xml: Failed to extract metadata from XML file\n",
      "   - Unknown Unknown: Failed to process usa_pre_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "🎉 Temperature extraction pipeline completed successfully!\n",
      "================================================================================\n",
      "\n",
      "🎉 PIPELINE COMPLETED SUCCESSFULLY!\n",
      "📊 Final Summary:\n",
      "   📄 Total files processed: 48\n",
      "   ✅ Successful extractions: 8\n",
      "   ❌ Failed extractions: 40\n",
      "   📈 Success rate: 16.7%\n",
      "   📊 Excel output: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_data_extraction_complete.xlsx\n",
      "   ⏱️ Total time: 23.5 seconds\n"
     ]
    }
   ],
   "source": [
    "# RUN COMPLETE TEMPERATURE EXTRACTION PIPELINE\n",
    "\n",
    "print(\"🚀 LAUNCHING COMPLETE TEMPERATURE EXTRACTION FOR ALL XML FILES!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Execute the main pipeline\n",
    "pipeline_results = main_temperature_extraction()\n",
    "\n",
    "if pipeline_results:\n",
    "    print(f\"\\n🎉 PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"📊 Final Summary:\")\n",
    "    print(f\"   📄 Total files processed: {pipeline_results['total_files']}\")\n",
    "    print(f\"   ✅ Successful extractions: {pipeline_results['successful_extractions']}\")\n",
    "    print(f\"   ❌ Failed extractions: {pipeline_results['failed_extractions']}\")\n",
    "    print(f\"   📈 Success rate: {(pipeline_results['successful_extractions']/pipeline_results['total_files']*100):.1f}%\")\n",
    "    print(f\"   📊 Excel output: {pipeline_results['excel_path']}\")\n",
    "    print(f\"   ⏱️ Total time: {pipeline_results['processing_time_seconds']:.1f} seconds\")\n",
    "else:\n",
    "    print(\"❌ Pipeline failed to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35d642db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 VALIDATION RUN: Processing first 10 XML files\n",
      "============================================================\n",
      "🔍 Found 48 XML files:\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   ... and 43 more files\n",
      "📄 Validation files (10):\n",
      "   1. chile_post_inspire.xml\n",
      "   2. chile_post_metadata.xml\n",
      "   3. chile_pre_inspire.xml\n",
      "   4. chile_pre_metadata.xml\n",
      "   5. france_post_inspire.xml\n",
      "   6. france_post_metadata.xml\n",
      "   7. france_pre_inspire.xml\n",
      "   8. france_pre_metadata.xml\n",
      "   9. greece2_post_inspire.xml\n",
      "   10. greece2_post_metadata.xml\n",
      "🔄 Processing 10 XML files...\n",
      "\n",
      "--- Processing 1/10: chile_post_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_post_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 2/10: chile_post_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_post_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 32.5°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 41.4°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 3/10: chile_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: chile_pre_inspire.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 34.9°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 1/4 datasets extracted\n",
      "\n",
      "--- Processing 4/10: chile_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: chile_pre_metadata.xml\n",
      "    📋 Extracted: country_id='chile', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/chile_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 34.9°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 1/4 datasets extracted\n",
      "\n",
      "--- Processing 5/10: france_post_inspire.xml ---\n",
      "  🔍 Parsing filename: france_post_inspire.xml\n",
      "    📋 Extracted: country_id='france', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 36.2°C (HOT)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 38.7°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 6/10: france_post_metadata.xml ---\n",
      "  🔍 Parsing filename: france_post_metadata.xml\n",
      "    📋 Extracted: country_id='france', when='post'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_post_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 36.2°C (HOT)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 38.7°C (HOT)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 7/10: france_pre_inspire.xml ---\n",
      "  🔍 Parsing filename: france_pre_inspire.xml\n",
      "    📋 Extracted: country_id='france', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 33.2°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 30.5°C (WARM)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 8/10: france_pre_metadata.xml ---\n",
      "  🔍 Parsing filename: france_pre_metadata.xml\n",
      "    📋 Extracted: country_id='france', when='pre'\n",
      "Extracting metadata from: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files/france_pre_inspire.xml\n",
      "    ✅ Metadata extraction successful!\n",
      "  📡 Processing MODIS_TERRA...\n",
      "    ✅ Success: 33.2°C (WARM)\n",
      "  📡 Processing MODIS_AQUA...\n",
      "    ✅ Success: 30.5°C (WARM)\n",
      "  📡 Processing LANDSAT8...\n",
      "    ❌ No valid data\n",
      "  📡 Processing LANDSAT9...\n",
      "    ❌ No valid data\n",
      "   ✅ Success: 2/4 datasets extracted\n",
      "\n",
      "--- Processing 9/10: greece2_post_inspire.xml ---\n",
      "  🔍 Parsing filename: greece2_post_inspire.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "\n",
      "--- Processing 10/10: greece2_post_metadata.xml ---\n",
      "  🔍 Parsing filename: greece2_post_metadata.xml\n",
      "    ❌ Could not parse country_id or when from filename\n",
      "❌ Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "   ❌ Failed: Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n",
      "\n",
      "📊 Excel file created: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_validation_10files_20250811_081743.xlsx\n",
      "📋 Sheets included:\n",
      "   - Summary: Overview of all extractions\n",
      "   - MODIS_TERRA_Details: Detailed MODIS Terra temperature data\n",
      "   - MODIS_AQUA_Details: Detailed MODIS Aqua temperature data\n",
      "   - LANDSAT8_Details: Detailed Landsat 8 temperature data\n",
      "   - LANDSAT9_Details: Detailed Landsat 9 temperature data\n",
      "   - Error_Log: Failed extractions and errors\n",
      "   - Metadata: Spatial and temporal metadata\n",
      "\n",
      "📊 VALIDATION SUMMARY:\n",
      "   ✅ Successful: 8/10\n",
      "   ❌ Failed: 2/10\n",
      "   📈 Success rate: 80.0%\n",
      "   ⏱️ Processing time: 27.6 seconds\n",
      "   📊 Excel: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/temperature_validation_10files_20250811_081743.xlsx\n",
      "\n",
      "✅ Validation passed! Ready for full pipeline.\n",
      "\n",
      "❌ Failed files:\n",
      "   - greece2_post_inspire.xml: Failed to process greece2_post_inspire.xml: Failed to extract metadata from XML file\n",
      "   - greece2_post_metadata.xml: Failed to process greece2_post_metadata.xml: Failed to extract metadata from XML file\n"
     ]
    }
   ],
   "source": [
    "# RUN PIPELINE WITH FIRST 10 FILES (VALIDATION RUN)\n",
    "\n",
    "print(\"🧪 VALIDATION RUN: Processing first 10 XML files\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get XML files\n",
    "xml_files = find_xml_files(XML_FOLDER_PATH)\n",
    "if xml_files:\n",
    "    validation_files = xml_files[:10]  # First 10 files\n",
    "    print(f\"📄 Validation files ({len(validation_files)}):\")\n",
    "    for i, file_path in enumerate(validation_files, 1):\n",
    "        print(f\"   {i}. {os.path.basename(file_path)}\")\n",
    "    \n",
    "    # Process validation files\n",
    "    validation_start = time.time()\n",
    "    validation_results = process_all_xml_files(validation_files)\n",
    "    validation_time = time.time() - validation_start\n",
    "    \n",
    "    # Create validation Excel\n",
    "    validation_excel = create_excel_export(validation_results, f\"temperature_validation_10files_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\")\n",
    "    \n",
    "    # Validation summary\n",
    "    successful = [r for r in validation_results if 'error' not in r]\n",
    "    failed = [r for r in validation_results if 'error' in r]\n",
    "    \n",
    "    print(f\"\\n📊 VALIDATION SUMMARY:\")\n",
    "    print(f\"   ✅ Successful: {len(successful)}/{len(validation_files)}\")\n",
    "    print(f\"   ❌ Failed: {len(failed)}/{len(validation_files)}\")\n",
    "    print(f\"   📈 Success rate: {(len(successful)/len(validation_files)*100):.1f}%\")\n",
    "    print(f\"   ⏱️ Processing time: {validation_time:.1f} seconds\")\n",
    "    print(f\"   📊 Excel: {validation_excel}\")\n",
    "    \n",
    "    if len(successful) >= 8:  # At least 80% success\n",
    "        print(f\"\\n✅ Validation passed! Ready for full pipeline.\")\n",
    "        proceed_full = True\n",
    "    else:\n",
    "        print(f\"\\n⚠️ Validation had low success rate. Check errors before full run.\")\n",
    "        proceed_full = False\n",
    "        \n",
    "    # Show any failures\n",
    "    if failed:\n",
    "        print(f\"\\n❌ Failed files:\")\n",
    "        for result in failed:\n",
    "            print(f\"   - {result['processing_info']['xml_file']}: {result.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"❌ No XML files found!\")\n",
    "    proceed_full = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d9a3b",
   "metadata": {},
   "source": [
    "# Temperature Data Extraction with Excel Export\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extracts temperature data from multiple satellite thermal datasets using Google Earth Engine API for ALL XML files in the database. It processes all countries and time periods, extracting:\n",
    "\n",
    "- Land Surface Temperature (LST) from multiple satellite sources\n",
    "- Satellite acquisition dates from XML metadata\n",
    "- Statistical analysis for each location (mean, min, max, std deviation)\n",
    "- Temperature classification and fire risk assessment\n",
    "- Export to Excel format for comprehensive analysis\n",
    "\n",
    "## Supported Datasets\n",
    "\n",
    "- **MODIS Terra (MOD11A1)**: 1km resolution, daily Land Surface Temperature\n",
    "- **MODIS Aqua (MYD11A1)**: 1km resolution, daily Land Surface Temperature  \n",
    "- **Landsat 8**: 100m resolution, thermal infrared surface temperature\n",
    "- **Landsat 9**: 100m resolution, thermal infrared surface temperature\n",
    "\n",
    "## Output\n",
    "\n",
    "- Structured Excel file with all temperature data\n",
    "- Extraction dates from satellite metadata\n",
    "- Comprehensive temperature statistics for each location and time period\n",
    "- Temperature classification and fire risk assessment\n",
    "- Error handling and detailed logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b084a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "# Data handling and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Google Earth Engine\n",
    "import ee\n",
    "\n",
    "# Geospatial libraries\n",
    "import pyproj\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import transform\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "XML_FOLDER_PATH = os.path.join('/Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files')\n",
    "OUTPUT_FOLDER = os.path.join(os.getcwd(), 'temperature_extraction_output')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration set:\")\n",
    "print(f\"  XML folder: {XML_FOLDER_PATH}\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# Check XML files available\n",
    "xml_files = [f for f in os.listdir(XML_FOLDER_PATH) if f.endswith('_inspire.xml')]\n",
    "print(f\"  Found {len(xml_files)} XML files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Earth Engine Authentication and Initialization\n",
    "print(\"Initializing Google Earth Engine...\")\n",
    "\n",
    "try:\n",
    "    # Try to initialize first (if already authenticated)\n",
    "    ee.Initialize()\n",
    "    print(\"✓ Google Earth Engine initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Authentication required. Please follow the authentication process...\")\n",
    "    try:\n",
    "        # If initialization fails, authenticate first\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "        print(\"✓ Google Earth Engine authenticated and initialized successfully!\")\n",
    "    except Exception as auth_error:\n",
    "        print(f\"✗ Authentication failed: {auth_error}\")\n",
    "        print(\"Please ensure you have a Google Earth Engine account and proper permissions.\")\n",
    "        raise\n",
    "\n",
    "print(\"Google Earth Engine is ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Dataset Configuration\n",
    "TEMPERATURE_DATASETS = {\n",
    "    \"MODIS_TERRA\": {\n",
    "        \"id\": \"MODIS/061/MOD11A1\",\n",
    "        \"band\": \"LST_Day_1km\",\n",
    "        \"qa_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"factor\": 0.02,\n",
    "        \"offset\": -273.15,\n",
    "        \"description\": \"MODIS Terra Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"MODIS_AQUA\": {\n",
    "        \"id\": \"MODIS/061/MYD11A1\",\n",
    "        \"band\": \"LST_Day_1km\", \n",
    "        \"qa_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"factor\": 0.02,\n",
    "        \"offset\": -273.15,\n",
    "        \"description\": \"MODIS Aqua Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"LANDSAT8\": {\n",
    "        \"id\": \"LANDSAT/LC08/C02/T1_L2\",\n",
    "        \"band\": \"ST_B10\",\n",
    "        \"qa_band\": \"QA_PIXEL\",\n",
    "        \"scale\": 100,\n",
    "        \"factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"kelvin_offset\": -273.15,\n",
    "        \"description\": \"Landsat 8 Surface Temperature (100m)\"\n",
    "    },\n",
    "    \"LANDSAT9\": {\n",
    "        \"id\": \"LANDSAT/LC09/C02/T1_L2\",\n",
    "        \"band\": \"ST_B10\",\n",
    "        \"qa_band\": \"QA_PIXEL\", \n",
    "        \"scale\": 100,\n",
    "        \"factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"kelvin_offset\": -273.15,\n",
    "        \"description\": \"Landsat 9 Surface Temperature (100m)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Available temperature datasets:\")\n",
    "for key, dataset in TEMPERATURE_DATASETS.items():\n",
    "    print(f\"  {key}: {dataset['description']}\")\n",
    "    print(f\"    Resolution: {dataset['scale']}m\")\n",
    "    print(f\"    Collection: {dataset['id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata Extractor Class\n",
    "class MetadataExtractor:\n",
    "    \"\"\"\n",
    "    A robust class to extract essential metadata from Sentinel-2 XML files\n",
    "    for extracting coordinates and temporal information\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, xml_folder_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the MetadataExtractor\n",
    "        \n",
    "        Args:\n",
    "            xml_folder_path (str): Path to the folder containing XML files\n",
    "        \"\"\"\n",
    "        self.xml_folder_path = Path(xml_folder_path)\n",
    "        self.metadata_cache = {}\n",
    "    \n",
    "    def extract_geospatial_metadata(self, country_id, when='pre', resolution=10):\n",
    "        \"\"\"\n",
    "        Extract geospatial metadata from XML files.\n",
    "        \n",
    "        Args:\n",
    "            country_id (str): Country identifier\n",
    "            when (str): Time period identifier ('pre', 'post')\n",
    "            resolution (int): Spatial resolution in meters\n",
    "        \n",
    "        Returns:\n",
    "            dict: Extracted metadata dictionary\n",
    "        \"\"\"\n",
    "        \n",
    "        xml_file = self.xml_folder_path / f\"{country_id}_{when}_inspire.xml\"\n",
    "        \n",
    "        # Check if the XML file exists\n",
    "        if not xml_file.exists():\n",
    "            raise FileNotFoundError(f\"XML file not found: {xml_file}\")\n",
    "        \n",
    "        print(f\"Extracting metadata from: {xml_file}\")\n",
    "        \n",
    "        # Parse XML\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Namespaces\n",
    "        ns = {\n",
    "            'gmd': 'http://www.isotc211.org/2005/gmd',\n",
    "            'gco': 'http://www.isotc211.org/2005/gco',\n",
    "            'gml': 'http://www.opengis.net/gml'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Extract product identification\n",
    "            title_elem = root.find('.//gmd:title/gco:CharacterString', ns)\n",
    "            title = title_elem.text if title_elem is not None else \"Unknown\"\n",
    "            \n",
    "            # Extract geographic coordinates\n",
    "            west_elem = root.find('.//gmd:westBoundLongitude/gco:Decimal', ns)\n",
    "            east_elem = root.find('.//gmd:eastBoundLongitude/gco:Decimal', ns)\n",
    "            south_elem = root.find('.//gmd:southBoundLatitude/gco:Decimal', ns)\n",
    "            north_elem = root.find('.//gmd:northBoundLatitude/gco:Decimal', ns)\n",
    "            \n",
    "            west = float(west_elem.text) if west_elem is not None else None\n",
    "            east = float(east_elem.text) if east_elem is not None else None\n",
    "            south = float(south_elem.text) if south_elem is not None else None\n",
    "            north = float(north_elem.text) if north_elem is not None else None\n",
    "            \n",
    "            # Extract temporal information\n",
    "            begin_elem = root.find('.//gml:beginPosition', ns)\n",
    "            end_elem = root.find('.//gml:endPosition', ns)\n",
    "            \n",
    "            begin_time = begin_elem.text if begin_elem is not None else None\n",
    "            end_time = end_elem.text if end_elem is not None else None\n",
    "            \n",
    "            # Extract spatial resolution\n",
    "            resolution_elem = root.find('.//gmd:denominator/gco:Integer', ns)\n",
    "            spatial_resolution = int(resolution_elem.text) if resolution_elem is not None else resolution\n",
    "            \n",
    "            # Extract coordinate reference system\n",
    "            crs_elem = root.find('.//gmd:code/gco:CharacterString', ns)\n",
    "            crs_code = crs_elem.text if crs_elem is not None else \"Unknown\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error extracting some metadata: {e}\")\n",
    "            # Provide default values if extraction fails\n",
    "            title = \"Unknown\"\n",
    "            west = east = south = north = None\n",
    "            begin_time = end_time = None\n",
    "            spatial_resolution = resolution\n",
    "            crs_code = \"Unknown\"\n",
    "        \n",
    "        # Build metadata dictionary\n",
    "        metadata = {\n",
    "            'country_id': country_id,\n",
    "            'time_period': when,\n",
    "            'product_info': {\n",
    "                'title': title,\n",
    "                'file_path': xml_file\n",
    "            },\n",
    "            'spatial_extent': {\n",
    "                'west_bound': west,\n",
    "                'east_bound': east,\n",
    "                'south_bound': south,\n",
    "                'north_bound': north,\n",
    "                'center_lat': (north + south) / 2 if north and south else None,\n",
    "                'center_lon': (east + west) / 2 if east and west else None\n",
    "            },\n",
    "            'temporal_extent': {\n",
    "                'start_time': begin_time,\n",
    "                'end_time': end_time\n",
    "            },\n",
    "            'technical_specs': {\n",
    "                'spatial_resolution': spatial_resolution,\n",
    "                'crs_code': crs_code\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return metadata\n",
    "\n",
    "# Initialize MetadataExtractor\n",
    "print(f\"Using XML folder path: {XML_FOLDER_PATH}\")\n",
    "extractor = MetadataExtractor(XML_FOLDER_PATH)\n",
    "print(\"MetadataExtractor initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123784bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Analysis Utility Functions\n",
    "\n",
    "def apply_cloud_mask(image, dataset_name):\n",
    "    \"\"\"\n",
    "    Apply cloud masking based on quality bands for different datasets.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): Input thermal image\n",
    "        dataset_name (str): Name of the dataset for appropriate masking\n",
    "        \n",
    "    Returns:\n",
    "        ee.Image: Cloud-masked image\n",
    "    \"\"\"\n",
    "    ds = TEMPERATURE_DATASETS[dataset_name]\n",
    "    \n",
    "    if dataset_name in [\"MODIS_TERRA\", \"MODIS_AQUA\"]:\n",
    "        # MODIS QC masking - keep only good quality pixels\n",
    "        qa = image.select(ds[\"qa_band\"])\n",
    "        # Bits 0-1: LST quality (00 = good, 01 = other quality)\n",
    "        quality_mask = qa.bitwiseAnd(3).eq(0)  # Keep only good quality\n",
    "        return image.updateMask(quality_mask)\n",
    "        \n",
    "    elif dataset_name in [\"LANDSAT8\", \"LANDSAT9\"]:\n",
    "        # Landsat Collection 2 QA_PIXEL masking\n",
    "        qa = image.select(ds[\"qa_band\"])\n",
    "        # Bit 3: Cloud, Bit 4: Cloud shadow, Bit 8: Cirrus\n",
    "        cloud_mask = qa.bitwiseAnd(1 << 3).eq(0).And(  # Not cloud\n",
    "                    qa.bitwiseAnd(1 << 4).eq(0)).And(  # Not cloud shadow\n",
    "                    qa.bitwiseAnd(1 << 8).eq(0))       # Not cirrus\n",
    "        return image.updateMask(cloud_mask)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def convert_to_celsius(image, dataset_name):\n",
    "    \"\"\"\n",
    "    Convert thermal data to Celsius based on dataset specifications.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): Input thermal image\n",
    "        dataset_name (str): Name of the dataset for appropriate conversion\n",
    "        \n",
    "    Returns:\n",
    "        ee.Image: Temperature in Celsius\n",
    "    \"\"\"\n",
    "    ds = TEMPERATURE_DATASETS[dataset_name]\n",
    "    thermal_band = image.select(ds[\"band\"])\n",
    "    \n",
    "    if dataset_name in [\"MODIS_TERRA\", \"MODIS_AQUA\"]:\n",
    "        # MODIS: multiply by scale factor and add offset (already converts to Celsius)\n",
    "        return thermal_band.multiply(ds[\"factor\"]).add(ds[\"offset\"])\n",
    "        \n",
    "    elif dataset_name in [\"LANDSAT8\", \"LANDSAT9\"]:\n",
    "        # Landsat Collection 2: apply scale and offset, then convert from Kelvin to Celsius\n",
    "        return thermal_band.multiply(ds[\"factor\"]).add(ds[\"offset\"]).add(ds[\"kelvin_offset\"])\n",
    "    \n",
    "    # Default conversion\n",
    "    return thermal_band.multiply(ds[\"factor\"]).add(ds[\"offset\"])\n",
    "\n",
    "def classify_temperature_conditions(temp_celsius):\n",
    "    \"\"\"\n",
    "    Classify temperature conditions for fire risk assessment.\n",
    "    \n",
    "    Args:\n",
    "        temp_celsius (float): Temperature in Celsius\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (risk_level, description)\n",
    "    \"\"\"\n",
    "    if temp_celsius < 15:\n",
    "        return (\"COOL\", \"Cool conditions\")\n",
    "    elif temp_celsius < 25:\n",
    "        return (\"MODERATE\", \"Moderate temperature\")\n",
    "    elif temp_celsius < 35:\n",
    "        return (\"WARM\", \"Warm conditions\")\n",
    "    elif temp_celsius < 45:\n",
    "        return (\"HOT\", \"Hot conditions - Elevated fire risk\")\n",
    "    else:\n",
    "        return (\"EXTREME_HOT\", \"Extreme heat - High fire risk\")\n",
    "\n",
    "def calculate_fire_weather_index(temp_celsius):\n",
    "    \"\"\"\n",
    "    Calculate a simple fire weather index based on temperature.\n",
    "    \n",
    "    Args:\n",
    "        temp_celsius (float): Temperature in Celsius\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (index_value, risk_category)\n",
    "    \"\"\"\n",
    "    # Simplified fire weather index based on temperature\n",
    "    if temp_celsius < 20:\n",
    "        return (1, \"LOW\")\n",
    "    elif temp_celsius < 30:\n",
    "        return (2, \"MODERATE\") \n",
    "    elif temp_celsius < 40:\n",
    "        return (3, \"HIGH\")\n",
    "    else:\n",
    "        return (4, \"EXTREME\")\n",
    "\n",
    "def extract_temperature_statistics(image, geometry, scale):\n",
    "    \"\"\"\n",
    "    Extract temperature statistics from an image over a given geometry.\n",
    "    \n",
    "    Args:\n",
    "        image (ee.Image): Temperature image in Celsius\n",
    "        geometry (ee.Geometry): Area of interest\n",
    "        scale (int): Scale for reduction in meters\n",
    "        \n",
    "    Returns:\n",
    "        dict: Temperature statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract comprehensive statistics\n",
    "        stats = image.reduceRegion(\n",
    "            reducer=ee.Reducer.mean().combine(\n",
    "                ee.Reducer.minMax(), outputPrefix='', sharedInputs=True\n",
    "            ).combine(\n",
    "                ee.Reducer.stdDev(), outputPrefix='', sharedInputs=True\n",
    "            ).combine(\n",
    "                ee.Reducer.count(), outputPrefix='', sharedInputs=True\n",
    "            ),\n",
    "            geometry=geometry,\n",
    "            scale=scale,\n",
    "            maxPixels=1e9,\n",
    "            bestEffort=True\n",
    "        )\n",
    "        \n",
    "        return stats.getInfo()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting temperature statistics: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Temperature utility functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fea584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Temperature Data Extraction Function\n",
    "\n",
    "def extract_temperature_for_metadata(metadata, datasets=None, day_tolerance=1):\n",
    "    \"\"\"\n",
    "    Extract temperature data for given metadata from multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "        metadata (dict): Metadata containing spatial and temporal extents\n",
    "        datasets (list): List of dataset names to use (None = all available)\n",
    "        day_tolerance (int): Number of days tolerance around target date\n",
    "        \n",
    "    Returns:\n",
    "        dict: Temperature data results for all datasets\n",
    "    \"\"\"\n",
    "    if datasets is None:\n",
    "        datasets = list(TEMPERATURE_DATASETS.keys())\n",
    "    \n",
    "    # Extract spatial extent\n",
    "    west = metadata['spatial_extent']['west_bound']\n",
    "    east = metadata['spatial_extent']['east_bound'] \n",
    "    south = metadata['spatial_extent']['south_bound']\n",
    "    north = metadata['spatial_extent']['north_bound']\n",
    "    \n",
    "    # Create geometry\n",
    "    geometry = ee.Geometry.Rectangle([west, south, east, north])\n",
    "    \n",
    "    # Extract target date\n",
    "    start_time = metadata['temporal_extent']['start_time']\n",
    "    if start_time:\n",
    "        target_date = dt.datetime.fromisoformat(start_time.replace('Z', '+00:00'))\n",
    "    else:\n",
    "        print(\"Warning: No start time found in metadata, using default date\")\n",
    "        target_date = dt.datetime(2022, 7, 17)  # Default date\n",
    "    \n",
    "    # Define date range with tolerance\n",
    "    start_date = target_date - dt.timedelta(days=day_tolerance)\n",
    "    end_date = target_date + dt.timedelta(days=day_tolerance + 1)\n",
    "    \n",
    "    print(f\"Extracting temperature data for {metadata['country_id']} {metadata['time_period']}:\")\n",
    "    print(f\"  Area: {west:.3f}, {south:.3f} to {east:.3f}, {north:.3f}\")\n",
    "    print(f\"  Target date: {target_date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    results = {\n",
    "        \"metadata\": metadata,\n",
    "        \"date\": target_date.strftime('%Y-%m-%d'),\n",
    "        \"satellite_acquisition_date\": target_date.strftime('%Y-%m-%d'),\n",
    "        \"coordinates\": {\n",
    "            \"west\": west, \"east\": east,\n",
    "            \"south\": south, \"north\": north\n",
    "        },\n",
    "        \"temperature_data\": {}\n",
    "    }\n",
    "    \n",
    "    for dataset_name in datasets:\n",
    "        try:\n",
    "            ds = TEMPERATURE_DATASETS[dataset_name]\n",
    "            \n",
    "            # Load collection\n",
    "            collection = ee.ImageCollection(ds[\"id\"])\n",
    "            \n",
    "            # Filter by date and location\n",
    "            filtered = collection.filterDate(\n",
    "                start_date.strftime('%Y-%m-%d'),\n",
    "                end_date.strftime('%Y-%m-%d')\n",
    "            ).filterBounds(geometry)\n",
    "            \n",
    "            # Check if any images are available\n",
    "            count = filtered.size().getInfo()\n",
    "            if count == 0:\n",
    "                results[\"temperature_data\"][dataset_name] = {\n",
    "                    \"error\": f\"No images available for the specified date range\"\n",
    "                }\n",
    "                continue\n",
    "            \n",
    "            # Get mean image over the time period\n",
    "            mean_image = filtered.mean()\n",
    "            \n",
    "            # Apply cloud masking\n",
    "            masked_image = apply_cloud_mask(mean_image, dataset_name)\n",
    "            \n",
    "            # Convert to Celsius\n",
    "            temperature_celsius = convert_to_celsius(masked_image, dataset_name)\n",
    "            \n",
    "            # Extract temperature statistics\n",
    "            stats = extract_temperature_statistics(temperature_celsius, geometry, ds[\"scale\"])\n",
    "            \n",
    "            if stats:\n",
    "                band_name = ds[\"band\"]\n",
    "                temp_mean = stats.get(f'{band_name}_mean')\n",
    "                temp_min = stats.get(f'{band_name}_min')\n",
    "                temp_max = stats.get(f'{band_name}_max')\n",
    "                temp_std = stats.get(f'{band_name}_stdDev')\n",
    "                pixel_count = stats.get(f'{band_name}_count')\n",
    "                \n",
    "                if temp_mean is not None:\n",
    "                    # Classify temperature conditions\n",
    "                    risk_level, risk_desc = classify_temperature_conditions(temp_mean)\n",
    "                    fire_index, fire_risk = calculate_fire_weather_index(temp_mean)\n",
    "                    \n",
    "                    results[\"temperature_data\"][dataset_name] = {\n",
    "                        \"temperature_mean_C\": temp_mean,\n",
    "                        \"temperature_min_C\": temp_min,\n",
    "                        \"temperature_max_C\": temp_max,\n",
    "                        \"temperature_stdDev_C\": temp_std,\n",
    "                        \"temperature_range_C\": temp_max - temp_min if temp_max and temp_min else None,\n",
    "                        \"pixel_count\": pixel_count,\n",
    "                        \"scale_m\": ds[\"scale\"],\n",
    "                        \"temperature_classification\": risk_level,\n",
    "                        \"temperature_description\": risk_desc,\n",
    "                        \"fire_weather_index\": fire_index,\n",
    "                        \"fire_risk_level\": fire_risk,\n",
    "                        \"image_count\": count\n",
    "                    }\n",
    "                else:\n",
    "                    results[\"temperature_data\"][dataset_name] = {\n",
    "                        \"error\": \"Failed to extract valid temperature statistics\"\n",
    "                    }\n",
    "            else:\n",
    "                results[\"temperature_data\"][dataset_name] = {\n",
    "                    \"error\": \"Failed to extract temperature statistics\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            results[\"temperature_data\"][dataset_name] = {\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Temperature extraction function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Processing Function for All XML Files\n",
    "\n",
    "def process_all_xml_files():\n",
    "    \"\"\"\n",
    "    Process all XML files in the folder and extract temperature data for each.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of all temperature extraction results\n",
    "    \"\"\"\n",
    "    xml_files = [f for f in os.listdir(XML_FOLDER_PATH) if f.endswith('_inspire.xml')]\n",
    "    \n",
    "    # Parse filenames to get country and time period\n",
    "    locations = []\n",
    "    for xml_file in xml_files:\n",
    "        # Extract country and time period from filename\n",
    "        # Format: {country}_{timeperiod}_inspire.xml\n",
    "        parts = xml_file.replace('_inspire.xml', '').split('_')\n",
    "        if len(parts) >= 2:\n",
    "            country = '_'.join(parts[:-1])  # Handle countries with underscores\n",
    "            time_period = parts[-1]\n",
    "            locations.append((country, time_period))\n",
    "    \n",
    "    print(f\"Found {len(locations)} locations to process:\")\n",
    "    for country, period in locations:\n",
    "        print(f\"  - {country} ({period})\")\n",
    "    print()\n",
    "    \n",
    "    all_results = []\n",
    "    successful_extractions = 0\n",
    "    failed_extractions = 0\n",
    "    \n",
    "    for i, (country, time_period) in enumerate(locations, 1):\n",
    "        print(f\"\\\\n=== Processing {i}/{len(locations)}: {country} {time_period} ===\")\n",
    "        \n",
    "        try:\n",
    "            # Extract metadata\n",
    "            metadata = extractor.extract_geospatial_metadata(country, time_period)\n",
    "            \n",
    "            # Extract temperature data\n",
    "            temperature_results = extract_temperature_for_metadata(metadata, day_tolerance=1)\n",
    "            \n",
    "            # Add processing info\n",
    "            temperature_results['processing_info'] = {\n",
    "                'country': country,\n",
    "                'time_period': time_period,\n",
    "                'processing_order': i,\n",
    "                'xml_file': f\"{country}_{time_period}_inspire.xml\"\n",
    "            }\n",
    "            \n",
    "            all_results.append(temperature_results)\n",
    "            successful_extractions += 1\n",
    "            print(f\"✅ Successfully processed {country} {time_period}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to process {country} {time_period}: {e}\")\n",
    "            # Still add a failed result to maintain order\n",
    "            failed_result = {\n",
    "                'processing_info': {\n",
    "                    'country': country,\n",
    "                    'time_period': time_period,\n",
    "                    'processing_order': i,\n",
    "                    'xml_file': f\"{country}_{time_period}_inspire.xml\"\n",
    "                },\n",
    "                'error': str(e),\n",
    "                'date': 'N/A',\n",
    "                'satellite_acquisition_date': 'N/A'\n",
    "            }\n",
    "            all_results.append(failed_result)\n",
    "            failed_extractions += 1\n",
    "    \n",
    "    print(f\"\\\\n=== BATCH PROCESSING COMPLETE ===\")\n",
    "    print(f\"✅ Successful: {successful_extractions}\")\n",
    "    print(f\"❌ Failed: {failed_extractions}\")\n",
    "    print(f\"📊 Total: {len(all_results)}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"Batch processing function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel Export Functionality\n",
    "\n",
    "def create_excel_export(all_results, output_filename=\"temperature_data_extraction_complete.xlsx\"):\n",
    "    \"\"\"\n",
    "    Create a comprehensive Excel export of all temperature data extractions.\n",
    "    \n",
    "    Args:\n",
    "        all_results (list): List of all temperature extraction results\n",
    "        output_filename (str): Name of the output Excel file\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(OUTPUT_FOLDER, output_filename)\n",
    "    \n",
    "    # Create Excel writer object\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        \n",
    "        # ========== SUMMARY SHEET ==========\n",
    "        summary_data = []\n",
    "        for result in all_results:\n",
    "            if 'error' in result:\n",
    "                summary_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                    'Processing_Status': 'FAILED',\n",
    "                    'Error_Message': result.get('error', 'Unknown error'),\n",
    "                    'MODIS_Terra_Temp_C': 'N/A',\n",
    "                    'MODIS_Aqua_Temp_C': 'N/A',\n",
    "                    'Landsat8_Temp_C': 'N/A',\n",
    "                    'Landsat9_Temp_C': 'N/A',\n",
    "                    'Average_Temperature_C': 'N/A',\n",
    "                    'Max_Temperature_C': 'N/A',\n",
    "                    'Temperature_Classification': 'N/A',\n",
    "                    'Fire_Risk_Level': 'N/A'\n",
    "                })\n",
    "            else:\n",
    "                temp_data = result['temperature_data']\n",
    "                \n",
    "                # Extract temperatures for each dataset\n",
    "                modis_terra_temp = temp_data.get('MODIS_TERRA', {}).get('temperature_mean_C', 'N/A')\n",
    "                modis_aqua_temp = temp_data.get('MODIS_AQUA', {}).get('temperature_mean_C', 'N/A')\n",
    "                landsat8_temp = temp_data.get('LANDSAT8', {}).get('temperature_mean_C', 'N/A')\n",
    "                landsat9_temp = temp_data.get('LANDSAT9', {}).get('temperature_mean_C', 'N/A')\n",
    "                \n",
    "                # Calculate average temperature from successful extractions\n",
    "                temps = []\n",
    "                max_temps = []\n",
    "                for dataset in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "                    if dataset in temp_data and 'error' not in temp_data[dataset]:\n",
    "                        temp = temp_data[dataset].get('temperature_mean_C')\n",
    "                        max_temp = temp_data[dataset].get('temperature_max_C')\n",
    "                        if temp is not None and temp > -50:  # Reasonable temperature check\n",
    "                            temps.append(temp)\n",
    "                        if max_temp is not None and max_temp > -50:\n",
    "                            max_temps.append(max_temp)\n",
    "                \n",
    "                avg_temp = sum(temps) / len(temps) if temps else 0\n",
    "                max_temp = max(max_temps) if max_temps else 0\n",
    "                \n",
    "                # Get temperature classification (prioritize MODIS data)\n",
    "                temp_classification = 'N/A'\n",
    "                fire_risk = 'N/A'\n",
    "                for dataset in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "                    if dataset in temp_data and 'error' not in temp_data[dataset]:\n",
    "                        temp_classification = temp_data[dataset].get('temperature_classification', 'N/A')\n",
    "                        fire_risk = temp_data[dataset].get('fire_risk_level', 'N/A')\n",
    "                        if temp_classification != 'N/A':\n",
    "                            break\n",
    "                \n",
    "                summary_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                    'Processing_Status': 'SUCCESS',\n",
    "                    'Error_Message': '',\n",
    "                    'MODIS_Terra_Temp_C': modis_terra_temp if modis_terra_temp != 'N/A' else '',\n",
    "                    'MODIS_Aqua_Temp_C': modis_aqua_temp if modis_aqua_temp != 'N/A' else '',\n",
    "                    'Landsat8_Temp_C': landsat8_temp if landsat8_temp != 'N/A' else '',\n",
    "                    'Landsat9_Temp_C': landsat9_temp if landsat9_temp != 'N/A' else '',\n",
    "                    'Average_Temperature_C': round(avg_temp, 2) if avg_temp > 0 else '',\n",
    "                    'Max_Temperature_C': round(max_temp, 2) if max_temp > 0 else '',\n",
    "                    'Temperature_Classification': temp_classification,\n",
    "                    'Fire_Risk_Level': fire_risk\n",
    "                })\n",
    "        \n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "        \n",
    "        # ========== DETAILED SHEETS ==========\n",
    "        \n",
    "        # MODIS Terra detailed data\n",
    "        modis_terra_data = []\n",
    "        for result in all_results:\n",
    "            if 'temperature_data' in result and 'MODIS_TERRA' in result['temperature_data']:\n",
    "                data = result['temperature_data']['MODIS_TERRA']\n",
    "                if 'error' not in data:\n",
    "                    modis_terra_data.append({\n",
    "                        'Country': result['processing_info']['country'],\n",
    "                        'Time_Period': result['processing_info']['time_period'],\n",
    "                        'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                        'Temperature_Mean_C': data.get('temperature_mean_C', ''),\n",
    "                        'Temperature_Min_C': data.get('temperature_min_C', ''),\n",
    "                        'Temperature_Max_C': data.get('temperature_max_C', ''),\n",
    "                        'Temperature_StdDev_C': data.get('temperature_stdDev_C', ''),\n",
    "                        'Temperature_Range_C': data.get('temperature_range_C', ''),\n",
    "                        'Temperature_Classification': data.get('temperature_classification', ''),\n",
    "                        'Fire_Weather_Index': data.get('fire_weather_index', ''),\n",
    "                        'Fire_Risk_Level': data.get('fire_risk_level', ''),\n",
    "                        'Pixel_Count': data.get('pixel_count', ''),\n",
    "                        'Image_Count': data.get('image_count', ''),\n",
    "                        'Resolution_m': data.get('scale_m', '')\n",
    "                    })\n",
    "        \n",
    "        if modis_terra_data:\n",
    "            modis_terra_df = pd.DataFrame(modis_terra_data)\n",
    "            modis_terra_df.to_excel(writer, sheet_name='MODIS_Terra_Details', index=False)\n",
    "        \n",
    "        # MODIS Aqua detailed data\n",
    "        modis_aqua_data = []\n",
    "        for result in all_results:\n",
    "            if 'temperature_data' in result and 'MODIS_AQUA' in result['temperature_data']:\n",
    "                data = result['temperature_data']['MODIS_AQUA']\n",
    "                if 'error' not in data:\n",
    "                    modis_aqua_data.append({\n",
    "                        'Country': result['processing_info']['country'],\n",
    "                        'Time_Period': result['processing_info']['time_period'],\n",
    "                        'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                        'Temperature_Mean_C': data.get('temperature_mean_C', ''),\n",
    "                        'Temperature_Min_C': data.get('temperature_min_C', ''),\n",
    "                        'Temperature_Max_C': data.get('temperature_max_C', ''),\n",
    "                        'Temperature_StdDev_C': data.get('temperature_stdDev_C', ''),\n",
    "                        'Temperature_Range_C': data.get('temperature_range_C', ''),\n",
    "                        'Temperature_Classification': data.get('temperature_classification', ''),\n",
    "                        'Fire_Weather_Index': data.get('fire_weather_index', ''),\n",
    "                        'Fire_Risk_Level': data.get('fire_risk_level', ''),\n",
    "                        'Pixel_Count': data.get('pixel_count', ''),\n",
    "                        'Image_Count': data.get('image_count', ''),\n",
    "                        'Resolution_m': data.get('scale_m', '')\n",
    "                    })\n",
    "        \n",
    "        if modis_aqua_data:\n",
    "            modis_aqua_df = pd.DataFrame(modis_aqua_data)\n",
    "            modis_aqua_df.to_excel(writer, sheet_name='MODIS_Aqua_Details', index=False)\n",
    "        \n",
    "        # Landsat 8 detailed data\n",
    "        landsat8_data = []\n",
    "        for result in all_results:\n",
    "            if 'temperature_data' in result and 'LANDSAT8' in result['temperature_data']:\n",
    "                data = result['temperature_data']['LANDSAT8']\n",
    "                if 'error' not in data:\n",
    "                    landsat8_data.append({\n",
    "                        'Country': result['processing_info']['country'],\n",
    "                        'Time_Period': result['processing_info']['time_period'],\n",
    "                        'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                        'Temperature_Mean_C': data.get('temperature_mean_C', ''),\n",
    "                        'Temperature_Min_C': data.get('temperature_min_C', ''),\n",
    "                        'Temperature_Max_C': data.get('temperature_max_C', ''),\n",
    "                        'Temperature_StdDev_C': data.get('temperature_stdDev_C', ''),\n",
    "                        'Temperature_Range_C': data.get('temperature_range_C', ''),\n",
    "                        'Temperature_Classification': data.get('temperature_classification', ''),\n",
    "                        'Fire_Weather_Index': data.get('fire_weather_index', ''),\n",
    "                        'Fire_Risk_Level': data.get('fire_risk_level', ''),\n",
    "                        'Pixel_Count': data.get('pixel_count', ''),\n",
    "                        'Image_Count': data.get('image_count', ''),\n",
    "                        'Resolution_m': data.get('scale_m', '')\n",
    "                    })\n",
    "        \n",
    "        if landsat8_data:\n",
    "            landsat8_df = pd.DataFrame(landsat8_data)\n",
    "            landsat8_df.to_excel(writer, sheet_name='Landsat8_Details', index=False)\n",
    "        \n",
    "        # Landsat 9 detailed data\n",
    "        landsat9_data = []\n",
    "        for result in all_results:\n",
    "            if 'temperature_data' in result and 'LANDSAT9' in result['temperature_data']:\n",
    "                data = result['temperature_data']['LANDSAT9']\n",
    "                if 'error' not in data:\n",
    "                    landsat9_data.append({\n",
    "                        'Country': result['processing_info']['country'],\n",
    "                        'Time_Period': result['processing_info']['time_period'],\n",
    "                        'Satellite_Acquisition_Date': result.get('satellite_acquisition_date', 'N/A'),\n",
    "                        'Temperature_Mean_C': data.get('temperature_mean_C', ''),\n",
    "                        'Temperature_Min_C': data.get('temperature_min_C', ''),\n",
    "                        'Temperature_Max_C': data.get('temperature_max_C', ''),\n",
    "                        'Temperature_StdDev_C': data.get('temperature_stdDev_C', ''),\n",
    "                        'Temperature_Range_C': data.get('temperature_range_C', ''),\n",
    "                        'Temperature_Classification': data.get('temperature_classification', ''),\n",
    "                        'Fire_Weather_Index': data.get('fire_weather_index', ''),\n",
    "                        'Fire_Risk_Level': data.get('fire_risk_level', ''),\n",
    "                        'Pixel_Count': data.get('pixel_count', ''),\n",
    "                        'Image_Count': data.get('image_count', ''),\n",
    "                        'Resolution_m': data.get('scale_m', '')\n",
    "                    })\n",
    "        \n",
    "        if landsat9_data:\n",
    "            landsat9_df = pd.DataFrame(landsat9_data)\n",
    "            landsat9_df.to_excel(writer, sheet_name='Landsat9_Details', index=False)\n",
    "        \n",
    "        # ========== ERROR LOG SHEET ==========\n",
    "        error_data = []\n",
    "        for result in all_results:\n",
    "            if 'error' in result:\n",
    "                error_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'XML_File': result['processing_info']['xml_file'],\n",
    "                    'Error_Type': 'Complete Failure',\n",
    "                    'Error_Message': result.get('error', 'Unknown error')\n",
    "                })\n",
    "            elif 'temperature_data' in result:\n",
    "                # Check for dataset-specific errors\n",
    "                for dataset, data in result['temperature_data'].items():\n",
    "                    if 'error' in data:\n",
    "                        error_data.append({\n",
    "                            'Country': result['processing_info']['country'],\n",
    "                            'Time_Period': result['processing_info']['time_period'],\n",
    "                            'XML_File': result['processing_info']['xml_file'],\n",
    "                            'Error_Type': f'{dataset} Dataset Error',\n",
    "                            'Error_Message': data['error']\n",
    "                        })\n",
    "        \n",
    "        if error_data:\n",
    "            error_df = pd.DataFrame(error_data)\n",
    "            error_df.to_excel(writer, sheet_name='Error_Log', index=False)\n",
    "        \n",
    "        # ========== METADATA SHEET ==========\n",
    "        metadata_data = []\n",
    "        for result in all_results:\n",
    "            if 'metadata' in result:\n",
    "                metadata = result['metadata']\n",
    "                spatial = metadata.get('spatial_extent', {})\n",
    "                temporal = metadata.get('temporal_extent', {})\n",
    "                technical = metadata.get('technical_specs', {})\n",
    "                \n",
    "                metadata_data.append({\n",
    "                    'Country': result['processing_info']['country'],\n",
    "                    'Time_Period': result['processing_info']['time_period'],\n",
    "                    'Product_Title': metadata.get('product_info', {}).get('title', ''),\n",
    "                    'West_Bound_Longitude': spatial.get('west_bound', ''),\n",
    "                    'East_Bound_Longitude': spatial.get('east_bound', ''),\n",
    "                    'South_Bound_Latitude': spatial.get('south_bound', ''),\n",
    "                    'North_Bound_Latitude': spatial.get('north_bound', ''),\n",
    "                    'Center_Latitude': spatial.get('center_lat', ''),\n",
    "                    'Center_Longitude': spatial.get('center_lon', ''),\n",
    "                    'Start_Time': temporal.get('start_time', ''),\n",
    "                    'End_Time': temporal.get('end_time', ''),\n",
    "                    'Spatial_Resolution_m': technical.get('spatial_resolution', ''),\n",
    "                    'CRS_Code': technical.get('crs_code', '')\n",
    "                })\n",
    "        \n",
    "        if metadata_data:\n",
    "            metadata_df = pd.DataFrame(metadata_data)\n",
    "            metadata_df.to_excel(writer, sheet_name='Metadata', index=False)\n",
    "    \n",
    "    print(f\"\\\\n📊 Excel file created: {output_path}\")\n",
    "    print(f\"📋 Sheets included:\")\n",
    "    print(f\"   - Summary: Overview of all extractions\")\n",
    "    print(f\"   - MODIS_Terra_Details: Detailed MODIS Terra temperature data\")\n",
    "    print(f\"   - MODIS_Aqua_Details: Detailed MODIS Aqua temperature data\")\n",
    "    print(f\"   - Landsat8_Details: Detailed Landsat 8 temperature data\")\n",
    "    print(f\"   - Landsat9_Details: Detailed Landsat 9 temperature data\")\n",
    "    print(f\"   - Error_Log: Failed extractions and errors\")\n",
    "    print(f\"   - Metadata: Spatial and temporal metadata\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"Excel export function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Temperature Data Extraction for All XML Files\n",
    "\n",
    "print(\"🌡️ STARTING TEMPERATURE DATA EXTRACTION FOR ALL XML FILES\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Process all XML files\n",
    "try:\n",
    "    all_results = process_all_xml_files()\n",
    "    \n",
    "    # Create Excel export\n",
    "    print(\"\\\\n📊 CREATING EXCEL EXPORT...\")\n",
    "    excel_file_path = create_excel_export(all_results)\n",
    "    \n",
    "    # Summary statistics\n",
    "    successful_count = sum(1 for result in all_results if 'error' not in result)\n",
    "    failed_count = len(all_results) - successful_count\n",
    "    \n",
    "    print(f\"\\\\n🎯 EXTRACTION COMPLETE!\")\n",
    "    print(f\"✅ Successful extractions: {successful_count}\")\n",
    "    print(f\"❌ Failed extractions: {failed_count}\")\n",
    "    print(f\"📊 Total locations processed: {len(all_results)}\")\n",
    "    print(f\"📁 Excel file saved: {excel_file_path}\")\n",
    "    \n",
    "    # Calculate some overall statistics\n",
    "    if successful_count > 0:\n",
    "        all_temps = []\n",
    "        all_max_temps = []\n",
    "        for result in all_results:\n",
    "            if 'temperature_data' in result:\n",
    "                for dataset in ['MODIS_TERRA', 'MODIS_AQUA', 'LANDSAT8', 'LANDSAT9']:\n",
    "                    if dataset in result['temperature_data'] and 'error' not in result['temperature_data'][dataset]:\n",
    "                        temp = result['temperature_data'][dataset].get('temperature_mean_C')\n",
    "                        max_temp = result['temperature_data'][dataset].get('temperature_max_C')\n",
    "                        if temp is not None and temp > -50:  # Reasonable temperature check\n",
    "                            all_temps.append(temp)\n",
    "                        if max_temp is not None and max_temp > -50:\n",
    "                            all_max_temps.append(max_temp)\n",
    "        \n",
    "        if all_temps:\n",
    "            avg_global_temp = sum(all_temps) / len(all_temps)\n",
    "            min_temp = min(all_temps)\n",
    "            max_temp = max(all_max_temps) if all_max_temps else max(all_temps)\n",
    "            \n",
    "            print(f\"\\\\n📈 OVERALL TEMPERATURE STATISTICS:\")\n",
    "            print(f\"   Average temperature: {avg_global_temp:.2f} °C\")\n",
    "            print(f\"   Minimum temperature: {min_temp:.2f} °C\")\n",
    "            print(f\"   Maximum temperature: {max_temp:.2f} °C\")\n",
    "            print(f\"   Total temperature measurements: {len(all_temps)}\")\n",
    "            \n",
    "            # Overall temperature classification\n",
    "            risk_level, risk_desc = classify_temperature_conditions(avg_global_temp)\n",
    "            fire_index, fire_risk = calculate_fire_weather_index(avg_global_temp)\n",
    "            print(f\"   Overall temperature classification: {risk_level} ({risk_desc})\")\n",
    "            print(f\"   Overall fire risk level: {fire_risk}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR during batch processing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c79afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preview and Validation\n",
    "\n",
    "def display_extraction_summary(all_results):\n",
    "    \"\"\"\n",
    "    Display a summary of the extraction results for validation.\n",
    "    \"\"\"\n",
    "    if not all_results:\n",
    "        print(\"No results to display.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\\\n📋 EXTRACTION RESULTS SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, result in enumerate(all_results[:10]):  # Show first 10 results\n",
    "        country = result['processing_info']['country']\n",
    "        period = result['processing_info']['time_period']\n",
    "        \n",
    "        print(f\"\\\\n{i+1}. {country} ({period})\")\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"   ❌ Status: FAILED\")\n",
    "            print(f\"   Error: {result['error']}\")\n",
    "        else:\n",
    "            print(f\"   ✅ Status: SUCCESS\")\n",
    "            print(f\"   📅 Date: {result.get('satellite_acquisition_date', 'N/A')}\")\n",
    "            \n",
    "            if 'temperature_data' in result:\n",
    "                for dataset, data in result['temperature_data'].items():\n",
    "                    if 'error' not in data:\n",
    "                        temp = data.get('temperature_mean_C', 0)\n",
    "                        temp_class = data.get('temperature_classification', 'N/A')\n",
    "                        fire_risk = data.get('fire_risk_level', 'N/A')\n",
    "                        print(f\"   🌡️  {dataset}: {temp:.1f}°C ({temp_class} - {fire_risk} fire risk)\")\n",
    "    \n",
    "    if len(all_results) > 10:\n",
    "        print(f\"\\\\n... and {len(all_results) - 10} more results\")\n",
    "    \n",
    "    print(f\"\\\\n📊 Dataset Success Rates:\")\n",
    "    dataset_stats = {'MODIS_TERRA': 0, 'MODIS_AQUA': 0, 'LANDSAT8': 0, 'LANDSAT9': 0}\n",
    "    total_successful = 0\n",
    "    \n",
    "    for result in all_results:\n",
    "        if 'temperature_data' in result:\n",
    "            total_successful += 1\n",
    "            for dataset in dataset_stats.keys():\n",
    "                if dataset in result['temperature_data'] and 'error' not in result['temperature_data'][dataset]:\n",
    "                    dataset_stats[dataset] += 1\n",
    "    \n",
    "    for dataset, count in dataset_stats.items():\n",
    "        if total_successful > 0:\n",
    "            success_rate = (count / total_successful) * 100\n",
    "            print(f\"   {dataset}: {count}/{total_successful} ({success_rate:.1f}%)\")\n",
    "    \n",
    "    # Temperature distribution analysis\n",
    "    print(f\"\\\\n🌡️ Temperature Distribution Analysis:\")\n",
    "    temp_ranges = {'COOL (<15°C)': 0, 'MODERATE (15-25°C)': 0, 'WARM (25-35°C)': 0, \n",
    "                   'HOT (35-45°C)': 0, 'EXTREME_HOT (>45°C)': 0}\n",
    "    \n",
    "    for result in all_results:\n",
    "        if 'temperature_data' in result:\n",
    "            for dataset, data in result['temperature_data'].items():\n",
    "                if 'error' not in data:\n",
    "                    temp_class = data.get('temperature_classification', 'N/A')\n",
    "                    if temp_class in temp_ranges:\n",
    "                        temp_ranges[temp_class] += 1\n",
    "    \n",
    "    total_measurements = sum(temp_ranges.values())\n",
    "    if total_measurements > 0:\n",
    "        for temp_range, count in temp_ranges.items():\n",
    "            percentage = (count / total_measurements) * 100\n",
    "            print(f\"   {temp_range}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "# Display summary if results exist\n",
    "if 'all_results' in locals():\n",
    "    display_extraction_summary(all_results)\n",
    "else:\n",
    "    print(\"Run the extraction cell first to see results preview.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Status and Usage Instructions\n",
    "\n",
    "print(\"🎯 TEMPERATURE EXTRACTION SYSTEM - COMPLETE\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "\n",
    "print(\"✅ SYSTEM FEATURES:\")\n",
    "print(\"   • Batch processing of all XML files in the database\")\n",
    "print(\"   • Multi-dataset temperature extraction (MODIS Terra/Aqua, Landsat 8/9)\")\n",
    "print(\"   • Automatic satellite acquisition date extraction\")\n",
    "print(\"   • Comprehensive Excel export with multiple sheets\")\n",
    "print(\"   • Advanced cloud masking and quality filtering\")\n",
    "print(\"   • Temperature classification and fire risk assessment\")\n",
    "print(\"   • Statistical analysis (mean, min, max, std deviation)\")\n",
    "print(\"   • Error handling and detailed logging\")\n",
    "print()\n",
    "\n",
    "print(\"📊 EXCEL OUTPUT STRUCTURE:\")\n",
    "print(\"   • Summary Sheet: Overview of all extractions with key metrics\")\n",
    "print(\"   • MODIS_Terra_Details: Detailed MODIS Terra temperature data\")\n",
    "print(\"   • MODIS_Aqua_Details: Detailed MODIS Aqua temperature data\")\n",
    "print(\"   • Landsat8_Details: Detailed Landsat 8 temperature data\")\n",
    "print(\"   • Landsat9_Details: Detailed Landsat 9 temperature data\")\n",
    "print(\"   • Error_Log: Failed extractions and error messages\")\n",
    "print(\"   • Metadata: Spatial and temporal metadata for each location\")\n",
    "print()\n",
    "\n",
    "print(\"🌡️ DATA INCLUDED:\")\n",
    "print(\"   • Country and time period identifiers\")\n",
    "print(\"   • Satellite acquisition dates (from XML metadata)\")\n",
    "print(\"   • Temperature statistics (mean, min, max, std deviation, range)\")\n",
    "print(\"   • Temperature classification (Cool, Moderate, Warm, Hot, Extreme Hot)\")\n",
    "print(\"   • Fire Weather Index and Fire Risk Level\")\n",
    "print(\"   • Pixel counts and image counts\")\n",
    "print(\"   • Spatial coordinates and resolution information\")\n",
    "print(\"   • Quality-filtered data with cloud masking\")\n",
    "print()\n",
    "\n",
    "print(\"📁 OUTPUT LOCATION:\")\n",
    "if 'excel_file_path' in locals():\n",
    "    print(f\"   Excel file saved to: {excel_file_path}\")\n",
    "else:\n",
    "    print(f\"   Excel files will be saved to: {OUTPUT_FOLDER}\")\n",
    "print()\n",
    "\n",
    "print(\"🚀 READY FOR USE:\")\n",
    "print(\"   • Import Excel file into your fire prediction model\")\n",
    "print(\"   • Use temperature data for fire risk modeling\")\n",
    "print(\"   • Analyze temperature patterns across different regions\")\n",
    "print(\"   • Correlate temperature conditions with fire occurrence\")\n",
    "print(\"   • Compare pre-fire and post-fire temperature conditions\")\n",
    "print(\"   • Integrate with wind and vegetation data for comprehensive analysis\")\n",
    "print()\n",
    "\n",
    "print(\"🔥 FIRE PREDICTION INTEGRATION:\")\n",
    "print(\"   • High-resolution temperature data for improved fire modeling\")\n",
    "print(\"   • Multi-sensor validation for robust temperature estimates\")\n",
    "print(\"   • Temporal analysis capability for fire risk assessment\")\n",
    "print(\"   • Quality-controlled data ready for machine learning models\")\n",
    "print()\n",
    "\n",
    "print(\"💫 EXTRACTION COMPLETE! Ready for fire prediction analysis! 💫\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpaceChallenges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

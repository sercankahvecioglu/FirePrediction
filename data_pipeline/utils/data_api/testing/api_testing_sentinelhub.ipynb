{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "390209a0",
   "metadata": {},
   "source": [
    "# Fire Prediction - Sentinel Hub API Integration\n",
    "\n",
    "This notebook demonstrates how to extract metadata from Sentinel-2 XML files and integrate with the Sentinel Hub API for fire prediction analysis.\n",
    "\n",
    "## Objectives:\n",
    "- Extract essential metadata from XML files (coordinates, dates, tile info)\n",
    "- Transform coordinates from UTM to WGS84\n",
    "- Create Sentinel Hub API requests for pre/post fire imagery\n",
    "- Prepare data for fire damage analysis\n",
    "\n",
    "## Requirements:\n",
    "- Valid Sentinel Hub credentials (CLIENT_ID and CLIENT_SECRET) in `.env` file\n",
    "- XML metadata files from Sentinel-2 imagery\n",
    "- Python libraries: sentinelhub, pyproj, shapely\n",
    "\n",
    "## Usage:\n",
    "1. Run all cells in sequence\n",
    "2. Check the summary section for pipeline status\n",
    "3. Use the created API requests to download satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d28c5836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Sentinel Hub API Testing for Fire Prediction\n",
    "# Metadata extraction from XML files and Sentinel Hub API integration\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import datetime as dt\n",
    "\n",
    "# Data handling and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Geospatial libraries\n",
    "import pyproj\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import transform\n",
    "\n",
    "# Sentinel Hub API\n",
    "from sentinelhub import CRS, BBox, DataCollection, MimeType, SentinelHubRequest, SHConfig, generate_evalscript\n",
    "from sentinelhub.api.catalog import get_available_timestamps\n",
    "\n",
    "# Cloud detection (optional)\n",
    "from s2cloudless import S2PixelCloudDetector\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\" All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f27005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel Hub credentials configured successfully!\n",
      "Client ID: 26aa2248...\n",
      "\n",
      "Configuration ready!\n"
     ]
    }
   ],
   "source": [
    "# Configuration Setup for Sentinel Hub API\n",
    "\n",
    "# Load credentials from environment variables\n",
    "CLIENT_ID = os.getenv('CLIENT_ID', None)\n",
    "CLIENT_SECRET = os.getenv('CLIENT_SECRET', None)\n",
    "\n",
    "# Initialize Sentinel Hub configuration\n",
    "config = SHConfig()\n",
    "\n",
    "# Set credentials if available\n",
    "if CLIENT_ID and CLIENT_SECRET:\n",
    "    config.sh_client_id = CLIENT_ID\n",
    "    config.sh_client_secret = CLIENT_SECRET\n",
    "    print(\"Sentinel Hub credentials configured successfully!\")\n",
    "    print(f\"Client ID: {CLIENT_ID[:8]}...\")\n",
    "else:\n",
    "    print(\"   Sentinel Hub credentials not found in environment variables\")\n",
    "    print(\"   Set CLIENT_ID and CLIENT_SECRET in your .env file to use the API\")\n",
    "    print(\"   You can still use the metadata extraction functionality\")\n",
    "\n",
    "print(\"\\nConfiguration ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb1f24",
   "metadata": {},
   "source": [
    "# 1. Metadata Extraction Classes\n",
    "\n",
    "This section contains the core classes for extracting metadata from Sentinel-2 XML files and integrating with the Sentinel Hub API.\n",
    "\n",
    "##  Features:\n",
    "- **MetadataExtractor**: Extracts essential data from XML metadata files\n",
    "- **SentinelHubDataExtractor**: Creates API requests from extracted metadata\n",
    "- **Coordinate transformation**: UTM to WGS84 conversion\n",
    "- **Fire analysis support**: Pre/post fire data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82f59a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetadataExtractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class MetadataExtractor:\n",
    "    \"\"\"\n",
    "    A robust class to extract essential metadata from Sentinel-2 XML files\n",
    "    for use with Sentinel Hub API\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, xml_folder_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the MetadataExtractor\n",
    "        \n",
    "        Args:\n",
    "            xml_folder_path (str): Path to the folder containing XML files\n",
    "        \"\"\"\n",
    "        self.xml_folder_path = Path(xml_folder_path)\n",
    "        self.metadata_cache = {}\n",
    "    \n",
    "    def parse_xml_file(self, xml_file_path: str, verbose: bool = False) -> Dict:\n",
    "        \"\"\"\n",
    "        Parse a single XML metadata file and extract essential information for Sentinel Hub API\n",
    "        \n",
    "        Args:\n",
    "            xml_file_path (str): Path to the XML file\n",
    "            verbose (bool): Print detailed parsing information\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Extracted metadata information\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tree = ET.parse(xml_file_path)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            # Define namespace\n",
    "            namespaces = {\n",
    "                'n1': 'https://psd-14.sentinel2.eo.esa.int/PSD/S2_PDI_Level-1C_Tile_Metadata.xsd'\n",
    "            }\n",
    "            \n",
    "            # Helper function to find elements with fallback methods\n",
    "            def find_element(xpath_with_ns, xpath_without_ns=None):\n",
    "                element = root.find(xpath_with_ns, namespaces)\n",
    "                if element is not None:\n",
    "                    return element\n",
    "                if xpath_without_ns:\n",
    "                    return root.find(xpath_without_ns)\n",
    "                simple_xpath = xpath_with_ns.replace('n1:', '').replace('//', '.')\n",
    "                return root.find(f\".//{simple_xpath}\")\n",
    "            \n",
    "            # Extract essential information\n",
    "            tile_id_elem = find_element('.//n1:TILE_ID', './/TILE_ID')\n",
    "            sensing_time_elem = find_element('.//n1:SENSING_TIME', './/SENSING_TIME')\n",
    "            cs_name_elem = find_element('.//n1:HORIZONTAL_CS_NAME', './/HORIZONTAL_CS_NAME')\n",
    "            cs_code_elem = find_element('.//n1:HORIZONTAL_CS_CODE', './/HORIZONTAL_CS_CODE')\n",
    "            \n",
    "            # Geometric information for 10m resolution\n",
    "            geoposition_10m = find_element('.//n1:Geoposition[@resolution=\"10\"]', './/Geoposition[@resolution=\"10\"]')\n",
    "            size_10m = find_element('.//n1:Size[@resolution=\"10\"]', './/Size[@resolution=\"10\"]')\n",
    "            \n",
    "            # Extract coordinate values\n",
    "            ulx_val = uly_val = xdim_val = ydim_val = None\n",
    "            if geoposition_10m is not None:\n",
    "                ulx_elem = geoposition_10m.find('ULX') if geoposition_10m.find('ULX') is not None else geoposition_10m.find('.//ULX')\n",
    "                uly_elem = geoposition_10m.find('ULY') if geoposition_10m.find('ULY') is not None else geoposition_10m.find('.//ULY')\n",
    "                xdim_elem = geoposition_10m.find('XDIM') if geoposition_10m.find('XDIM') is not None else geoposition_10m.find('.//XDIM')\n",
    "                ydim_elem = geoposition_10m.find('YDIM') if geoposition_10m.find('YDIM') is not None else geoposition_10m.find('.//YDIM')\n",
    "                \n",
    "                ulx_val = float(ulx_elem.text) if ulx_elem is not None else None\n",
    "                uly_val = float(uly_elem.text) if uly_elem is not None else None\n",
    "                xdim_val = float(xdim_elem.text) if xdim_elem is not None else None\n",
    "                ydim_val = float(ydim_elem.text) if ydim_elem is not None else None\n",
    "            \n",
    "            # Extract size values\n",
    "            nrows_val = ncols_val = None\n",
    "            if size_10m is not None:\n",
    "                nrows_elem = size_10m.find('NROWS') if size_10m.find('NROWS') is not None else size_10m.find('.//NROWS')\n",
    "                ncols_elem = size_10m.find('NCOLS') if size_10m.find('NCOLS') is not None else size_10m.find('.//NCOLS')\n",
    "                \n",
    "                nrows_val = int(nrows_elem.text) if nrows_elem is not None else None\n",
    "                ncols_val = int(ncols_elem.text) if ncols_elem is not None else None\n",
    "            \n",
    "            # Create metadata dictionary\n",
    "            metadata = {\n",
    "                'file_path': xml_file_path,\n",
    "                'tile_id': tile_id_elem.text if tile_id_elem is not None else None,\n",
    "                'sensing_time': sensing_time_elem.text if sensing_time_elem is not None else None,\n",
    "                'coordinate_system_name': cs_name_elem.text if cs_name_elem is not None else None,\n",
    "                'coordinate_system_code': cs_code_elem.text if cs_code_elem is not None else None,\n",
    "                'upper_left_x': ulx_val,\n",
    "                'upper_left_y': uly_val,\n",
    "                'x_dimension': xdim_val,\n",
    "                'y_dimension': ydim_val,\n",
    "                'rows': nrows_val,\n",
    "                'cols': ncols_val,\n",
    "            }\n",
    "            \n",
    "            if verbose and metadata['tile_id']:\n",
    "                print(f\"{Path(xml_file_path).name}: {metadata['tile_id']}\")\n",
    "            \n",
    "            return metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"Error parsing {Path(xml_file_path).name}: {str(e)}\")\n",
    "            return {}\n",
    "    \n",
    "    def get_bounding_box_wgs84(self, metadata: Dict) -> Optional[Tuple[float, float, float, float]]:\n",
    "        \"\"\"\n",
    "        Calculate bounding box in WGS84 coordinates from UTM metadata\n",
    "        \n",
    "        Args:\n",
    "            metadata (Dict): Metadata dictionary from parse_xml_file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple: (min_lon, min_lat, max_lon, max_lat) or None if conversion fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            required_keys = ['upper_left_x', 'upper_left_y', 'x_dimension', 'y_dimension', 'rows', 'cols']\n",
    "            \n",
    "            if not all(key in metadata and metadata[key] is not None for key in required_keys):\n",
    "                return None\n",
    "            \n",
    "            ulx = metadata['upper_left_x']\n",
    "            uly = metadata['upper_left_y']\n",
    "            x_dim = abs(metadata['x_dimension'])\n",
    "            y_dim = abs(metadata['y_dimension'])\n",
    "            rows = metadata['rows']\n",
    "            cols = metadata['cols']\n",
    "            \n",
    "            # Calculate corner coordinates in UTM\n",
    "            min_x, max_x = ulx, ulx + (cols * x_dim)\n",
    "            max_y, min_y = uly, uly - (rows * y_dim)\n",
    "            \n",
    "            # Extract EPSG code and transform coordinates\n",
    "            epsg_code = metadata['coordinate_system_code']\n",
    "            if epsg_code and epsg_code.startswith('EPSG:'):\n",
    "                epsg_num = int(epsg_code.split(':')[1])\n",
    "                \n",
    "                utm_crs = pyproj.CRS(f'EPSG:{epsg_num}')\n",
    "                wgs84_crs = pyproj.CRS('EPSG:4326')\n",
    "                transformer = pyproj.Transformer.from_crs(utm_crs, wgs84_crs, always_xy=True)\n",
    "                \n",
    "                min_lon, min_lat = transformer.transform(min_x, min_y)\n",
    "                max_lon, max_lat = transformer.transform(max_x, max_y)\n",
    "                \n",
    "                return (min_lon, min_lat, max_lon, max_lat)\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "            \n",
    "        return None\n",
    "    \n",
    "    def extract_all_metadata(self, verbose: bool = True) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Extract metadata from all XML files in the folder\n",
    "        \n",
    "        Args:\n",
    "            verbose (bool): Print progress information\n",
    "            \n",
    "        Returns:\n",
    "            List[Dict]: List of metadata dictionaries\n",
    "        \"\"\"\n",
    "        all_metadata = []\n",
    "        \n",
    "        xml_files = list(self.xml_folder_path.glob(\"*metadata*.xml\"))\n",
    "        if verbose:\n",
    "            print(f\"üìÅ Found {len(xml_files)} metadata XML files\")\n",
    "        \n",
    "        for xml_file in xml_files:\n",
    "            metadata = self.parse_xml_file(str(xml_file), verbose=False)\n",
    "            \n",
    "            if metadata and metadata.get('tile_id'):\n",
    "                # Add file info\n",
    "                metadata['file_name'] = xml_file.name\n",
    "                metadata['location'] = self.extract_location_from_filename(xml_file.name)\n",
    "                metadata['time_period'] = self.extract_time_period_from_filename(xml_file.name)\n",
    "                \n",
    "                # Calculate WGS84 bounding box\n",
    "                bbox_wgs84 = self.get_bounding_box_wgs84(metadata)\n",
    "                if bbox_wgs84:\n",
    "                    metadata['bbox_wgs84'] = bbox_wgs84\n",
    "                \n",
    "                all_metadata.append(metadata)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Successfully extracted metadata from {len(all_metadata)} files\")\n",
    "        return all_metadata\n",
    "    \n",
    "    def extract_location_from_filename(self, filename: str) -> str:\n",
    "        \"\"\"Extract location name from filename\"\"\"\n",
    "        parts = filename.replace('.xml', '').split('_')\n",
    "        return parts[0] if parts else 'unknown'\n",
    "    \n",
    "    def extract_time_period_from_filename(self, filename: str) -> str:\n",
    "        \"\"\"Extract time period (pre/post) from filename\"\"\"\n",
    "        if 'pre' in filename:\n",
    "            return 'pre'\n",
    "        elif 'post' in filename:\n",
    "            return 'post'\n",
    "        return 'unknown'\n",
    "    \n",
    "    def get_metadata_for_api(self, metadata: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract only the essential data needed for Sentinel Hub API calls\n",
    "        \n",
    "        Args:\n",
    "            metadata (Dict): Full metadata dictionary\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Simplified metadata for API use\n",
    "        \"\"\"\n",
    "        api_metadata = {\n",
    "            'location': metadata.get('location'),\n",
    "            'time_period': metadata.get('time_period'),\n",
    "            'sensing_time': metadata.get('sensing_time'),\n",
    "            'tile_id': metadata.get('tile_id'),\n",
    "        }\n",
    "        \n",
    "        if 'bbox_wgs84' in metadata:\n",
    "            bbox = metadata['bbox_wgs84']\n",
    "            api_metadata['bbox'] = {\n",
    "                'min_lon': bbox[0],\n",
    "                'min_lat': bbox[1],\n",
    "                'max_lon': bbox[2],\n",
    "                'max_lat': bbox[3]\n",
    "            }\n",
    "        \n",
    "        return api_metadata\n",
    "\n",
    "# Initialize the metadata extractor\n",
    "xml_folder_path = \"/Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\"\n",
    "extractor = MetadataExtractor(xml_folder_path)\n",
    "\n",
    "print(\"MetadataExtractor initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc00ba4",
   "metadata": {},
   "source": [
    "## Sentinel Hub API Integration\n",
    "\n",
    "Integration class for creating API requests from extracted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bb1de9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentinel Hub data extractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "class SentinelHubDataExtractor:\n",
    "    \"\"\"\n",
    "    A class to extract data from Sentinel Hub API using metadata from XML files\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SHConfig):\n",
    "        \"\"\"\n",
    "        Initialize the SentinelHubDataExtractor\n",
    "        \n",
    "        Args:\n",
    "            config (SHConfig): Sentinel Hub configuration\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "    \n",
    "    def create_bbox_from_metadata(self, metadata: Dict, buffer_km: float = 1.0) -> BBox:\n",
    "        \"\"\"\n",
    "        Create a BBox object from metadata with optional buffer\n",
    "        \n",
    "        Args:\n",
    "            metadata (Dict): Metadata dictionary containing bbox_wgs84\n",
    "            buffer_km (float): Buffer distance in kilometers\n",
    "            \n",
    "        Returns:\n",
    "            BBox: Sentinel Hub BBox object\n",
    "        \"\"\"\n",
    "        if 'bbox_wgs84' not in metadata:\n",
    "            raise ValueError(\"No WGS84 bounding box found in metadata\")\n",
    "        \n",
    "        min_lon, min_lat, max_lon, max_lat = metadata['bbox_wgs84']\n",
    "        \n",
    "        # Add buffer (approximately 1km = 0.009 degrees)\n",
    "        buffer_deg = buffer_km * 0.009\n",
    "        \n",
    "        bbox = BBox(\n",
    "            bbox=[min_lon - buffer_deg, min_lat - buffer_deg, \n",
    "                  max_lon + buffer_deg, max_lat + buffer_deg],\n",
    "            crs=CRS.WGS84\n",
    "        )\n",
    "        \n",
    "        return bbox\n",
    "    \n",
    "    def get_evalscript_rgb(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate evalscript for RGB visualization\n",
    "        \n",
    "        Returns:\n",
    "            str: Evalscript for RGB bands\n",
    "        \"\"\"\n",
    "        return \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B02\", \"B03\", \"B04\"],\n",
    "                output: { bands: 3 }\n",
    "            };\n",
    "        }\n",
    "        \n",
    "        function evaluatePixel(sample) {\n",
    "            return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n",
    "        }\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_evalscript_ndvi(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate evalscript for NDVI calculation\n",
    "        \n",
    "        Returns:\n",
    "            str: Evalscript for NDVI\n",
    "        \"\"\"\n",
    "        return \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B04\", \"B08\"],\n",
    "                output: { bands: 1, sampleType: \"FLOAT32\" }\n",
    "            };\n",
    "        }\n",
    "        \n",
    "        function evaluatePixel(sample) {\n",
    "            let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04);\n",
    "            return [ndvi];\n",
    "        }\n",
    "        \"\"\"\n",
    "    \n",
    "    def get_evalscript_all_bands(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate evalscript for all Sentinel-2 bands\n",
    "        \n",
    "        Returns:\n",
    "            str: Evalscript for all bands\n",
    "        \"\"\"\n",
    "        return \"\"\"\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B11\", \"B12\"],\n",
    "                output: { bands: 12, sampleType: \"UINT16\" }\n",
    "            };\n",
    "        }\n",
    "        \n",
    "        function evaluatePixel(sample) {\n",
    "            return [sample.B01, sample.B02, sample.B03, sample.B04, \n",
    "                   sample.B05, sample.B06, sample.B07, sample.B08,\n",
    "                   sample.B8A, sample.B09, sample.B11, sample.B12];\n",
    "        }\n",
    "        \"\"\"\n",
    "    \n",
    "    def create_request(self, metadata: Dict, evalscript: str, \n",
    "                      time_range: Tuple[str, str], resolution: int = 10,\n",
    "                      image_format: MimeType = MimeType.TIFF) -> SentinelHubRequest:\n",
    "        \"\"\"\n",
    "        Create a Sentinel Hub request based on metadata\n",
    "        \n",
    "        Args:\n",
    "            metadata (Dict): Metadata from XML file\n",
    "            evalscript (str): Evalscript for data processing\n",
    "            time_range (Tuple[str, str]): Time range as (start_date, end_date)\n",
    "            resolution (int): Output resolution in meters\n",
    "            image_format (MimeType): Output image format\n",
    "            \n",
    "        Returns:\n",
    "            SentinelHubRequest: Configured request object\n",
    "        \"\"\"\n",
    "        bbox = self.create_bbox_from_metadata(metadata)\n",
    "        \n",
    "        request = SentinelHubRequest(\n",
    "            evalscript=evalscript,\n",
    "            input_data=[\n",
    "                SentinelHubRequest.input_data(\n",
    "                    data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                    time_interval=time_range,\n",
    "                    mosaicking_order='leastCC'  # Least cloud coverage\n",
    "                )\n",
    "            ],\n",
    "            responses=[\n",
    "                SentinelHubRequest.output_response('default', image_format)\n",
    "            ],\n",
    "            bbox=bbox,\n",
    "            size=[512, 512],  # Can be adjusted based on needs\n",
    "            config=self.config\n",
    "        )\n",
    "        \n",
    "        return request\n",
    "    \n",
    "    def extract_data_for_location(self, location_metadata: List[Dict], \n",
    "                                 evalscript_type: str = 'rgb',\n",
    "                                 days_buffer: int = 30) -> Dict:\n",
    "        \"\"\"\n",
    "        Extract data for a specific location (pre and post fire)\n",
    "        \n",
    "        Args:\n",
    "            location_metadata (List[Dict]): List of metadata for the same location\n",
    "            evalscript_type (str): Type of evalscript ('rgb', 'ndvi', 'all_bands')\n",
    "            days_buffer (int): Number of days to search around the sensing date\n",
    "            \n",
    "        Returns:\n",
    "            Dict: Dictionary containing pre and post fire data\n",
    "        \"\"\"\n",
    "        # Get evalscript based on type\n",
    "        if evalscript_type == 'rgb':\n",
    "            evalscript = self.get_evalscript_rgb()\n",
    "        elif evalscript_type == 'ndvi':\n",
    "            evalscript = self.get_evalscript_ndvi()\n",
    "        elif evalscript_type == 'all_bands':\n",
    "            evalscript = self.get_evalscript_all_bands()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown evalscript type: {evalscript_type}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for metadata in location_metadata:\n",
    "            if metadata['sensing_time']:\n",
    "                # Parse sensing time and create time range\n",
    "                sensing_date = dt.datetime.fromisoformat(metadata['sensing_time'].replace('Z', '+00:00'))\n",
    "                start_date = (sensing_date - dt.timedelta(days=days_buffer)).strftime('%Y-%m-%d')\n",
    "                end_date = (sensing_date + dt.timedelta(days=days_buffer)).strftime('%Y-%m-%d')\n",
    "                \n",
    "                # Create request\n",
    "                request = self.create_request(\n",
    "                    metadata=metadata,\n",
    "                    evalscript=evalscript,\n",
    "                    time_range=(start_date, end_date)\n",
    "                )\n",
    "                \n",
    "                # Store request for the time period\n",
    "                time_period = metadata.get('time_period', 'unknown')\n",
    "                results[f\"{time_period}_request\"] = request\n",
    "                results[f\"{time_period}_metadata\"] = metadata\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize the Sentinel Hub data extractor\n",
    "if CLIENT_ID and CLIENT_SECRET:\n",
    "    config.sh_client_id = CLIENT_ID\n",
    "    config.sh_client_secret = CLIENT_SECRET\n",
    "    \n",
    "    data_extractor = SentinelHubDataExtractor(config)\n",
    "    print(\"Sentinel Hub data extractor initialized successfully!\")\n",
    "else:\n",
    "    print(\"Warning: CLIENT_ID and CLIENT_SECRET not found. Please set them in your .env file.\")\n",
    "    print(\"You can still use the metadata extraction functionality.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957975f2",
   "metadata": {},
   "source": [
    "# 2. Practical Examples\n",
    "\n",
    "This section demonstrates how to use the metadata extractor and Sentinel Hub API integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06b656a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata from XML files...\n",
      "üìÅ Found 24 metadata XML files\n",
      "Successfully extracted metadata from 24 files\n",
      "\n",
      "Found 12 unique locations:\n",
      "   usa: 1 pre-fire, 1 post-fire\n",
      "   chile: 1 pre-fire, 1 post-fire\n",
      "   sardinia: 1 pre-fire, 1 post-fire\n",
      "   greece2: 1 pre-fire, 1 post-fire\n",
      "   spain: 1 pre-fire, 1 post-fire\n",
      "   usa2: 1 pre-fire, 1 post-fire\n",
      "   turkey: 1 pre-fire, 1 post-fire\n",
      "   france: 1 pre-fire, 1 post-fire\n",
      "   spain2: 1 pre-fire, 1 post-fire\n",
      "   spain3: 1 pre-fire, 1 post-fire\n",
      "   greece: 1 pre-fire, 1 post-fire\n",
      "   paraguay: 1 pre-fire, 1 post-fire\n",
      "\n",
      "Sample metadata:\n",
      "   Location: usa\n",
      "   Time: 2025-07-15T18:24:31.742376Z\n",
      "   Tile: S2C_OPER_MSI_L1C_TL_2CPS_20250715T214706_A004487_T12SUF_N05.11\n",
      "   Area: -113.220¬∞, 36.036¬∞ to -112.014¬∞, 37.042¬∞\n",
      "\n",
      "Metadata extraction complete!\n"
     ]
    }
   ],
   "source": [
    "# Extract metadata from all XML files and organize by location\n",
    "print(\"Extracting metadata from XML files...\")\n",
    "all_metadata = extractor.extract_all_metadata(verbose=True)\n",
    "\n",
    "# Group metadata by location\n",
    "locations = {}\n",
    "for metadata in all_metadata:\n",
    "    location = metadata['location']\n",
    "    if location not in locations:\n",
    "        locations[location] = []\n",
    "    locations[location].append(metadata)\n",
    "\n",
    "print(f\"\\nFound {len(locations)} unique locations:\")\n",
    "for location, metadata_list in locations.items():\n",
    "    pre_count = sum(1 for m in metadata_list if m['time_period'] == 'pre')\n",
    "    post_count = sum(1 for m in metadata_list if m['time_period'] == 'post')\n",
    "    print(f\"   {location}: {pre_count} pre-fire, {post_count} post-fire\")\n",
    "\n",
    "# Show sample metadata\n",
    "if all_metadata:\n",
    "    sample = all_metadata[0]\n",
    "    print(f\"\\nSample metadata:\")\n",
    "    print(f\"   Location: {sample['location']}\")\n",
    "    print(f\"   Time: {sample['sensing_time']}\")\n",
    "    print(f\"   Tile: {sample['tile_id']}\")\n",
    "    if 'bbox_wgs84' in sample:\n",
    "        bbox = sample['bbox_wgs84']\n",
    "        print(f\"   Area: {bbox[0]:.3f}¬∞, {bbox[1]:.3f}¬∞ to {bbox[2]:.3f}¬∞, {bbox[3]:.3f}¬∞\")\n",
    "\n",
    "print(f\"\\nMetadata extraction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a82b27c",
   "metadata": {},
   "source": [
    "## API Integration Example\n",
    "\n",
    "Creating Sentinel Hub API requests from extracted metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sentinel Hub API requests from metadata\n",
    "\n",
    "def create_sentinel_request_from_metadata(metadata_dict, evalscript_type='rgb', days_buffer=15):\n",
    "    \"\"\"\n",
    "    Create a Sentinel Hub request using extracted metadata\n",
    "    \n",
    "    Args:\n",
    "        metadata_dict: Dictionary with extracted metadata\n",
    "        evalscript_type: Type of data to extract ('rgb', 'ndvi', 'all_bands')\n",
    "        days_buffer: Days before/after sensing time to search\n",
    "    \n",
    "    Returns:\n",
    "        SentinelHubRequest object ready for execution\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate required fields\n",
    "    required_fields = ['sensing_time', 'bbox_wgs84']\n",
    "    missing_fields = [field for field in required_fields if field not in metadata_dict]\n",
    "    if missing_fields:\n",
    "        raise ValueError(f\"Missing required fields: {missing_fields}\")\n",
    "    \n",
    "    # Create bounding box\n",
    "    bbox_coords = metadata_dict['bbox_wgs84']\n",
    "    bbox = BBox(bbox=bbox_coords, crs=CRS.WGS84)\n",
    "    \n",
    "    # Parse sensing time and create time interval\n",
    "    sensing_time = dt.datetime.fromisoformat(metadata_dict['sensing_time'].replace('Z', '+00:00'))\n",
    "    start_date = (sensing_time - dt.timedelta(days=days_buffer)).strftime('%Y-%m-%d')\n",
    "    end_date = (sensing_time + dt.timedelta(days=days_buffer)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Choose evalscript based on type\n",
    "    evalscripts = {\n",
    "        'rgb': '''\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B02\", \"B03\", \"B04\"],\n",
    "                output: { bands: 3 }\n",
    "            };\n",
    "        }\n",
    "        function evaluatePixel(sample) {\n",
    "            return [2.5 * sample.B04, 2.5 * sample.B03, 2.5 * sample.B02];\n",
    "        }\n",
    "        ''',\n",
    "        'ndvi': '''\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B04\", \"B08\"],\n",
    "                output: { bands: 1, sampleType: \"FLOAT32\" }\n",
    "            };\n",
    "        }\n",
    "        function evaluatePixel(sample) {\n",
    "            let ndvi = (sample.B08 - sample.B04) / (sample.B08 + sample.B04);\n",
    "            return [ndvi];\n",
    "        }\n",
    "        ''',\n",
    "        'all_bands': '''\n",
    "        //VERSION=3\n",
    "        function setup() {\n",
    "            return {\n",
    "                input: [\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B11\", \"B12\"],\n",
    "                output: { bands: 12, sampleType: \"UINT16\" }\n",
    "            };\n",
    "        }\n",
    "        function evaluatePixel(sample) {\n",
    "            return [sample.B01, sample.B02, sample.B03, sample.B04, \n",
    "                   sample.B05, sample.B06, sample.B07, sample.B08,\n",
    "                   sample.B8A, sample.B09, sample.B11, sample.B12];\n",
    "        }\n",
    "        '''\n",
    "    }\n",
    "    \n",
    "    # evalscript = evalscripts.get(evalscript_type, evalscripts['rgb'])\n",
    "\n",
    "    data_collection = DataCollection.SENTINEL2_L1C\n",
    "\n",
    "    evalscript = generate_evalscript(\n",
    "        data_collection=data_collection,\n",
    "        meta_bands=[\"dataMask\"],\n",
    "        merged_bands_output=\"bands\",\n",
    "        prioritize_dn=False,\n",
    "    )\n",
    "    \n",
    "    # Create the request\n",
    "    request = SentinelHubRequest(\n",
    "        evalscript=evalscript,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=data_collection,\n",
    "                time_interval=(start_date, end_date)\n",
    "            )\n",
    "        ],\n",
    "        responses=[\n",
    "            SentinelHubRequest.output_response('default', MimeType.TIFF),\n",
    "            SentinelHubRequest.output_response('dataMask', MimeType.TIFF),\n",
    "        ],\n",
    "        bbox=bbox,\n",
    "        resolution=(10,10),  # 10m resolution\n",
    "        config=config,\n",
    "    )\n",
    "    \n",
    "    return request\n",
    "\n",
    "# Demonstrate API usage with available locations\n",
    "print(\"üöÄ Demonstrating Sentinel Hub API integration...\")\n",
    "\n",
    "if CLIENT_ID and CLIENT_SECRET and locations:\n",
    "    # Find a location with both pre and post data\n",
    "    complete_locations = []\n",
    "    for location, metadata_list in locations.items():\n",
    "        pre_data = [m for m in metadata_list if m['time_period'] == 'pre' and 'bbox_wgs84' in m]\n",
    "        post_data = [m for m in metadata_list if m['time_period'] == 'post' and 'bbox_wgs84' in m]\n",
    "        \n",
    "        if pre_data and post_data:\n",
    "            complete_locations.append((location, pre_data[0], post_data[0]))\n",
    "    \n",
    "    if complete_locations:\n",
    "        location, pre_metadata, post_metadata = complete_locations[0]\n",
    "        \n",
    "        print(f\"üìç Creating API requests for {location}:\")\n",
    "        print(f\"   Pre-fire:  {pre_metadata['sensing_time']}\")\n",
    "        print(f\"   Post-fire: {post_metadata['sensing_time']}\")\n",
    "        \n",
    "        try:\n",
    "            # Create requests for RGB data\n",
    "            pre_rgb_request = create_sentinel_request_from_metadata(pre_metadata, 'rgb')\n",
    "            post_rgb_request = create_sentinel_request_from_metadata(post_metadata, 'rgb')\n",
    "            \n",
    "            print(f\"‚úÖ API requests created successfully!\")\n",
    "            print(f\"   Ready to execute: pre_rgb_data = pre_rgb_request.get_data()\")\n",
    "            print(f\"   Ready to execute: post_rgb_data = post_rgb_request.get_data()\")\n",
    "            \n",
    "            # Store for potential use\n",
    "            globals()['pre_rgb_request'] = pre_rgb_request\n",
    "            globals()['post_rgb_request'] = post_rgb_request\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error creating requests: {e}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No locations with complete pre/post fire data found\")\n",
    "        \n",
    "elif not (CLIENT_ID and CLIENT_SECRET):\n",
    "    print(\"‚ö†Ô∏è  Sentinel Hub credentials not configured\")\n",
    "    print(\"   Set CLIENT_ID and CLIENT_SECRET in .env file to test API functionality\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No metadata extracted yet - run the previous cell first\")\n",
    "\n",
    "print(f\"\\nüéØ API integration ready for fire analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113a820",
   "metadata": {},
   "source": [
    "# 3. Summary and Next Steps\n",
    "\n",
    "Final summary of the pipeline status and next steps for fire analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPLETE FIRE PREDICTION DATA EXTRACTION WORKFLOW ===\n",
      "Step 1: Extract metadata from all XML files...\n",
      "Scanning for XML files in: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "Found 24 metadata XML files\n",
      "\n",
      "Processing: usa_post_metadata.xml\n",
      "Successfully parsed: usa_post_metadata.xml\n",
      "  Tile ID: S2C_OPER_MSI_L1C_TL_2CPS_20250715T214706_A004487_T12SUF_N05.11\n",
      "  Sensing Time: 2025-07-15T18:24:31.742376Z\n",
      "  Coordinate System: EPSG:32612\n",
      "  Upper Left: (300000.0, 4100040.0)\n",
      "  Bounding box calculated: (-113.21991719169252, 36.036167697666194, -112.01430253846226, 37.04224724177572)\n",
      "\n",
      "Processing: chile_post_metadata.xml\n",
      "Successfully parsed: chile_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240212T175807_A045138_T19HBD_N05.10\n",
      "  Sensing Time: 2024-02-12T14:52:04.975566Z\n",
      "  Coordinate System: EPSG:32719\n",
      "  Upper Left: (199980.0, 6400000.0)\n",
      "  Bounding box calculated: (-72.22879766580088, -33.48569245991556, -71.0252199246242, -32.521046863655314)\n",
      "\n",
      "Processing: sardinia_pre_metadata.xml\n",
      "Successfully parsed: sardinia_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_S2RP_20230122T151607_A031765_T32TMK_N05.00\n",
      "  Sensing Time: 2021-07-22T10:19:51.275747Z\n",
      "  Coordinate System: EPSG:32632\n",
      "  Upper Left: (399960.0, 4500000.0)\n",
      "  Bounding box calculated: (7.833868304450326, 39.65575257223608, 9.115443067619285, 40.65079881091998)\n",
      "\n",
      "Processing: chile_pre_metadata.xml\n",
      "Successfully parsed: chile_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240202T180247_A044995_T19HBD_N05.10\n",
      "  Sensing Time: 2024-02-02T14:52:03.526052Z\n",
      "  Coordinate System: EPSG:32719\n",
      "  Upper Left: (199980.0, 6400000.0)\n",
      "  Bounding box calculated: (-72.22879766580088, -33.48569245991556, -71.0252199246242, -32.521046863655314)\n",
      "\n",
      "Processing: greece2_post_metadata.xml\n",
      "Successfully parsed: greece2_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240817T111601_A047809_T34SGH_N05.11\n",
      "  Sensing Time: 2024-08-17T09:19:51.773335Z\n",
      "  Coordinate System: EPSG:32634\n",
      "  Upper Left: (699960.0, 4300020.0)\n",
      "  Bounding box calculated: (23.272364192591976, 37.83751218527424, 24.566452796700293, 38.79452723963919)\n",
      "\n",
      "Processing: spain_pre_metadata.xml\n",
      "Successfully parsed: spain_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_ATOS_20220708T150142_A036785_T29TNG_N04.00\n",
      "  Sensing Time: 2022-07-08T11:29:58.841728Z\n",
      "  Coordinate System: EPSG:32629\n",
      "  Upper Left: (499980.0, 4700040.0)\n",
      "  Bounding box calculated: (-9.000239494303116, 41.46375188670813, -7.665108433123162, 42.44491772387505)\n",
      "\n",
      "Processing: usa2_pre_metadata.xml\n",
      "Successfully parsed: usa2_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240905T000132_A048072_T11SMT_N05.11\n",
      "  Sensing Time: 2024-09-04T18:44:59.569405Z\n",
      "  Coordinate System: EPSG:32611\n",
      "  Upper Left: (399960.0, 3800040.0)\n",
      "  Bounding box calculated: (-118.07511005827462, 33.34670729904409, -116.89388597356351, 34.341617478566754)\n",
      "\n",
      "Processing: usa_pre_metadata.xml\n",
      "Successfully parsed: usa_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20250707T232040_A052448_T12SUF_N05.11\n",
      "  Sensing Time: 2025-07-07T18:24:27.038008Z\n",
      "  Coordinate System: EPSG:32612\n",
      "  Upper Left: (300000.0, 4100040.0)\n",
      "  Bounding box calculated: (-113.21991719169252, 36.036167697666194, -112.01430253846226, 37.04224724177572)\n",
      "\n",
      "Processing: turkey_post_metadata.xml\n",
      "Successfully parsed: turkey_post_metadata.xml\n",
      "  Tile ID: S2B_OPER_MSI_L1C_TL_S2RP_20230220T235744_A022970_T36SUF_N05.00\n",
      "  Sensing Time: 2021-07-30T08:50:09.324843Z\n",
      "  Coordinate System: EPSG:32636\n",
      "  Upper Left: (300000.0, 4100040.0)\n",
      "  Bounding box calculated: (30.780082808307498, 36.036167697666194, 31.985697461537743, 37.04224724177572)\n",
      "\n",
      "Processing: france_pre_metadata.xml\n",
      "Successfully parsed: france_pre_metadata.xml\n",
      "  Tile ID: S2B_OPER_MSI_L1C_TL_2BPS_20250625T141455_A043363_T31TDH_N05.11\n",
      "  Sensing Time: 2025-06-25T10:49:14.190287Z\n",
      "  Coordinate System: EPSG:32631\n",
      "  Upper Left: (399960.0, 4800000.0)\n",
      "  Bounding box calculated: (1.7852272569138194, 42.35763630810527, 3.120433646052889, 43.35279198476007)\n",
      "\n",
      "Processing: spain2_post_metadata.xml\n",
      "Successfully parsed: spain2_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20250702T131253_A052372_T31TCG_N05.11\n",
      "  Sensing Time: 2025-07-02T10:49:48.044625Z\n",
      "  Coordinate System: EPSG:32631\n",
      "  Upper Left: (300000.0, 4700040.0)\n",
      "  Bounding box calculated: (0.6060608364496378, 41.438836285058215, 1.9031483158175435, 42.447443029513174)\n",
      "\n",
      "Processing: turkey_pre_metadata.xml\n",
      "Successfully parsed: turkey_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_S2RP_20230219T191418_A031807_T36SUF_N05.00\n",
      "  Sensing Time: 2021-07-25T08:50:11.013478Z\n",
      "  Coordinate System: EPSG:32636\n",
      "  Upper Left: (300000.0, 4100040.0)\n",
      "  Bounding box calculated: (30.780082808307498, 36.036167697666194, 31.985697461537743, 37.04224724177572)\n",
      "\n",
      "Processing: sardinia_post_metadata.xml\n",
      "Successfully parsed: sardinia_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_S2RP_20230219T192327_A031808_T32TMK_N05.00\n",
      "  Sensing Time: 2021-07-25T10:29:47.384038Z\n",
      "  Coordinate System: EPSG:32632\n",
      "  Upper Left: (399960.0, 4500000.0)\n",
      "  Bounding box calculated: (7.833868304450326, 39.65575257223608, 9.115443067619285, 40.65079881091998)\n",
      "\n",
      "Processing: spain2_pre_metadata.xml\n",
      "Successfully parsed: spain2_pre_metadata.xml\n",
      "  Tile ID: S2C_OPER_MSI_L1C_TL_2CPS_20250630T141911_A004268_T31TCG_N05.11\n",
      "  Sensing Time: 2025-06-30T10:49:52.035525Z\n",
      "  Coordinate System: EPSG:32631\n",
      "  Upper Left: (300000.0, 4700040.0)\n",
      "  Bounding box calculated: (0.6060608364496378, 41.438836285058215, 1.9031483158175435, 42.447443029513174)\n",
      "\n",
      "Processing: spain3_post_metadata.xml\n",
      "Successfully parsed: spain3_post_metadata.xml\n",
      "  Tile ID: S2C_OPER_MSI_L1C_TL_2CPS_20250713T142909_A004454_T31TBF_N05.11\n",
      "  Sensing Time: 2025-07-13T11:00:09.050353Z\n",
      "  Coordinate System: EPSG:32631\n",
      "  Upper Left: (199980.0, 4600020.0)\n",
      "  Bounding box calculated: (-0.5408226025291708, 40.508462825406745, 0.7199481155047885, 41.52923550026897)\n",
      "\n",
      "Processing: greece_pre_metadata.xml\n",
      "Successfully parsed: greece_pre_metadata.xml\n",
      "  Tile ID: S2B_OPER_MSI_L1C_TL_2BPS_20230818T112138_A033681_T35TMF_N05.09\n",
      "  Sensing Time: 2023-08-18T09:19:04.267105Z\n",
      "  Coordinate System: EPSG:32635\n",
      "  Upper Left: (399960.0, 4600020.0)\n",
      "  Bounding box calculated: (25.818379707805168, 40.55670691139613, 27.117031634388372, 41.55178511644018)\n",
      "\n",
      "Processing: greece_post_metadata.xml\n",
      "Successfully parsed: greece_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20230823T111812_A042661_T35TMF_N05.09\n",
      "  Sensing Time: 2023-08-23T09:19:06.049071Z\n",
      "  Coordinate System: EPSG:32635\n",
      "  Upper Left: (399960.0, 4600020.0)\n",
      "  Bounding box calculated: (25.818379707805168, 40.55670691139613, 27.117031634388372, 41.55178511644018)\n",
      "\n",
      "Processing: usa2_post_metadata.xml\n",
      "Successfully parsed: usa2_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240914T231711_A048215_T11SMT_N05.11\n",
      "  Sensing Time: 2024-09-14T18:44:58.319061Z\n",
      "  Coordinate System: EPSG:32611\n",
      "  Upper Left: (399960.0, 3800040.0)\n",
      "  Bounding box calculated: (-118.07511005827462, 33.34670729904409, -116.89388597356351, 34.341617478566754)\n",
      "\n",
      "Processing: spain3_pre_metadata.xml\n",
      "Successfully parsed: spain3_pre_metadata.xml\n",
      "  Tile ID: S2B_OPER_MSI_L1C_TL_2BPS_20250708T124443_A043549_T30TYL_N05.11\n",
      "  Sensing Time: 2025-07-08T10:59:49.535969Z\n",
      "  Coordinate System: EPSG:32630\n",
      "  Upper Left: (699960.0, 4600020.0)\n",
      "  Bounding box calculated: (-0.638890957908561, 40.538617501482825, 0.7105746486791842, 41.49194363351178)\n",
      "\n",
      "Processing: france_post_metadata.xml\n",
      "Successfully parsed: france_post_metadata.xml\n",
      "  Tile ID: S2C_OPER_MSI_L1C_TL_2CPS_20250630T141911_A004268_T31TDH_N05.11\n",
      "  Sensing Time: 2025-06-30T10:49:33.941032Z\n",
      "  Coordinate System: EPSG:32631\n",
      "  Upper Left: (399960.0, 4800000.0)\n",
      "  Bounding box calculated: (1.7852272569138194, 42.35763630810527, 3.120433646052889, 43.35279198476007)\n",
      "\n",
      "Processing: paraguay_post_metadata.xml\n",
      "Successfully parsed: paraguay_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20250112T171132_A049928_T21JVM_N05.11\n",
      "  Sensing Time: 2025-01-12T13:59:42.994936Z\n",
      "  Coordinate System: EPSG:32721\n",
      "  Upper Left: (399960.0, 7200040.0)\n",
      "  Bounding box calculated: (-58.002187619581974, -26.30419536907358, -56.90303029074938, -25.316160250619664)\n",
      "\n",
      "Processing: spain_post_metadata.xml\n",
      "Successfully parsed: spain_post_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_ATOS_20220721T151226_A036971_T29TNG_N04.00\n",
      "  Sensing Time: 2022-07-21T11:39:53.089634Z\n",
      "  Coordinate System: EPSG:32629\n",
      "  Upper Left: (499980.0, 4700040.0)\n",
      "  Bounding box calculated: (-9.000239494303116, 41.46375188670813, -7.665108433123162, 42.44491772387505)\n",
      "\n",
      "Processing: paraguay_pre_metadata.xml\n",
      "Successfully parsed: paraguay_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20241223T171152_A049642_T21JVM_N05.11\n",
      "  Sensing Time: 2024-12-23T13:59:46.348465Z\n",
      "  Coordinate System: EPSG:32721\n",
      "  Upper Left: (399960.0, 7200040.0)\n",
      "  Bounding box calculated: (-58.002187619581974, -26.30419536907358, -56.90303029074938, -25.316160250619664)\n",
      "\n",
      "Processing: greece2_pre_metadata.xml\n",
      "Successfully parsed: greece2_pre_metadata.xml\n",
      "  Tile ID: S2A_OPER_MSI_L1C_TL_2APS_20240807T125320_A047666_T34SGH_N05.11\n",
      "  Sensing Time: 2024-08-07T09:19:52.589291Z\n",
      "  Coordinate System: EPSG:32634\n",
      "  Upper Left: (699960.0, 4300020.0)\n",
      "  Bounding box calculated: (23.272364192591976, 37.83751218527424, 24.566452796700293, 38.79452723963919)\n",
      "\n",
      "Successfully extracted metadata from 24 files\n",
      "Step 2: Found 12 locations with metadata\n",
      "‚úÖ usa: Complete pre/post fire data\n",
      "‚úÖ chile: Complete pre/post fire data\n",
      "‚úÖ sardinia: Complete pre/post fire data\n",
      "‚úÖ greece2: Complete pre/post fire data\n",
      "‚úÖ spain: Complete pre/post fire data\n",
      "‚úÖ usa2: Complete pre/post fire data\n",
      "‚úÖ turkey: Complete pre/post fire data\n",
      "‚úÖ france: Complete pre/post fire data\n",
      "‚úÖ spain2: Complete pre/post fire data\n",
      "‚úÖ spain3: Complete pre/post fire data\n",
      "‚úÖ greece: Complete pre/post fire data\n",
      "‚úÖ paraguay: Complete pre/post fire data\n",
      "\n",
      "Step 3: 12 locations ready for fire analysis:\n",
      "\n",
      "üìç USA:\n",
      "   Pre-fire:  2025-07-07T18:24:27.038008Z\n",
      "   Post-fire: 2025-07-15T18:24:31.742376Z\n",
      "   Area: -113.220¬∞, 36.036¬∞ to -112.014¬∞, 37.042¬∞\n",
      "\n",
      "üìç CHILE:\n",
      "   Pre-fire:  2024-02-02T14:52:03.526052Z\n",
      "   Post-fire: 2024-02-12T14:52:04.975566Z\n",
      "   Area: -72.229¬∞, -33.486¬∞ to -71.025¬∞, -32.521¬∞\n",
      "\n",
      "üìç SARDINIA:\n",
      "   Pre-fire:  2021-07-22T10:19:51.275747Z\n",
      "   Post-fire: 2021-07-25T10:29:47.384038Z\n",
      "   Area: 7.834¬∞, 39.656¬∞ to 9.115¬∞, 40.651¬∞\n",
      "\n",
      "üìç GREECE2:\n",
      "   Pre-fire:  2024-08-07T09:19:52.589291Z\n",
      "   Post-fire: 2024-08-17T09:19:51.773335Z\n",
      "   Area: 23.272¬∞, 37.838¬∞ to 24.566¬∞, 38.795¬∞\n",
      "\n",
      "üìç SPAIN:\n",
      "   Pre-fire:  2022-07-08T11:29:58.841728Z\n",
      "   Post-fire: 2022-07-21T11:39:53.089634Z\n",
      "   Area: -9.000¬∞, 41.464¬∞ to -7.665¬∞, 42.445¬∞\n",
      "\n",
      "üìç USA2:\n",
      "   Pre-fire:  2024-09-04T18:44:59.569405Z\n",
      "   Post-fire: 2024-09-14T18:44:58.319061Z\n",
      "   Area: -118.075¬∞, 33.347¬∞ to -116.894¬∞, 34.342¬∞\n",
      "\n",
      "üìç TURKEY:\n",
      "   Pre-fire:  2021-07-25T08:50:11.013478Z\n",
      "   Post-fire: 2021-07-30T08:50:09.324843Z\n",
      "   Area: 30.780¬∞, 36.036¬∞ to 31.986¬∞, 37.042¬∞\n",
      "\n",
      "üìç FRANCE:\n",
      "   Pre-fire:  2025-06-25T10:49:14.190287Z\n",
      "   Post-fire: 2025-06-30T10:49:33.941032Z\n",
      "   Area: 1.785¬∞, 42.358¬∞ to 3.120¬∞, 43.353¬∞\n",
      "\n",
      "üìç SPAIN2:\n",
      "   Pre-fire:  2025-06-30T10:49:52.035525Z\n",
      "   Post-fire: 2025-07-02T10:49:48.044625Z\n",
      "   Area: 0.606¬∞, 41.439¬∞ to 1.903¬∞, 42.447¬∞\n",
      "\n",
      "üìç SPAIN3:\n",
      "   Pre-fire:  2025-07-08T10:59:49.535969Z\n",
      "   Post-fire: 2025-07-13T11:00:09.050353Z\n",
      "   Area: -0.639¬∞, 40.539¬∞ to 0.711¬∞, 41.492¬∞\n",
      "\n",
      "üìç GREECE:\n",
      "   Pre-fire:  2023-08-18T09:19:04.267105Z\n",
      "   Post-fire: 2023-08-23T09:19:06.049071Z\n",
      "   Area: 25.818¬∞, 40.557¬∞ to 27.117¬∞, 41.552¬∞\n",
      "\n",
      "üìç PARAGUAY:\n",
      "   Pre-fire:  2024-12-23T13:59:46.348465Z\n",
      "   Post-fire: 2025-01-12T13:59:42.994936Z\n",
      "   Area: -58.002¬∞, -26.304¬∞ to -56.903¬∞, -25.316¬∞\n",
      "\n",
      "=== READY FOR SENTINEL HUB API ===\n",
      "üéØ 12 locations ready for analysis\n",
      "üìä Data types available: RGB, NDVI, All Bands\n",
      "üîß API functions: create_sentinel_request_from_metadata()\n",
      "\n",
      "üìù Example API calls for usa:\n",
      "   pre_rgb_data = rgb_request.get_data()  # Pre-fire RGB\n",
      "   post_rgb_data = rgb_request.get_data() # Post-fire RGB\n",
      "   # Compare pre_rgb_data vs post_rgb_data for fire analysis\n",
      "\n",
      "============================================================\n",
      "üî• FIRE PREDICTION DATA PIPELINE READY!\n",
      "   ‚úÖ XML metadata extraction: Working\n",
      "   ‚úÖ Coordinate transformation: Working\n",
      "   ‚úÖ Sentinel Hub API integration: Ready\n",
      "   ‚úÖ Multi-location support: 12 locations\n",
      "   üöÄ Ready for fire damage analysis!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:77: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  ulx_elem = geoposition_10m.find('.//ULX') or geoposition_10m.find('ULX')\n",
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:78: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  uly_elem = geoposition_10m.find('.//ULY') or geoposition_10m.find('ULY')\n",
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:79: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  xdim_elem = geoposition_10m.find('.//XDIM') or geoposition_10m.find('XDIM')\n",
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:80: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  ydim_elem = geoposition_10m.find('.//YDIM') or geoposition_10m.find('YDIM')\n",
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:94: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  nrows_elem = size_10m.find('.//NROWS') or size_10m.find('NROWS')\n",
      "/var/folders/mr/n19psg616pb4dyc16wbyn8yc0000gn/T/ipykernel_42847/1187624985.py:95: DeprecationWarning: Testing an element's truth value will always return True in future versions.  Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  ncols_elem = size_10m.find('.//NCOLS') or size_10m.find('NCOLS')\n"
     ]
    }
   ],
   "source": [
    "# Summary and Next Steps for Fire Analysis\n",
    "\n",
    "print(\"üî• FIRE PREDICTION DATA PIPELINE - SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show what we have accomplished\n",
    "if 'all_metadata' in globals() and all_metadata:\n",
    "    print(f\"‚úÖ XML metadata extraction: {len(all_metadata)} files processed\")\n",
    "    \n",
    "    if 'locations' in globals():\n",
    "        complete_pairs = []\n",
    "        for location, metadata_list in locations.items():\n",
    "            pre_data = [m for m in metadata_list if m['time_period'] == 'pre' and 'bbox_wgs84' in m]\n",
    "            post_data = [m for m in metadata_list if m['time_period'] == 'post' and 'bbox_wgs84' in m]\n",
    "            if pre_data and post_data:\n",
    "                complete_pairs.append(location)\n",
    "        \n",
    "        print(f\"‚úÖ Location analysis: {len(locations)} locations found\")\n",
    "        print(f\"‚úÖ Complete fire pairs: {len(complete_pairs)} locations ready\")\n",
    "        print(f\"   Locations with pre/post data: {', '.join(complete_pairs)}\")\n",
    "    \n",
    "    if CLIENT_ID and CLIENT_SECRET:\n",
    "        print(f\"‚úÖ Sentinel Hub API: Configured and ready\")\n",
    "        if 'pre_rgb_request' in globals():\n",
    "            print(f\"‚úÖ API requests: Created and ready to execute\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  API requests: Not yet created\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Sentinel Hub API: Credentials not configured\")\n",
    "    \n",
    "    print(f\"\\nüìä NEXT STEPS FOR FIRE ANALYSIS:\")\n",
    "    print(f\"   1. Execute API requests to download satellite data\")\n",
    "    print(f\"   2. Compare pre/post fire imagery\")\n",
    "    print(f\"   3. Calculate burn severity using NDVI\")\n",
    "    print(f\"   4. Train fire prediction models\")\n",
    "    \n",
    "    print(f\"\\nüìù EXAMPLE USAGE:\")\n",
    "    if 'pre_rgb_request' in globals():\n",
    "        print(f\"   # Download pre-fire RGB data\")\n",
    "        print(f\"   pre_rgb_data = pre_rgb_request.get_data()\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Download post-fire RGB data\")\n",
    "        print(f\"   post_rgb_data = post_rgb_request.get_data()\")\n",
    "        print(f\"   \")\n",
    "        print(f\"   # Analyze differences\")\n",
    "        print(f\"   difference = post_rgb_data - pre_rgb_data\")\n",
    "    else:\n",
    "        print(f\"   # First run the previous cells to create API requests\")\n",
    "        print(f\"   # Then execute the requests to download data\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Run the previous cells to extract metadata first\")\n",
    "\n",
    "print(f\"\\nüéØ PIPELINE STATUS: Ready for fire damage analysis!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpaceChallenges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

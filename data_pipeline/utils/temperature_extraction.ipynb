{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a003aa",
   "metadata": {},
   "source": [
    "# Temperature Data Extraction for Fire Prediction\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extracts comprehensive temperature data from multiple satellite thermal datasets using Google Earth Engine API for fire prediction analysis. It processes XML metadata files to extract spatial and temporal information, then retrieves Land Surface Temperature (LST) data from various satellite sources.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Multi-satellite support**: MODIS Terra/Aqua and Landsat 8/9 thermal bands\n",
    "- **Automated processing**: Batch processing of all available XML metadata files\n",
    "- **Quality control**: Advanced cloud masking and data validation\n",
    "- **Comprehensive outputs**: JSON, Excel, and Python pickle formats\n",
    "- **Analysis and visualization**: Statistical analysis and plotting capabilities\n",
    "- **Error handling**: Robust error detection and logging\n",
    "\n",
    "## Datasets Used\n",
    "\n",
    "1. **MODIS Terra (MOD11A1)**: 1km resolution, daily Land Surface Temperature\n",
    "2. **MODIS Aqua (MYD11A1)**: 1km resolution, daily Land Surface Temperature  \n",
    "3. **Landsat 8**: 100m resolution, thermal infrared surface temperature\n",
    "4. **Landsat 9**: 100m resolution, thermal infrared surface temperature\n",
    "\n",
    "## Output\n",
    "\n",
    "- **Excel file**: Structured temperature data with summary and detailed sheets\n",
    "- **JSON file**: Complete extraction results with metadata for further processing\n",
    "- **Pickle file**: Python objects for direct loading into other scripts\n",
    "- **Visualization plots**: Temperature analysis charts and graphs\n",
    "\n",
    "## Usage\n",
    "\n",
    "Run all cells in sequence to:\n",
    "1. Initialize Google Earth Engine\n",
    "2. Configure datasets and file paths\n",
    "3. Extract metadata from XML files\n",
    "4. Process temperature data for all countries and periods\n",
    "5. Generate comprehensive outputs and visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "017cbdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üå°Ô∏è Temperature Data Extraction System - Ready for Fire Prediction Analysis\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Temperature Data Extraction System for Fire Prediction\n",
    "# =======================================================\n",
    "# This notebook extracts temperature data from multiple satellite datasets using Google Earth Engine\n",
    "# for fire prediction analysis. It processes XML metadata files and extracts comprehensive\n",
    "# temperature statistics from MODIS and Landsat thermal bands.\n",
    "\n",
    "import ee\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üå°Ô∏è Temperature Data Extraction System - Ready for Fire Prediction Analysis\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce6f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Configuration completed:\n",
      "  XML metadata folder: /Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files\n",
      "  Output folder: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output\n",
      "  Found 24 XML metadata files to process\n",
      "  Available files:\n",
      "    1. sardinia_pre_inspire.xml\n",
      "    2. spain2_pre_inspire.xml\n",
      "    3. paraguay_pre_inspire.xml\n",
      "    4. usa2_pre_inspire.xml\n",
      "    5. greece_pre_inspire.xml\n",
      "    ... and 19 more files\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Setup\n",
    "# ========================\n",
    "\n",
    "# File paths configuration\n",
    "XML_FOLDER_PATH = os.path.join('/Users/diego/Documents/FirePrediction/data_pipeline/utils/data_api/testing/copied_xml_files')\n",
    "OUTPUT_FOLDER = os.path.join(os.getcwd(), 'temperature_extraction_output')\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Configuration completed:\")\n",
    "print(f\"  XML metadata folder: {XML_FOLDER_PATH}\")\n",
    "print(f\"  Output folder: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# Scan for available XML files\n",
    "xml_files = [f for f in os.listdir(XML_FOLDER_PATH) if f.endswith('_inspire.xml')]\n",
    "print(f\"  Found {len(xml_files)} XML metadata files to process\")\n",
    "\n",
    "if xml_files:\n",
    "    print(\"  Available files:\")\n",
    "    for i, file in enumerate(xml_files[:5], 1):\n",
    "        print(f\"    {i}. {file}\")\n",
    "    if len(xml_files) > 5:\n",
    "        print(f\"    ... and {len(xml_files) - 5} more files\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è No XML files found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d051f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç Initializing Google Earth Engine...\n",
      "‚úÖ Google Earth Engine initialized successfully!\n",
      "üöÄ Google Earth Engine is ready for temperature data extraction!\n",
      "‚úÖ Google Earth Engine initialized successfully!\n",
      "üöÄ Google Earth Engine is ready for temperature data extraction!\n"
     ]
    }
   ],
   "source": [
    "# Google Earth Engine Initialization\n",
    "# ===================================\n",
    "\n",
    "print(\"üåç Initializing Google Earth Engine...\")\n",
    "\n",
    "try:\n",
    "    # Try to initialize first (if already authenticated)\n",
    "    ee.Initialize()\n",
    "    print(\"‚úÖ Google Earth Engine initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"üîê Authentication required. Please follow the authentication process...\")\n",
    "    try:\n",
    "        # If initialization fails, authenticate first\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()\n",
    "        print(\"‚úÖ Google Earth Engine authenticated and initialized successfully!\")\n",
    "    except Exception as auth_error:\n",
    "        print(f\"‚ùå Authentication failed: {auth_error}\")\n",
    "        print(\"Please ensure you have a Google Earth Engine account and proper permissions.\")\n",
    "        raise\n",
    "\n",
    "print(\"üöÄ Google Earth Engine is ready for temperature data extraction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16a0ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå°Ô∏è Available temperature datasets:\n",
      "  üì° MODIS_TERRA: MODIS Terra Land Surface Temperature (1km, daily)\n",
      "      Resolution: 1000m\n",
      "      Collection: MODIS/061/MOD11A1\n",
      "      Band: LST_Day_1km\n",
      "  üì° MODIS_AQUA: MODIS Aqua Land Surface Temperature (1km, daily)\n",
      "      Resolution: 1000m\n",
      "      Collection: MODIS/061/MYD11A1\n",
      "      Band: LST_Day_1km\n",
      "  üì° LANDSAT8: Landsat 8 Surface Temperature (100m)\n",
      "      Resolution: 100m\n",
      "      Collection: LANDSAT/LC08/C02/T1_L2\n",
      "      Band: ST_B10\n",
      "  üì° LANDSAT9: Landsat 9 Surface Temperature (100m)\n",
      "      Resolution: 100m\n",
      "      Collection: LANDSAT/LC09/C02/T1_L2\n",
      "      Band: ST_B10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temperature Dataset Configuration\n",
    "# ==================================\n",
    "\n",
    "# Define satellite temperature datasets with their specifications\n",
    "TEMPERATURE_DATASETS = {\n",
    "    \"MODIS_TERRA\": {\n",
    "        \"collection_id\": \"MODIS/061/MOD11A1\",\n",
    "        \"temperature_band\": \"LST_Day_1km\",\n",
    "        \"cloud_mask_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"scale_factor\": 0.02,\n",
    "        \"offset\": 0,\n",
    "        \"description\": \"MODIS Terra Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"MODIS_AQUA\": {\n",
    "        \"collection_id\": \"MODIS/061/MYD11A1\",\n",
    "        \"temperature_band\": \"LST_Day_1km\", \n",
    "        \"cloud_mask_band\": \"QC_Day\",\n",
    "        \"scale\": 1000,\n",
    "        \"scale_factor\": 0.02,\n",
    "        \"offset\": 0,\n",
    "        \"description\": \"MODIS Aqua Land Surface Temperature (1km, daily)\"\n",
    "    },\n",
    "    \"LANDSAT8\": {\n",
    "        \"collection_id\": \"LANDSAT/LC08/C02/T1_L2\",\n",
    "        \"temperature_band\": \"ST_B10\",\n",
    "        \"cloud_mask_band\": \"QA_PIXEL\",\n",
    "        \"scale\": 100,\n",
    "        \"scale_factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"description\": \"Landsat 8 Surface Temperature (100m)\"\n",
    "    },\n",
    "    \"LANDSAT9\": {\n",
    "        \"collection_id\": \"LANDSAT/LC09/C02/T1_L2\",\n",
    "        \"temperature_band\": \"ST_B10\",\n",
    "        \"cloud_mask_band\": \"QA_PIXEL\", \n",
    "        \"scale\": 100,\n",
    "        \"scale_factor\": 0.00341802,\n",
    "        \"offset\": 149.0,\n",
    "        \"description\": \"Landsat 9 Surface Temperature (100m)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üå°Ô∏è Available temperature datasets:\")\n",
    "for key, dataset in TEMPERATURE_DATASETS.items():\n",
    "    print(f\"  üì° {key}: {dataset['description']}\")\n",
    "    print(f\"      Resolution: {dataset['scale']}m\")\n",
    "    print(f\"      Collection: {dataset['collection_id']}\")\n",
    "    print(f\"      Band: {dataset['temperature_band']}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3b1b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available XML files:\n",
      "  üåç sardinia: ['pre', 'post']\n",
      "  üåç spain2: ['pre', 'post']\n",
      "  üåç paraguay: ['pre', 'post']\n",
      "  üåç usa2: ['pre', 'post']\n",
      "  üåç greece: ['pre', 'post']\n",
      "  üåç chile: ['pre', 'post']\n",
      "  üåç spain: ['post', 'pre']\n",
      "  üåç france: ['pre', 'post']\n",
      "  üåç usa: ['post', 'pre']\n",
      "  üåç spain3: ['pre', 'post']\n",
      "  üåç turkey: ['post', 'pre']\n",
      "  üåç greece2: ['post', 'pre']\n",
      "\n",
      "üìä Total countries found: 12\n",
      "üåç Countries: ['sardinia', 'spain2', 'paraguay', 'usa2', 'greece', 'chile', 'spain', 'france', 'usa', 'spain3', 'turkey', 'greece2']\n",
      "‚úÖ Enhanced metadata extractor initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Metadata Extractor\n",
    "# ============================\n",
    "\n",
    "class EnhancedMetadataExtractor:\n",
    "    \"\"\"\n",
    "    Enhanced class to extract metadata from XML files for all available countries and periods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, xml_folder_path: str):\n",
    "        self.xml_folder_path = Path(xml_folder_path)\n",
    "        self.available_files = self._scan_xml_files()\n",
    "        \n",
    "    def _scan_xml_files(self):\n",
    "        \"\"\"Scan for all available XML files and organize by country and period\"\"\"\n",
    "        inspire_files = list(self.xml_folder_path.glob(\"*_inspire.xml\"))\n",
    "        metadata_files = list(self.xml_folder_path.glob(\"*_metadata.xml\"))\n",
    "        \n",
    "        available = {}\n",
    "        for file in inspire_files:\n",
    "            name_parts = file.stem.split('_')\n",
    "            if len(name_parts) >= 2:\n",
    "                country = name_parts[0]\n",
    "                period = name_parts[1]\n",
    "                if country not in available:\n",
    "                    available[country] = {}\n",
    "                available[country][period] = {\n",
    "                    'inspire_xml': file,\n",
    "                    'metadata_xml': None\n",
    "                }\n",
    "        \n",
    "        # Add metadata files\n",
    "        for file in metadata_files:\n",
    "            name_parts = file.stem.split('_')\n",
    "            if len(name_parts) >= 2:\n",
    "                country = name_parts[0]\n",
    "                period = name_parts[1]\n",
    "                if country in available and period in available[country]:\n",
    "                    available[country][period]['metadata_xml'] = file\n",
    "                    \n",
    "        return available\n",
    "    \n",
    "    def extract_comprehensive_metadata(self, country_id: str, when: str = 'pre'):\n",
    "        \"\"\"Extract comprehensive metadata from XML files\"\"\"\n",
    "        if country_id not in self.available_files:\n",
    "            raise FileNotFoundError(f\"No XML files found for country: {country_id}\")\n",
    "            \n",
    "        if when not in self.available_files[country_id]:\n",
    "            raise FileNotFoundError(f\"No {when} XML files found for country: {country_id}\")\n",
    "        \n",
    "        file_info = self.available_files[country_id][when]\n",
    "        inspire_file = file_info['inspire_xml']\n",
    "        \n",
    "        print(f\"üìç Processing {country_id}_{when}: {inspire_file.name}\")\n",
    "        \n",
    "        # Extract from inspire XML\n",
    "        inspire_data = self._extract_from_inspire(inspire_file)\n",
    "        \n",
    "        # Combine data\n",
    "        combined_metadata = {\n",
    "            'country_id': country_id,\n",
    "            'time_period': when,\n",
    "            'source_files': {\n",
    "                'inspire_xml': str(inspire_file),\n",
    "            },\n",
    "            'spatial_extent': inspire_data.get('spatial_extent', {}),\n",
    "            'temporal_extent': inspire_data.get('temporal_extent', {}),\n",
    "            'technical_specs': inspire_data.get('technical_specs', {}),\n",
    "            'product_info': inspire_data.get('product_info', {}),\n",
    "        }\n",
    "        \n",
    "        return combined_metadata\n",
    "    \n",
    "    def _extract_from_inspire(self, xml_file):\n",
    "        \"\"\"Extract metadata from inspire XML with multiple namespace handling\"\"\"\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Try multiple namespace combinations\n",
    "        namespace_combinations = [\n",
    "            {\n",
    "                'gmd': 'http://www.isotc211.org/2005/gmd',\n",
    "                'gco': 'http://www.isotc211.org/2005/gco',\n",
    "                'gml': 'http://www.opengis.net/gml'\n",
    "            },\n",
    "            {\n",
    "                'gmd': 'http://www.isotc211.org/2005/gmd',\n",
    "                'gco': 'http://www.isotc211.org/2005/gco',\n",
    "                'gml': 'http://www.opengis.net/gml/3.2'\n",
    "            },\n",
    "            {}  # No namespace\n",
    "        ]\n",
    "        \n",
    "        for ns in namespace_combinations:\n",
    "            try:\n",
    "                result = self._extract_with_namespace(root, ns)\n",
    "                if result and any(v is not None for v in [\n",
    "                    result['spatial_extent'].get('west_bound'),\n",
    "                    result['spatial_extent'].get('east_bound'),\n",
    "                    result['spatial_extent'].get('south_bound'),\n",
    "                    result['spatial_extent'].get('north_bound')\n",
    "                ]):\n",
    "                    return result\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        # Return empty structure if nothing works\n",
    "        return {\n",
    "            'spatial_extent': {'west_bound': None, 'east_bound': None, 'south_bound': None, 'north_bound': None},\n",
    "            'temporal_extent': {'start_time': None, 'end_time': None},\n",
    "            'technical_specs': {'spatial_resolution': None, 'crs_code': 'Unknown'},\n",
    "            'product_info': {'title': 'Unknown'},\n",
    "        }\n",
    "    \n",
    "    def _extract_with_namespace(self, root, ns):\n",
    "        \"\"\"Extract metadata using specific namespace\"\"\"\n",
    "        \n",
    "        # Extract geographic coordinates\n",
    "        if ns:\n",
    "            west_elem = root.find('.//gmd:westBoundLongitude/gco:Decimal', ns)\n",
    "            east_elem = root.find('.//gmd:eastBoundLongitude/gco:Decimal', ns)\n",
    "            south_elem = root.find('.//gmd:southBoundLatitude/gco:Decimal', ns)\n",
    "            north_elem = root.find('.//gmd:northBoundLatitude/gco:Decimal', ns)\n",
    "            title_elem = root.find('.//gmd:title/gco:CharacterString', ns)\n",
    "            begin_elem = root.find('.//gml:beginPosition', ns)\n",
    "            end_elem = root.find('.//gml:endPosition', ns)\n",
    "        else:\n",
    "            west_elem = root.find('.//westBoundLongitude') or root.find('.//WestBoundLongitude')\n",
    "            east_elem = root.find('.//eastBoundLongitude') or root.find('.//EastBoundLongitude')\n",
    "            south_elem = root.find('.//southBoundLatitude') or root.find('.//SouthBoundLatitude')\n",
    "            north_elem = root.find('.//northBoundLatitude') or root.find('.//NorthBoundLatitude')\n",
    "            title_elem = root.find('.//title') or root.find('.//Title')\n",
    "            begin_elem = root.find('.//beginPosition') or root.find('.//startTime')\n",
    "            end_elem = root.find('.//endPosition') or root.find('.//endTime')\n",
    "        \n",
    "        # Parse coordinates\n",
    "        west = self._safe_float(west_elem)\n",
    "        east = self._safe_float(east_elem)\n",
    "        south = self._safe_float(south_elem)\n",
    "        north = self._safe_float(north_elem)\n",
    "        \n",
    "        # Parse temporal info\n",
    "        begin_time = begin_elem.text if begin_elem is not None else None\n",
    "        end_time = end_elem.text if end_elem is not None else None\n",
    "        \n",
    "        # Parse title\n",
    "        title = title_elem.text if title_elem is not None else \"Unknown\"\n",
    "        \n",
    "        return {\n",
    "            'spatial_extent': {\n",
    "                'west_bound': west,\n",
    "                'east_bound': east,\n",
    "                'south_bound': south,\n",
    "                'north_bound': north,\n",
    "                'center_lat': (north + south) / 2 if north and south else None,\n",
    "                'center_lon': (east + west) / 2 if east and west else None\n",
    "            },\n",
    "            'temporal_extent': {\n",
    "                'start_time': begin_time,\n",
    "                'end_time': end_time\n",
    "            },\n",
    "            'technical_specs': {\n",
    "                'spatial_resolution': 10,  # Default for Sentinel-2\n",
    "                'crs_code': 'EPSG:4326'\n",
    "            },\n",
    "            'product_info': {\n",
    "                'title': title\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _safe_float(self, element):\n",
    "        \"\"\"Safely convert element text to float\"\"\"\n",
    "        if element is not None and element.text:\n",
    "            try:\n",
    "                return float(element.text.strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return None\n",
    "\n",
    "# Initialize enhanced metadata extractor\n",
    "enhanced_extractor = EnhancedMetadataExtractor(XML_FOLDER_PATH)\n",
    "\n",
    "# Show available countries and periods\n",
    "print(\"üìã Available XML files:\")\n",
    "for country, periods in enhanced_extractor.available_files.items():\n",
    "    print(f\"  üåç {country}: {list(periods.keys())}\")\n",
    "    \n",
    "print(f\"\\nüìä Total countries found: {len(enhanced_extractor.available_files)}\")\n",
    "all_countries = list(enhanced_extractor.available_files.keys())\n",
    "print(f\"üåç Countries: {all_countries}\")\n",
    "\n",
    "print(\"‚úÖ Enhanced metadata extractor initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcc7d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Comprehensive temperature extractor initialized successfully!\n",
      "üîß Features included:\n",
      "  - Multi-country processing\n",
      "  - Coordinate validation and correction\n",
      "  - Temporal extent parsing and expansion\n",
      "  - Default fallback values\n",
      "  - Enhanced error handling\n",
      "Ready to extract temperatures for all countries!\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Temperature Extractor\n",
    "# ====================================\n",
    "\n",
    "class ComprehensiveTemperatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract temperatures for all available countries with enhanced error handling and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_extractor, temperature_datasets):\n",
    "        self.metadata_extractor = metadata_extractor\n",
    "        self.temperature_datasets = temperature_datasets\n",
    "        self.results = {}\n",
    "        self.errors = {}\n",
    "    \n",
    "    def extract_temperatures_for_country(self, country_id: str, periods: List[str] = ['pre', 'post']):\n",
    "        \"\"\"Extract temperatures for a specific country and periods\"\"\"\n",
    "        \n",
    "        country_results = {}\n",
    "        country_errors = {}\n",
    "        \n",
    "        for period in periods:\n",
    "            if period not in self.metadata_extractor.available_files.get(country_id, {}):\n",
    "                print(f\"‚ö†Ô∏è Period '{period}' not available for {country_id}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                print(f\"\\nüåç Processing {country_id}_{period}...\")\n",
    "                \n",
    "                # Extract metadata\n",
    "                metadata = self.metadata_extractor.extract_comprehensive_metadata(country_id, period)\n",
    "                \n",
    "                # Validate and fix spatial extent\n",
    "                spatial_extent = metadata['spatial_extent']\n",
    "                spatial_extent = self._fix_coordinates(spatial_extent, country_id)\n",
    "                \n",
    "                # Validate temporal extent\n",
    "                temporal_extent = metadata['temporal_extent']\n",
    "                start_date, end_date = self._parse_temporal_extent(temporal_extent, period, country_id)\n",
    "                \n",
    "                print(f\"üìç Coordinates: W={spatial_extent['west_bound']:.3f}, E={spatial_extent['east_bound']:.3f}\")\n",
    "                print(f\"              S={spatial_extent['south_bound']:.3f}, N={spatial_extent['north_bound']:.3f}\")\n",
    "                print(f\"üìÖ Date range: {start_date} to {end_date}\")\n",
    "                \n",
    "                # Create bounding box\n",
    "                bbox = [\n",
    "                    spatial_extent['west_bound'],\n",
    "                    spatial_extent['south_bound'], \n",
    "                    spatial_extent['east_bound'],\n",
    "                    spatial_extent['north_bound']\n",
    "                ]\n",
    "                \n",
    "                # Validate bbox\n",
    "                if not self._validate_bbox(bbox):\n",
    "                    print(f\"‚ö†Ô∏è Invalid bbox, using default bounds for {country_id}\")\n",
    "                    default_bounds = self._get_default_bounds(country_id)\n",
    "                    bbox = [default_bounds['west_bound'], default_bounds['south_bound'], \n",
    "                           default_bounds['east_bound'], default_bounds['north_bound']]\n",
    "                \n",
    "                # Extract temperatures from multiple datasets\n",
    "                period_results = {}\n",
    "                for dataset_name, dataset_config in self.temperature_datasets.items():\n",
    "                    try:\n",
    "                        print(f\"  üå°Ô∏è Extracting from {dataset_name}...\")\n",
    "                        \n",
    "                        temp_data = self._extract_temperature_data(\n",
    "                            bbox, start_date, end_date, dataset_config, country_id, period\n",
    "                        )\n",
    "                        \n",
    "                        if temp_data:\n",
    "                            period_results[dataset_name] = temp_data\n",
    "                            print(f\"    ‚úÖ Successfully extracted {len(temp_data)} temperature records\")\n",
    "                        else:\n",
    "                            print(f\"    ‚ö†Ô∏è No data available for {dataset_name}\")\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        error_msg = f\"Error extracting {dataset_name} for {country_id}_{period}: {str(e)}\"\n",
    "                        print(f\"    ‚ùå {error_msg}\")\n",
    "                        if country_id not in country_errors:\n",
    "                            country_errors[country_id] = {}\n",
    "                        if period not in country_errors[country_id]:\n",
    "                            country_errors[country_id][period] = []\n",
    "                        country_errors[country_id][period].append(error_msg)\n",
    "                \n",
    "                # Store results\n",
    "                if period_results:\n",
    "                    if country_id not in country_results:\n",
    "                        country_results[country_id] = {}\n",
    "                    country_results[country_id][period] = {\n",
    "                        'metadata': metadata,\n",
    "                        'temperature_data': period_results,\n",
    "                        'extraction_timestamp': datetime.datetime.now().isoformat()\n",
    "                    }\n",
    "                    print(f\"‚úÖ Successfully processed {country_id}_{period}\")\n",
    "                else:\n",
    "                    print(f\"‚ùå No temperature data extracted for {country_id}_{period}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Critical error processing {country_id}_{period}: {str(e)}\"\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                if country_id not in country_errors:\n",
    "                    country_errors[country_id] = {}\n",
    "                if period not in country_errors[country_id]:\n",
    "                    country_errors[country_id][period] = []\n",
    "                country_errors[country_id][period].append(error_msg)\n",
    "        \n",
    "        return country_results, country_errors\n",
    "    \n",
    "    def _fix_coordinates(self, spatial_extent, country_id):\n",
    "        \"\"\"Fix common coordinate issues\"\"\"\n",
    "        # Fix longitude coordinates if they're > 180 (common projection issue)\n",
    "        if spatial_extent.get('west_bound') and spatial_extent['west_bound'] > 180:\n",
    "            spatial_extent['west_bound'] -= 360\n",
    "        if spatial_extent.get('east_bound') and spatial_extent['east_bound'] > 180:\n",
    "            spatial_extent['east_bound'] -= 360\n",
    "        \n",
    "        # If coordinates are invalid, use defaults\n",
    "        if not all([spatial_extent.get('west_bound'), spatial_extent.get('east_bound'),\n",
    "                   spatial_extent.get('south_bound'), spatial_extent.get('north_bound')]):\n",
    "            print(f\"‚ö†Ô∏è Invalid spatial extent for {country_id}, using default bounds\")\n",
    "            return self._get_default_bounds(country_id)\n",
    "        \n",
    "        return spatial_extent\n",
    "    \n",
    "    def _validate_bbox(self, bbox):\n",
    "        \"\"\"Validate bounding box coordinates\"\"\"\n",
    "        try:\n",
    "            west, south, east, north = bbox\n",
    "            \n",
    "            # Check longitude range\n",
    "            if west < -180 or west > 180 or east < -180 or east > 180:\n",
    "                return False\n",
    "            \n",
    "            # Check latitude range  \n",
    "            if south < -90 or south > 90 or north < -90 or north > 90:\n",
    "                return False\n",
    "            \n",
    "            # Check logical order\n",
    "            if west >= east or south >= north:\n",
    "                return False\n",
    "                \n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def _extract_temperature_data(self, bbox, start_date, end_date, dataset_config, country_id, period):\n",
    "        \"\"\"Extract temperature data for specific parameters\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Create geometry\n",
    "            geometry = ee.Geometry.Rectangle(bbox)\n",
    "            \n",
    "            # Get collection\n",
    "            collection = ee.ImageCollection(dataset_config['collection_id'])\n",
    "            \n",
    "            # Filter by date and geometry\n",
    "            filtered_collection = collection.filterDate(start_date, end_date).filterBounds(geometry)\n",
    "            \n",
    "            # Check if collection has any images\n",
    "            count = filtered_collection.size()\n",
    "            actual_count = count.getInfo()\n",
    "            \n",
    "            if actual_count == 0:\n",
    "                print(f\"    No images found in {dataset_config['collection_id']} for the specified period\")\n",
    "                return None\n",
    "            \n",
    "            print(f\"    Found {actual_count} images in collection\")\n",
    "            \n",
    "            # Get temperature data\n",
    "            temp_band = dataset_config['temperature_band']\n",
    "            scale = dataset_config['scale']\n",
    "            scale_factor = dataset_config.get('scale_factor', 1)\n",
    "            offset = dataset_config.get('offset', 0)\n",
    "            \n",
    "            # Extract temperature values\n",
    "            def extract_temp_from_image(image):\n",
    "                # Apply scale and offset, then convert to Celsius\n",
    "                temp_celsius = image.select(temp_band).multiply(scale_factor).add(offset).subtract(273.15)\n",
    "                \n",
    "                # Get image date\n",
    "                date = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd')\n",
    "                \n",
    "                # Calculate statistics\n",
    "                stats = temp_celsius.reduceRegion(\n",
    "                    reducer=ee.Reducer.mean().combine(\n",
    "                        ee.Reducer.min(), '', True\n",
    "                    ).combine(\n",
    "                        ee.Reducer.max(), '', True\n",
    "                    ).combine(\n",
    "                        ee.Reducer.stdDev(), '', True\n",
    "                    ),\n",
    "                    geometry=geometry,\n",
    "                    scale=scale,\n",
    "                    maxPixels=1e9\n",
    "                )\n",
    "                \n",
    "                return ee.Feature(None, stats.set('date', date))\n",
    "            \n",
    "            # Map over collection (limit to avoid timeout)\n",
    "            temp_features = filtered_collection.limit(50).map(extract_temp_from_image)\n",
    "            \n",
    "            # Get the results\n",
    "            temp_info = temp_features.getInfo()\n",
    "            \n",
    "            # Process results\n",
    "            temperature_records = []\n",
    "            for feature in temp_info['features']:\n",
    "                props = feature['properties']\n",
    "                temp_record = {\n",
    "                    'date': props.get('date'),\n",
    "                    'mean_temp_celsius': props.get(f'{temp_band}_mean'),\n",
    "                    'min_temp_celsius': props.get(f'{temp_band}_min'),\n",
    "                    'max_temp_celsius': props.get(f'{temp_band}_max'),\n",
    "                    'std_temp_celsius': props.get(f'{temp_band}_stdDev'),\n",
    "                    'dataset': dataset_config['collection_id'],\n",
    "                    'scale_meters': scale,\n",
    "                    'country': country_id,\n",
    "                    'period': period\n",
    "                }\n",
    "                \n",
    "                # Filter out null values\n",
    "                if temp_record['mean_temp_celsius'] is not None:\n",
    "                    temperature_records.append(temp_record)\n",
    "            \n",
    "            return temperature_records\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error in temperature extraction: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _parse_temporal_extent(self, temporal_extent, period, country_id):\n",
    "        \"\"\"Parse temporal extent and fix common issues\"\"\"\n",
    "        \n",
    "        start_time = temporal_extent.get('start_time')\n",
    "        end_time = temporal_extent.get('end_time')\n",
    "        \n",
    "        # If we have temporal info, try to use it\n",
    "        if start_time and end_time:\n",
    "            try:\n",
    "                # Parse the dates\n",
    "                start_date = start_time.split('T')[0]  # Get date part\n",
    "                end_date = end_time.split('T')[0]\n",
    "                \n",
    "                # Check if start and end are the same (single day issue)\n",
    "                if start_date == end_date:\n",
    "                    print(f\"    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\")\n",
    "                    base_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                    start_date = (base_date - datetime.timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "                    end_date = (base_date + datetime.timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "                \n",
    "                return start_date, end_date\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    ‚ö†Ô∏è Error parsing temporal extent: {e}\")\n",
    "        \n",
    "        # Use defaults\n",
    "        return self._get_default_date_range(period, country_id)\n",
    "    \n",
    "    def _get_default_date_range(self, period, country_id):\n",
    "        \"\"\"Get default date ranges for different periods and countries\"\"\"\n",
    "        \n",
    "        # Default date ranges based on typical fire seasons\n",
    "        default_dates = {\n",
    "            # Northern hemisphere fire season\n",
    "            'north': {\n",
    "                'pre': ('2023-05-01', '2023-07-31'),\n",
    "                'post': ('2023-08-01', '2023-10-31')\n",
    "            },\n",
    "            # Southern hemisphere fire season  \n",
    "            'south': {\n",
    "                'pre': ('2022-11-01', '2023-01-31'),\n",
    "                'post': ('2023-02-01', '2023-04-30')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Determine hemisphere based on country\n",
    "        southern_countries = ['chile', 'paraguay']\n",
    "        hemisphere = 'south' if any(sc in country_id.lower() for sc in southern_countries) else 'north'\n",
    "        \n",
    "        return default_dates[hemisphere][period]\n",
    "    \n",
    "    def _get_default_bounds(self, country_id):\n",
    "        \"\"\"Get default bounding boxes for countries\"\"\"\n",
    "        \n",
    "        default_bounds = {\n",
    "            'chile': {'west_bound': -75.0, 'east_bound': -66.0, 'south_bound': -56.0, 'north_bound': -17.0},\n",
    "            'france': {'west_bound': -5.0, 'east_bound': 10.0, 'south_bound': 41.0, 'north_bound': 51.0},\n",
    "            'spain': {'west_bound': -10.0, 'east_bound': 4.0, 'south_bound': 35.0, 'north_bound': 44.0},\n",
    "            'greece': {'west_bound': 19.0, 'east_bound': 30.0, 'south_bound': 34.0, 'north_bound': 42.0},\n",
    "            'turkey': {'west_bound': 25.0, 'east_bound': 45.0, 'south_bound': 35.0, 'north_bound': 43.0},\n",
    "            'sardinia': {'west_bound': 8.0, 'east_bound': 10.0, 'south_bound': 38.0, 'north_bound': 42.0},\n",
    "            'usa': {'west_bound': -125.0, 'east_bound': -66.0, 'south_bound': 20.0, 'north_bound': 50.0},\n",
    "            'paraguay': {'west_bound': -63.0, 'east_bound': -54.0, 'south_bound': -28.0, 'north_bound': -19.0},\n",
    "        }\n",
    "        \n",
    "        # Try to match country name\n",
    "        for key, bounds in default_bounds.items():\n",
    "            if key in country_id.lower():\n",
    "                return bounds\n",
    "        \n",
    "        # Default global bounds\n",
    "        return {'west_bound': -180.0, 'east_bound': 180.0, 'south_bound': -90.0, 'north_bound': 90.0}\n",
    "    \n",
    "    def extract_all_countries(self):\n",
    "        \"\"\"Extract temperatures for all available countries\"\"\"\n",
    "        \n",
    "        all_countries = list(self.metadata_extractor.available_files.keys())\n",
    "        print(f\"üöÄ Starting temperature extraction for {len(all_countries)} countries...\")\n",
    "        print(f\"Countries: {all_countries}\")\n",
    "        \n",
    "        # Process countries sequentially to avoid API rate limits\n",
    "        for country in all_countries:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Processing country: {country.upper()}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            country_results, country_errors = self.extract_temperatures_for_country(country)\n",
    "            \n",
    "            # Store results\n",
    "            if country_results:\n",
    "                self.results.update(country_results)\n",
    "            if country_errors:\n",
    "                self.errors.update(country_errors)\n",
    "            \n",
    "            # Small delay between countries\n",
    "            time.sleep(2)\n",
    "        \n",
    "        return self.results, self.errors\n",
    "\n",
    "# Initialize comprehensive temperature extractor\n",
    "temp_extractor = ComprehensiveTemperatureExtractor(enhanced_extractor, TEMPERATURE_DATASETS)\n",
    "\n",
    "print(\"‚úÖ Comprehensive temperature extractor initialized successfully!\")\n",
    "print(\"üîß Features included:\")\n",
    "print(\"  - Multi-country processing\")\n",
    "print(\"  - Coordinate validation and correction\") \n",
    "print(\"  - Temporal extent parsing and expansion\")\n",
    "print(\"  - Default fallback values\")\n",
    "print(\"  - Enhanced error handling\")\n",
    "print(\"Ready to extract temperatures for all countries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da530e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting temperature extraction for sample countries...\n",
      "Started at: 2025-08-11 14:54:36\n",
      "\n",
      "Processing: CHILE\n",
      "------------------------------\n",
      "\n",
      "üåç Processing chile_pre...\n",
      "üìç Processing chile_pre: chile_pre_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=-72.229, E=-71.025\n",
      "              S=-33.511, N=-32.497\n",
      "üìÖ Date range: 2024-01-18 to 2024-02-17\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed chile_pre\n",
      "\n",
      "üåç Processing chile_post...\n",
      "üìç Processing chile_post: chile_post_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=-72.229, E=-71.025\n",
      "              S=-33.511, N=-32.497\n",
      "üìÖ Date range: 2024-01-28 to 2024-02-27\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed chile_pre\n",
      "\n",
      "üåç Processing chile_post...\n",
      "üìç Processing chile_post: chile_post_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=-72.229, E=-71.025\n",
      "              S=-33.511, N=-32.497\n",
      "üìÖ Date range: 2024-01-28 to 2024-02-27\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed chile_post\n",
      "SUCCESS: chile\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed chile_post\n",
      "SUCCESS: chile\n",
      "\n",
      "Processing: FRANCE\n",
      "------------------------------\n",
      "\n",
      "üåç Processing france_pre...\n",
      "üìç Processing france_pre: france_pre_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=1.766, E=3.120\n",
      "              S=42.358, N=43.353\n",
      "üìÖ Date range: 2025-06-10 to 2025-07-10\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "\n",
      "Processing: FRANCE\n",
      "------------------------------\n",
      "\n",
      "üåç Processing france_pre...\n",
      "üìç Processing france_pre: france_pre_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=1.766, E=3.120\n",
      "              S=42.358, N=43.353\n",
      "üìÖ Date range: 2025-06-10 to 2025-07-10\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed france_pre\n",
      "\n",
      "üåç Processing france_post...\n",
      "üìç Processing france_post: france_post_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=1.766, E=3.120\n",
      "              S=42.358, N=43.353\n",
      "üìÖ Date range: 2025-06-15 to 2025-07-15\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed france_pre\n",
      "\n",
      "üåç Processing france_post...\n",
      "üìç Processing france_post: france_post_inspire.xml\n",
      "    ‚ö†Ô∏è Single day range detected, expanding to 30-day window\n",
      "üìç Coordinates: W=1.766, E=3.120\n",
      "              S=42.358, N=43.353\n",
      "üìÖ Date range: 2025-06-15 to 2025-07-15\n",
      "  üå°Ô∏è Extracting from MODIS_TERRA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    ‚úÖ Successfully extracted 29 temperature records\n",
      "  üå°Ô∏è Extracting from MODIS_AQUA...\n",
      "    Found 30 images in collection\n",
      "    Found 30 images in collection\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    ‚úÖ Successfully extracted 28 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT8...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "  üå°Ô∏è Extracting from LANDSAT9...\n",
      "    Found 8 images in collection\n",
      "    Found 8 images in collection\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed france_post\n",
      "SUCCESS: france\n",
      "    ‚úÖ Successfully extracted 8 temperature records\n",
      "‚úÖ Successfully processed france_post\n",
      "SUCCESS: france\n",
      "\n",
      "==================================================\n",
      "EXTRACTION SUMMARY\n",
      "==================================================\n",
      "Countries processed: 2\n",
      "Successful: 2\n",
      "With errors: 0\n",
      "\n",
      "SUCCESSFUL EXTRACTIONS:\n",
      "  CHILE:\n",
      "    pre: 4 datasets, 73 records\n",
      "    post: 4 datasets, 72 records\n",
      "  FRANCE:\n",
      "    pre: 4 datasets, 74 records\n",
      "    post: 4 datasets, 73 records\n",
      "\n",
      "Total temperature records: 292\n",
      "\n",
      "Results saved to: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/sample_temperature_extraction_20250811_145454.json\n",
      "Variables 'results' and 'errors' are available for analysis.\n",
      "\n",
      "Extraction completed!\n",
      "\n",
      "Completed at: 2025-08-11 14:54:54\n",
      "\n",
      "==================================================\n",
      "EXTRACTION SUMMARY\n",
      "==================================================\n",
      "Countries processed: 2\n",
      "Successful: 2\n",
      "With errors: 0\n",
      "\n",
      "SUCCESSFUL EXTRACTIONS:\n",
      "  CHILE:\n",
      "    pre: 4 datasets, 73 records\n",
      "    post: 4 datasets, 72 records\n",
      "  FRANCE:\n",
      "    pre: 4 datasets, 74 records\n",
      "    post: 4 datasets, 73 records\n",
      "\n",
      "Total temperature records: 292\n",
      "\n",
      "Results saved to: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output/sample_temperature_extraction_20250811_145454.json\n",
      "Variables 'results' and 'errors' are available for analysis.\n",
      "\n",
      "Extraction completed!\n",
      "\n",
      "Completed at: 2025-08-11 14:54:54\n"
     ]
    }
   ],
   "source": [
    "# Execute Temperature Extraction for Sample Countries\n",
    "# ===================================================\n",
    "\n",
    "print(\"Starting temperature extraction for sample countries...\")\n",
    "print(f\"Started at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Execute the extraction for a sample of countries\n",
    "sample_countries = ['chile', 'france']  # Test with 2 countries\n",
    "\n",
    "try:\n",
    "    all_results = {}\n",
    "    all_errors = {}\n",
    "    \n",
    "    for country in sample_countries:\n",
    "        print(f\"\\nProcessing: {country.upper()}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        country_results, country_errors = temp_extractor.extract_temperatures_for_country(country)\n",
    "        \n",
    "        # Store results\n",
    "        if country_results:\n",
    "            all_results.update(country_results)\n",
    "            print(f\"SUCCESS: {country}\")\n",
    "            \n",
    "        if country_errors:\n",
    "            all_errors.update(country_errors)\n",
    "            print(f\"ERRORS: {country}\")\n",
    "        \n",
    "        # Small delay\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"EXTRACTION SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_countries = len(sample_countries)\n",
    "    successful_countries = len(all_results)\n",
    "    countries_with_errors = len(all_errors)\n",
    "    \n",
    "    print(f\"Countries processed: {total_countries}\")\n",
    "    print(f\"Successful: {successful_countries}\")\n",
    "    print(f\"With errors: {countries_with_errors}\")\n",
    "    \n",
    "    # Count total records\n",
    "    total_records = 0\n",
    "    \n",
    "    # Detailed results\n",
    "    if all_results:\n",
    "        print(f\"\\nSUCCESSFUL EXTRACTIONS:\")\n",
    "        for country, periods in all_results.items():\n",
    "            print(f\"  {country.upper()}:\")\n",
    "            for period, data in periods.items():\n",
    "                temp_data = data['temperature_data']\n",
    "                period_records = sum(len(dataset_data) for dataset_data in temp_data.values())\n",
    "                total_records += period_records\n",
    "                print(f\"    {period}: {len(temp_data)} datasets, {period_records} records\")\n",
    "        \n",
    "        print(f\"\\nTotal temperature records: {total_records}\")\n",
    "    else:\n",
    "        print(f\"\\nNo successful extractions\")\n",
    "    \n",
    "    # Save results if we have any\n",
    "    if all_results:\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Save as JSON\n",
    "        json_filename = f\"sample_temperature_extraction_{timestamp}.json\"\n",
    "        json_filepath = os.path.join(OUTPUT_FOLDER, json_filename)\n",
    "        \n",
    "        # Convert results to JSON-serializable format\n",
    "        json_results = {}\n",
    "        for country, periods in all_results.items():\n",
    "            json_results[country] = {}\n",
    "            for period, data in periods.items():\n",
    "                json_results[country][period] = {\n",
    "                    'metadata': data['metadata'],\n",
    "                    'temperature_data': data['temperature_data'],\n",
    "                    'extraction_timestamp': data['extraction_timestamp']\n",
    "                }\n",
    "        \n",
    "        with open(json_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'results': json_results,\n",
    "                'errors': all_errors,\n",
    "                'extraction_summary': {\n",
    "                    'total_countries': total_countries,\n",
    "                    'successful_countries': successful_countries,\n",
    "                    'countries_with_errors': countries_with_errors,\n",
    "                    'total_records': total_records,\n",
    "                    'extraction_timestamp': datetime.datetime.now().isoformat()\n",
    "                }\n",
    "            }, f, indent=2, default=str, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nResults saved to: {json_filepath}\")\n",
    "        \n",
    "        # Store results in variables for analysis\n",
    "        results = all_results\n",
    "        errors = all_errors\n",
    "        \n",
    "        print(f\"Variables 'results' and 'errors' are available for analysis.\")\n",
    "    \n",
    "    print(f\"\\nExtraction completed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError during extraction: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\nCompleted at: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2699e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking extraction results and output files...\n",
      "==================================================\n",
      "\n",
      "1. Output Directory: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output\n",
      "   Found 8 output files:\n",
      "   - comprehensive_temperature_extraction_20250811_141637.json (782,805 bytes)\n",
      "   - temperature_extraction_summary_20250811_141637.xlsx (128,999 bytes)\n",
      "   - extraction_error_log_20250811_140917.txt (376 bytes)\n",
      "   - temperature_extraction_summary_20250811_141142.xlsx (6,770 bytes)\n",
      "   - sample_temperature_extraction_20250811_145454.json (130,007 bytes)\n",
      "   - temperature_analysis_plots_20250811_141651.png (731,514 bytes)\n",
      "   - ~$temperature_extraction_summary_20250811_141637.xlsx (165 bytes)\n",
      "   - comprehensive_temperature_extraction_20250811_141637.pkl (164,322 bytes)\n",
      "\n",
      "2. Results Variable Check:\n",
      "   [OK] Results variable exists with 2 countries\n",
      "   - chile: ['pre', 'post']\n",
      "     pre: 73 temperature records\n",
      "     post: 72 temperature records\n",
      "   - france: ['pre', 'post']\n",
      "     pre: 74 temperature records\n",
      "     post: 73 temperature records\n",
      "\n",
      "3. Errors Variable Check:\n",
      "   [OK] No errors variable found\n",
      "\n",
      "4. Data Quality Check:\n",
      "   [OK] Found 48 valid temperature readings\n",
      "   Temperature range: -13.5¬∞C to 39.9¬∞C\n",
      "   Average temperature: 25.5¬∞C\n",
      "\n",
      "5. System Status:\n",
      "   XML Files: 12 countries available\n",
      "   Temperature Datasets: 4 configured\n",
      "   Google Earth Engine: Connected\n",
      "   Output Directory: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output\n",
      "\n",
      "Check completed!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Check Output Files and Results\n",
    "# ===============================\n",
    "\n",
    "print(\"Checking extraction results and output files...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if output directory exists and list files\n",
    "import os\n",
    "print(f\"\\n1. Output Directory: {OUTPUT_FOLDER}\")\n",
    "if os.path.exists(OUTPUT_FOLDER):\n",
    "    files = [f for f in os.listdir(OUTPUT_FOLDER) if not f.startswith('.')]\n",
    "    print(f\"   Found {len(files)} output files:\")\n",
    "    for file in files:\n",
    "        file_path = os.path.join(OUTPUT_FOLDER, file)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        print(f\"   - {file} ({file_size:,} bytes)\")\n",
    "else:\n",
    "    print(\"   Directory does not exist\")\n",
    "\n",
    "# Check if results variable exists\n",
    "print(f\"\\n2. Results Variable Check:\")\n",
    "if 'results' in locals() and results:\n",
    "    print(f\"   [OK] Results variable exists with {len(results)} countries\")\n",
    "    for country, periods in results.items():\n",
    "        print(f\"   - {country}: {list(periods.keys())}\")\n",
    "        for period, data in periods.items():\n",
    "            temp_data = data['temperature_data']\n",
    "            total_records = sum(len(dataset_data) for dataset_data in temp_data.values())\n",
    "            print(f\"     {period}: {total_records} temperature records\")\n",
    "else:\n",
    "    print(\"   [INFO] No results variable found\")\n",
    "\n",
    "# Check if errors variable exists\n",
    "print(f\"\\n3. Errors Variable Check:\")\n",
    "if 'errors' in locals() and errors:\n",
    "    print(f\"   [WARNING] Errors variable exists with {len(errors)} countries\")\n",
    "    for country, periods in errors.items():\n",
    "        print(f\"   - {country}: {list(periods.keys())}\")\n",
    "else:\n",
    "    print(\"   [OK] No errors variable found\")\n",
    "\n",
    "# Test basic temperature data access\n",
    "print(f\"\\n4. Data Quality Check:\")\n",
    "if 'results' in locals() and results:\n",
    "    sample_temps = []\n",
    "    for country, periods in results.items():\n",
    "        for period, data in periods.items():\n",
    "            for dataset_name, records in data['temperature_data'].items():\n",
    "                for record in records[:3]:  # Check first 3 records\n",
    "                    if record['mean_temp_celsius'] is not None:\n",
    "                        sample_temps.append(record['mean_temp_celsius'])\n",
    "    \n",
    "    if sample_temps:\n",
    "        print(f\"   [OK] Found {len(sample_temps)} valid temperature readings\")\n",
    "        print(f\"   Temperature range: {min(sample_temps):.1f}¬∞C to {max(sample_temps):.1f}¬∞C\")\n",
    "        print(f\"   Average temperature: {sum(sample_temps)/len(sample_temps):.1f}¬∞C\")\n",
    "    else:\n",
    "        print(\"   [WARNING] No valid temperature readings found\")\n",
    "else:\n",
    "    print(\"   [INFO] No results to check\")\n",
    "\n",
    "print(f\"\\n5. System Status:\")\n",
    "print(f\"   XML Files: {len(enhanced_extractor.available_files)} countries available\")\n",
    "print(f\"   Temperature Datasets: {len(TEMPERATURE_DATASETS)} configured\")\n",
    "print(f\"   Google Earth Engine: Connected\")\n",
    "print(f\"   Output Directory: {OUTPUT_FOLDER}\")\n",
    "\n",
    "print(f\"\\nCheck completed!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40149e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TEMPERATURE EXTRACTION SYSTEM - COMPLETE\n",
      "==================================================\n",
      "\n",
      "‚úÖ SYSTEM FEATURES:\n",
      "   ‚Ä¢ Batch processing of all XML files in the database\n",
      "   ‚Ä¢ Multi-dataset temperature extraction (MODIS Terra/Aqua, Landsat 8/9)\n",
      "   ‚Ä¢ Automatic satellite acquisition date extraction\n",
      "   ‚Ä¢ Comprehensive Excel export with multiple sheets\n",
      "   ‚Ä¢ Advanced cloud masking and quality filtering\n",
      "   ‚Ä¢ Temperature classification and fire risk assessment\n",
      "   ‚Ä¢ Statistical analysis (mean, min, max, std deviation)\n",
      "   ‚Ä¢ Error handling and detailed logging\n",
      "\n",
      "üìä OUTPUT FILES:\n",
      "   ‚Ä¢ JSON: Complete extraction results with metadata\n",
      "   ‚Ä¢ Excel: Structured data with summary and detailed sheets\n",
      "   ‚Ä¢ Pickle: Python objects for further processing\n",
      "   ‚Ä¢ Plots: Temperature analysis visualizations\n",
      "\n",
      "üå°Ô∏è DATA INCLUDED:\n",
      "   ‚Ä¢ Country and time period identifiers\n",
      "   ‚Ä¢ Satellite acquisition dates (from XML metadata)\n",
      "   ‚Ä¢ Temperature statistics (mean, min, max, std deviation, range)\n",
      "   ‚Ä¢ Multiple satellite datasets for validation\n",
      "   ‚Ä¢ Spatial coordinates and resolution information\n",
      "   ‚Ä¢ Quality-filtered data with cloud masking\n",
      "\n",
      "üìÅ OUTPUT LOCATION:\n",
      "   All files saved to: /Users/diego/Documents/FirePrediction/data_pipeline/utils/temperature_extraction_output\n",
      "\n",
      "üöÄ READY FOR FIRE PREDICTION:\n",
      "   ‚Ä¢ High-resolution temperature data for improved fire modeling\n",
      "   ‚Ä¢ Multi-sensor validation for robust temperature estimates\n",
      "   ‚Ä¢ Temporal analysis capability for fire risk assessment\n",
      "   ‚Ä¢ Quality-controlled data ready for machine learning models\n",
      "   ‚Ä¢ Integration with wind and vegetation data for comprehensive analysis\n",
      "\n",
      "üí´ TEMPERATURE EXTRACTION COMPLETE! Ready for fire prediction analysis! üí´\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Summary and Usage Instructions\n",
    "# =====================================\n",
    "\n",
    "print(\"üéØ TEMPERATURE EXTRACTION SYSTEM - COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print()\n",
    "\n",
    "print(\"‚úÖ SYSTEM FEATURES:\")\n",
    "print(\"   ‚Ä¢ Batch processing of all XML files in the database\")\n",
    "print(\"   ‚Ä¢ Multi-dataset temperature extraction (MODIS Terra/Aqua, Landsat 8/9)\")\n",
    "print(\"   ‚Ä¢ Automatic satellite acquisition date extraction\")\n",
    "print(\"   ‚Ä¢ Comprehensive Excel export with multiple sheets\")\n",
    "print(\"   ‚Ä¢ Advanced cloud masking and quality filtering\")\n",
    "print(\"   ‚Ä¢ Temperature classification and fire risk assessment\")\n",
    "print(\"   ‚Ä¢ Statistical analysis (mean, min, max, std deviation)\")\n",
    "print(\"   ‚Ä¢ Error handling and detailed logging\")\n",
    "print()\n",
    "\n",
    "print(\"üìä OUTPUT FILES:\")\n",
    "print(\"   ‚Ä¢ JSON: Complete extraction results with metadata\")\n",
    "print(\"   ‚Ä¢ Excel: Structured data with summary and detailed sheets\")\n",
    "print(\"   ‚Ä¢ Pickle: Python objects for further processing\")\n",
    "print(\"   ‚Ä¢ Plots: Temperature analysis visualizations\")\n",
    "print()\n",
    "\n",
    "print(\"üå°Ô∏è DATA INCLUDED:\")\n",
    "print(\"   ‚Ä¢ Country and time period identifiers\")\n",
    "print(\"   ‚Ä¢ Satellite acquisition dates (from XML metadata)\")\n",
    "print(\"   ‚Ä¢ Temperature statistics (mean, min, max, std deviation, range)\")\n",
    "print(\"   ‚Ä¢ Multiple satellite datasets for validation\")\n",
    "print(\"   ‚Ä¢ Spatial coordinates and resolution information\")\n",
    "print(\"   ‚Ä¢ Quality-filtered data with cloud masking\")\n",
    "print()\n",
    "\n",
    "print(\"üìÅ OUTPUT LOCATION:\")\n",
    "print(f\"   All files saved to: {OUTPUT_FOLDER}\")\n",
    "print()\n",
    "\n",
    "print(\"üöÄ READY FOR FIRE PREDICTION:\")\n",
    "print(\"   ‚Ä¢ High-resolution temperature data for improved fire modeling\")\n",
    "print(\"   ‚Ä¢ Multi-sensor validation for robust temperature estimates\")\n",
    "print(\"   ‚Ä¢ Temporal analysis capability for fire risk assessment\")\n",
    "print(\"   ‚Ä¢ Quality-controlled data ready for machine learning models\")\n",
    "print(\"   ‚Ä¢ Integration with wind and vegetation data for comprehensive analysis\")\n",
    "print()\n",
    "\n",
    "print(\"üí´ TEMPERATURE EXTRACTION COMPLETE! Ready for fire prediction analysis! üí´\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpaceChallenges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
